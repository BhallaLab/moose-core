26 Dec 2006

Revision 50: Implemented connects and disconnects at the conn level. This
is non-trivial as it involves updating ranges and target Conns affected by
the index changes.

- Handle Element deletion. Do it intelligently: first mark all elements
	scheduled for deletion, then efficiently update only the surviving
	connections.
	This is a bit premature as we also need to delete the MsgSrc/MsgDest
	entries along with this.

- Build up MsgSrc and MsgDest handling

- Test regular messages

=============================================================================
29 Dec 2006

Revision 51: checked in the preliminary element deletion stuff prior to
going on with the MsgSrc stuff.

=============================================================================
30 Dec 2006

Message creation starting to take shape. For shared messages we have
to go to the first src _on both sides_, and ask this src to insert a new
Conn which is then used to make a connection. If the shared message only
has dests then the dest takes care of the Conn insertion. For regular
messages it is straightforward: insert Conn on src and dest respectively.

Also have a flow chart for how to set up the messages from the view point of
the Field/finfo:

typedef FuncList vector< RecvFunc >

addFrom:
- Check respondToAdd. This returns a conn index if it works
- Trigger a local event for message formation.
- Insert new Conn on src as above
- Tie up Conns.

bool respondToAdd( Field src, FuncList& srcRf, vector< Ftype* >& srcType,
	FuncList& destRF, unsigned int& destConn )
- Check the types
- Trigger a local event for message formation.
- inert the new Conn, using a src if there are any funcs coming in.
- Return with the new Conn and recvfuncs.

delete
- Most of the effort goes into identifying the conns to go for.
- Delete the conn
- Do local event.

set/call
- Check arg type(s)
- Make dummy conn
- execute all RFs in FuncList.

get
- For values:
	- Copy values into pointer
- For MsgSrc:
	- Copy target list
- msgDest
	- Copy target list.

strSet
- Convert arg type(s)
- Do above set/call

strGet
- Do above get
- Convert arg types into string.

Finally got initial pass at messaging to compile, though it croaks when run.
=============================================================================
31 Dec 2006

Setting up to make messages using MsgSrc and MsgDest.
Got initial message creation to work. 
Looks like we could simplify MsgDests to be independent of ranges, and 
refer directly to ranges in the Conn vector.

Checked in as revision 53.

Trying now to do send.
OK, got it to work. But the send is a horribly messy function, way too many
indirections. Need to rethink the structure of MsgSrc and MsgDest, try to 
do away with the Range altogether.
Anyway, check this version in as revision 54.

Working on update. Looks like it will be good. But currently the updates
are a bit messy. Not wrapped up.
Could even consider putting in pointers to the Conn entries in the Src
vector. Would need to do a bit of extra work on some updates, but the
Sends would be slightly faster as they would not have to lookup values.
=============================================================================
1 Jan 2007
After much grinding, finally reimplemented the messaging starting from the
definition of MsgSrc to get rid of the Range. Compiles. Fails.

Various fixes later. Compiles, runs.

Checked in as revision 55.

Now to do more thorough checking
+ Conn insertion and updates in later sections.
+ src link list
+ Managing both dests and srcs as if in a shared message.
+ Conn deleting


=============================================================================
2 Jan 2007
Working on the checks listed above. Minor fixes.
Lots more tests added, all clear. Time to check it in.

=============================================================================
3 Jan 2007
Design the infos now. Operations to support:

Admin:
match ( to find info from string, and possibly subfields or array entries )
isA (type identity, going through Ftype)

Messaging:
add ( as source )
respondToAdd (as dest )
drop (as any half of connection )
respondToDrop ( as other half )
srcList
destList

Data:
set/call ( using usual recvfunc )
get
strset
strget

The Element itself has to manage an array of finfos, which are set up
using a static initializer. Each finfo must have
RecvFunc ( This provides the set operation )
getFunc ( for messages this is an indexed list of targets. But doesn't match
	RecvFunc )
Ftype ( handles str conversions either way, does type checking )
base class info (needed to handle nested fields)
Would like to also finfos to contain cinfos. finfo_[0] has class info of
	data ptr as a whole.
	Field finfos are derived from cinfos for other classes, so that 
	every field has full class mappings.
	Perhaps Ftype === cinfo? But we have multi-arg recvfuncs.


I had a proliferation of ~20 Finfos, all listed:

What is a finfo?
- Something you send messages to or from.
- Something to manage and access data fields

The first is more restrictive. More stuff is needed for data fields.


=============================================================================
4 Jan 2007

Relay stuff for finfos:

All srcs can be dests: Provide a RecvFunc that is templated to pass arguments
from the triggering function directly to the src. Can use send and sendTo, 
but sendBack is tricky.
	- This means that we can configure fields to do this cleanly, except
	that here the RecvFunc is munged so it instead uses the field value.

All dests can be srcs passing the same arguments:
Here we just need to go back to the real src and have it send another message.
No additional stuff in the finfo.

In the earlier version we had some 20 Finfo types. Here we need:
- ObjFinfo: Uses a lookup func, permits nesting, 
	permits full object assignment, passes a pointer except at postmaster.
- ValueFinfo: No nesting. provides recvFunc for set. Use another recvFunc to
	trigger return message, which is also used for get. Perhaps split it?
	Actually respondToAdd is a good way to provide different recvFuncs.
- MsgSrcFinfo: No nesting. provides recvFunc for passing arguments right into
	src.  Handles specific MsgSrc entries.
- MsgDestFinfo: No nesting. Provides recvFunc for operations.
- SharedFinfo: No nesting. Provides a whole set of recvFuncs. Or sometimes
	no recvfuncs if it is only srcs.

Options for getting values from fields:
- Use a getfunc
	- Simple.
	- Still need to implement something for message access.
- Using a shared message with a trigger and a return msgsrc 
	- Complex. For regular object assignment would need something like
	a temporary message to be set up. If this could be simplified it would
	be OK.
		- Get the trigger recvfunc with a respondToAdd. Perhaps at
		this point the target can decide which recvfunc to return,
		one for gets, or one for proper messages.
		- Calling a trigger recvfunc is easy.
		- Need to provide a return conn in any case, because that is
		how recvfuncs work. In addition would need to have a recvFunc
		to accept the return value. 
			- Pass the rf in the triggering recvFunc? 
			Not good, specially across nodes.
			- Assume a generic recvfunc that just typecasts the
			e->data and assigns it? Works, except how do we give
			it other recvfuncs when we set up proper messages.
			- Actually, simple: Just pass in the required return
			recvfunc in the respondToAdd itself. But oops, where
			does it store it? The proper message stores it in 
			the MsgSrc array.
			- Make a distinction in the respondToAdd about which
			recvfunc to return to the caller. If there is no
			passed in recvfunc, return the recvfunc that typecasts
			e->data.
	- Works for message access
	- Would it be simpler for cross-node field access?
- Build a full message and then delete it.
	- Major complex to execute, but simplest to program.
	- Residual allocations all over the place.
	- Completely general across nodes
		- Issue with deadlocks and timings across nodes. These are
		there in the other methods too unless we do the serializing.
- Return a recvfunc void(*)(Conn*, value& ret) where we return the value
	in a naughty way.
- Pass in a recvfunc to be used for the return operation. Also naughty,
	but keeps the typecast function interface to a minimum.
- Provide Set/Get functions but typecast to some uniform shape so that we 
	can put them in the main Finfo class without juggling through a 
	valuefinfo class. Do type protection via the finfo's ftype... can we?
	Yes, the set< T >  function can build a temporary ftype for the
	comparison.

=============================================================================
5 Jan 2007

After messing around a fair bit with finfos, I think the best bet is to go
ahead and reimplement essentially the same functional set as before, but with
an eye to cleanness and moving all type-specificity to Ftype. Later we can
look at further merging of concepts.

Implemented the basic message passing SrcFinfo and DestFinfo, compiled.
Time to check it in. Revision 57

Did a preliminary unit test to show that the Src and Dest Finfos can 
manage the setting up of messages.
Now to try sending information.

Did so, after lots of additional fixes. Revision 58.

Accessing finfos:
- Ptr to vector off Element*
	- Tricky to extend
- vector off Element* where first entry is always self, and points to cinfo,
	which points to array of finfos for default fields.
	- Each data Finfo points to a cinfo which gives a further set of
	finfos obtained by indirection. Their use is fine for get/set,
	but for real messages we need to copy the nested finfo, put it into
	a new finfo to live on the finfo vector. The new finfo will also
	handle indirection.

=============================================================================
6 Jan 2007

Looking at handling nested fields. OK as above up to the generation of a 
new finfo to deal with it, but not good for messaging. Functors are an obvious
way to pass in the extra indirection info, but this would add a minimum 2
indirections to every func call. We would need a wrapper functor with
a pointer to the polymorphic class that executes the func, because functors
are pass-by-value. Then the virtual func would cost at least another 
indirection. Original plan was to provide a wrapper Element* to do this.
It would do the lookup of the nested part of the data, and the assigning 
func only needs to know the final data type. Issue is how to manage this
wrapper Element. We would need to pass it back in the respondToAdd, and
the incipient Conn would need to know about it to replace the primary
Element.
Alternatively: Can we design a recvfunc that is precompiled but looks up
some extra info to find the other parts of it?
Two possibilities: 
- Template off about 3 recvfuncs with indices, and send out
whichever is needed. Rarely will we need more, complain if it happens. These
just look up the appropriate entry when needed. Messiness here with scaling
and with predefining a load of recvfuncs.
- Use the conn index to look for a matching entry. Slightly slow for looking
up, but saved because we will rarely have many. No issue with scaling.
I like this. The RecvFunc simply says, look for the entry in the extended
Finfo table which matches this, and do your operation with its help.

void extRecFunc( Conn& c, T v )
{
	ExtFinfo* f = findExtFinfo( c ); // Match it using the Conn index.
	assert( f != 0 );

// Here the lookup func is wrapped into the indirection element
	TempConn tc( c, f->data() ); // Here we set up an indirection Element
				// to replace the one from c. 
				// Or perhaps TempConn tc = c.tempConn( e, f->data() );

// Here the nested recv func is applied to the looked up data part as held in
// the indirection Element.
	reinterpret_cast< void ( *ofunc )( Conn&, T ) >( f->origFunc() ) ( tc, v );
}

Slow building up of many things here. Began with implementation of Cinfo.
Begun implementing ThisFinfo, which handles the object itself.

Checked it in as version 59.

Other pieces:
ValueFinfo: Need it to understand the API we will need for fields.
IndirectFinfo: Manage the above function and recvfuncs
ObjFinfo: A finfo that refers to a nested object.
IndirectElement: Manage lookup of data() internally.
DynamicFinfo: Finfo to be made on the fly for handling non-compiled operations.
	Looked up using the cinfo index.
=============================================================================
7 Jan 2007

Putting preliminary implementations together for various things, just to
clarify implementation possibilities. Lots of things coming together here,
and now I should steadily work through implementing each.
* Class definition through array of Finfos.
* Finfo lookup
+ Value fields
- Nested fields
- Array fields
- Shared messages
+ Dynamic messaging: To value fields
- Dynamic messaging: To nested fields

Getting close to sending messages using the class definition. Bug somewhere
in how the numbering of msgsrcs is done.
Also SimpleElement::add is not defined, but doesn't seem to bother it.
Possible issue is  SimpleElement::insertConnOnSrc

=============================================================================
8 Jan 2007

Finally got a simple network with messaging to work, various bugs ironed out.
Time to check it in. This is revision 60.

=============================================================================
9 Jan 2007.

Got first level of finfo lookup to work, no bells and whistles yet. Checked in.
This was revision 61.

=============================================================================
10 Jan 2007.
Beginning to set up ValueFinfo, which in large part also involves defining
DynamicFinfo.

Trying to compile.
=============================================================================
11 Jan 2007

Horrible mess compiling, obscure error messages about vtables that did not
identify the source of the problem. Turns out it helps to have an object
file rather than just inlines, because then the compiler deigns to explain
what the problem was. The problem was that in the base Element class I had
not put the =0; when defining a pure virtual.

Anyway, checked this whole mess in prior to doing the next stage of getting
data field assignment to work, and then the messaging to value fields.
This was version 62.

Now got simple set and get to work. This entailed development of the listFinfos
function that ramifies through many classes, just to test that the
finfo was a valid one. The function has other uses too, which is why I 
bothered. Checked in as version 63.

=============================================================================
12 Jan 2007
Now working on messages to and from Values.
Setting up a rather big seris of tests for this. First stage was just
doing the controls: ensuring that the regular messaging works. Works.

Got set message into a ValueFinfo to work. Checked in as version 64.

Currently a little stuck on line 983 in the unit tests. dval of e0 has
changed, and I don't know why.
=============================================================================
13 Jan 2007
Need to use the MsgDest ranging to monitor if a DynamicFinfo is invoked by an
incoming message. Actually reduces work when we are changing conns.

Architecture issues pending:
- Parallel messages
- SWIG
- Class init and MPP
- Solver messaging
- Scheduling and clock juggling
- Field objects
- Object/field ids across nodes
- Serialization and persistence: data
- Serialization and persistence: messages
- Multithreading options.


=============================================================================
14 Jan 2007

After much messing around, figured out why there was a problem in unit
tests when I tried --proc--> e1/procout --> e0/dval --> e4/dsum
Turned out not to be an issue with the messaging, which worked, but with
the field gets, which failed when confronted with a DynamicFinfo. This led
me to do some general reorganization of the set/get functions so that they
are now part of the main Finfo base class with delayed typing.
So we now have messages going into and out of fields. Still more variants
to test, but first to check it all in. This was revision 65.

Now testing  --proc--> e1/procout --> e5/dval --> e6/dsum";
where we first add the message from d5 to e6, then the trigger. Currently
it fails.

Yet more fixes to how the DynamicFinfo handles messaging, and how it is
set up by the ValueFinfo. Now it works.

Then I went through adding further tests:
trig then dval: --proc--> e1/procout --> e7/dval --> e8/dval";
dval then trig: --proc--> e1/procout --> e9/dval --> e10/dval";

All OK. Still remain to handle shared messages, but otherwise things look
pretty good here, and a very general solution so far. Time to check it in.
This was revision 66.

Running into problems with the PtrFinfo. The issue is the usual one of 
providing a static function for set/get, while having the available func
as a different function ptr. functors would be easy, but I don't think
the code will allow it.

=============================================================================
15 Jan 2007
For now, defer the problem of ptr use for set/get. Require that if one
wants to access the entire data field, one should define it also as a
ValueFinfo for itself.
Back to the PtrFinfo. I'm able to generate a nested set of DynamicFinfos
using the recursive match operation. But where and when does the returned
Finfo get used? If used for set/get, then it is used once and should then
be deleted. if used for messaging, we need to anchor the DynamicFinfo on
the elm. Perhaps the add operation can trigger a call within the
DynamicFinfo to check if it has been moored onto the elm.

=============================================================================
17 Jan 2007
Let's start by splitting up the problem.
- Separate DynamicFinfos for each class. Later merge if good.
- ArrayFinfo, DynArrayFinfo: ValueFinfo for arrays.
- NestFinfo (to replace PtrFinfo): ONLY for nesting, refers to a known Cinfo.
	NOT for assigning values, at least not at first.
- Figure out if DynamicFinfo handles Dest->other and other->Src cases.

ArrayFinfo: A variant on ValueFinfo and deals with specific, known classes. 
- No further nesting. 
- User provides 
	void set( const Conn&, T, unsigned int index )
	T get ( const void*, index )


NestFinfo( const string& name, const Cinfo*, void* (*)( void*, unsigned int index ) )
- Matching: identifies traversal, index and nested field. Looks up
	Finfo for nested field. Generates a DyNestFinfo.
- Only does nesting, no sets or gets at this point for field as a whole.
- set, RecvFunc: Nested Finfo->ftype()->nestFunc()
	which uses DyNestFinfo.
- get: NestedFinfo->Ftype()->getFunc but needs to be invoked from DyNestFinfo.
- add: Wrapper function to look up actual target, fake the conn?
- respondToAdd: ?
- DestFinfo: Same as Set
- SrcFinfo: DyNest provides dummy Element to fudge MsgSrc indices
- ArrayFinfo: 
- NestFinfo:
All in all, the NestFinfo has a pretty formidable set of things to do.

Another approach:
- Use DynamicFinfo for all funny messages, but look up supplementary info
efficiently in the same way that Synapse info is looked up.
- Use different kinds of DynamicFinfos, but look them up using efficient
indexing a la synapses.


OK, current approach:
- We'll work out how to index the DynamicFinfo as needed.
- We'll create a new DynamicFinfo as soon as the 'match' function is called.
	We immediately place it on the finfo_ vector.
	By definition, future calls would hit the DynamicFinfo first,
	so match should only be called once on any object.
	(May need to refer between DynamicFinfo and original Finfo in case
	we have more messiness here.)
- If the subsequent function is set or get, it checks if the DynamicFinfo
	is unmessages. If so, delete it as soon as op is done.
- If the subsequent function is messaging, add/drop messaging and delete
	DynamicFinfo if now empty.
- Add, respondToAdd, and drop now operate on the new dynamic finfo, NOT on the 
	original finfo. So these operations need to be handled only by
	the DynamicFinfo.
- Whatever recvFunc or other op is needed, is handled by the original
	Finfo, which typically refers these to the Ftype. In all cases
	the DynamicFinfo, or a subclass, provides additional data.
- set/get remain a problem. They really need to refer somehow to the
	parent Finfo. I suppose that only Value and DynamicFinfos should
	support set/get, in which case we could organize it. Even better,
	we never actually expose anything except the DynamicFinfo...
	oops, we wanted also to do DestFinfos.

=============================================================================
18 Jan
Running into all sorts of problems with set/get for funny finfos.
Perhaps I should stick to implementing messaging operations alone, and
do set/get through messages. Question is whether overhead will be too much.

Try:
- DynamicFinfo that can handle indirection to forward operations for
	doing add or respondToAdd.
	- Need common mechanism for doing this forwarding.
- Value, Src and Dest Finfos that provide add and respond.
- Array and Nesting Finfos to provide info for DynamicFinfo to do indirection.
- Ftype to deal with all function typing. Clean up ValueFinfo so it doesn't

- ValueFinfo with setFunc and either a getFunc or a trigFunc given by the user.
- ArrayFinfo with setFunc and either getFunc or trigFunc, indexed by Dynamic.
- 

=============================================================================
19 Jan 2007
Should I modify the Send so that there is a sendWithIndex that passes
an extra arg, of the conn index, to each target. Used for synapses etc.
This would have the implication that the RecvFunc need not know anything
at all about the Element. It would be an entirely local operation.
No, won't work. The outgoing Send commands in a recvFunc will need the
Element info.

Now into concrete compilation. 
- Compile and test. Currently stuck with the usual template header
	dependency headaches.
	Now compiled, but get immediate segve
- Eliminate ValueFinfo<T> and just have the generic operations, rest by 
	Ftype. Compile and test.
- Make an ArrayFinfo
- Make a NestFinfo
=============================================================================
20 Jan 2007
Conversion under way. Somewhat to my surprise I have a working 
(clears all unit tests) intermediate version where DynamicFinfo
is handling all the adds and respondToAdds, and various mutations
have happened to Ftype1.

Checked it in. It is version 67.

Now lots of changes going on to get the ValueFinfo to become non-templated
and shift stuff over to Ftype. Ftype1 has been subclassed into variants
for handling Value, Array and Nest.

Again, surprisingly, it worked and cleared unit tests with relatively little
effort after many rather deep changes. Checked in as version 68.

Now let's set up the ArrayFinfos.

Point here: The DynamicFinfo needs two sets of setFuncs and getFuncs.
The inner set is the set that the original object passes it. These are
used by the Ftype to generate the static setFunc and trigFuncs that
are seen by the outside world, such as messages.
Point is that the DynamicFinfo needs to have the whole lot accessible to it.
But possibly we could have the Ftypes accessing the funcs in a
setFunc( Finfo ) type operation, which either passes back the statically
defined Ftype variant of the function, or the variant that the parent Finfo
generated. A bit too convoluted. Let's just have the Finfo pass the 
correct functions in to the DynamicFinfo, which now has rather a lot
of args.

Cleaned up use of set/get funcs in Finfo. Separated the role of different
types of Ftype. Redid the set<T> and get<T> operations, they are more
general now and should work with arrays and nested fields in due course.
Yet again surprised at the whole thing clearing the unit tests.
Checked in as version 69.

Next to set up unit tests for Arrays, then for nested objects. Begun.
Barfs.

=============================================================================
21 Jan 2007

Fixed up minor bugs, fixed issue with naming in the DynamicFinfo. We really 
need to have the fully specified name given to the DynamicFinfo so that
a regular name match is sufficient to identify it. Updated the UnitTests
so that they test Set and Get on the Array.

Some issues with looking it up because conn index is zero but so is conn size
on the dummy element.
This is a more fundamental problem. It happens because we assume each
DynamicFinfo is associated with at least one incoming Conn. But if we
are doing a set/get, we have unassociated DynamicFinfos sitting around.
Worse, we could have multiple of them unless we can guarantee that the others
will be deleted at once. Multithreading of shell is an issue here.

OK, one issue dealt with. For set and get we do not rely on the lookup of
DynamicFinfos, we use the one provided. However, we still have 'droppings'
of old DynamicFinfos left sitting on the SimpleElement finfo_ list. These
can be identified by having no incoming Conns, and can be deleted at
some garbage collection stage. Perhaps addFinfo would be a good stage for
this.

Implemented the fix, ran a few unit tests, looks like ArrayFinfo set and
get now works. Hooray. Checked it in as version 70.

Now to check messaging to and from array entries.
Great. This worked right off. I have done most of the variants on
message to and from regular, Value and Array Finfos. 
Checked it in as version 71.

Looking at NestFinfo. This will need a functioning cinfo infrastructure.
It has a problem because Finfos are const. So we really want the nested
class to be passed in as a cinfo, which constrains us to having the class
already defined. This rules out an initialization step. Given the
usual static initialization approach, we need something clever to ensure
that the nested class is defined first so its cinfo can be looked up.

Anyway, started implementing NestFinfo.h using this idea. Should march
on through. Need also to back up all this work.

=============================================================================
22 Jan 2006
Did complete disk backup.
Muddling along with Nest implementation.
=============================================================================
23 Jan 2006
Heard from Dave Beeman that Jim has decided to cut MOOSE out of the loop with
his incarnation of GENESIS, and to go with Hugo's Neurospaces instead.
Various decisions follow.
- Takeover and Makeover of the MOOSE site. 
- Whether to do our own graphics. If so, how.
- Tie ups. Erik, Sharon and Padriag, Sys Bio people.
- Renaming and release plans
- Announcements and writing
- Prioritization

Anyway, for now let's get the Nest implementation to work. Main obstacle now
is defining its scope.
- Consider a channel. It has nested in it several interpols.
Actually we would normally do this using messages, so that the interpols
could be shared.
- Consider an nreac. It has nested in it an array of reactions and molecules,
all computed efficiently in one step. Same rate for the lot, but an array
of state variables. But this could be set up using the regular array. Do I
really want it to look like many steps inside?
- Consider diffusion. Idea is to have a single Element managing an array of
identical molecules, and superimpose a diffusive calculator on it.
But I would like to refer to each molecule as if it were the real thing.
- Consider an array of 1e6 neurons. They all share the same heirarchy. We
build one neuron, and then say that each compartment actually represents
the 1e6 corresponding ones.

Two key points:
1. Often we want to have generic access plus a black-box solver on top.
2. Other times we want to have generic access but preserve a certain messaging
	structure for all the pieces. Often this would be taken over by
	a solver.

Both these cases seem to require an ArrayElement rather than a SimpleElement.
Here we can acheive the message replication effect by having a local variable
in the ArrayElement to indicate which index we are on. All the old messaging
Just Works using the Element::data() function. Only issue is how to get the
whole lot of elements to coordinate this indexing. Perhaps a special message
to the whole lot of them? 
createmap /neuron /map 100 100
le /map
	neuron[0..9999]
showfield /map/neuron[2703]/compt/Vm

So here the index on the neuron[2703] would tell neuron/compt which index
to use.

Any attempts to modify message structure on an individual basis would be messy.
But necessary, for example, for synaptic connectivity. The ArrayElement would
need an extra internal table to direct the conn_ entries correctly.

Would like to have vector messaging here.
Would like to have vector Process operations, provided the thing isn't
solved. Or even if it is.
Would like to have solver messaging set up in a similar invisible way for
zillions of children.

For now: Move on. Let's get something that works and that we can use
for computing. Here is a list of things to work on with current priority set.

- SWIG
- GENESIS parser
- Windows compilation				Assign Niraj
- MOOSE web site.				Assign Harsha to look at it.
- Scheduling and clock juggling			Me, also get an idea of obj
- Implementation of some basic classes		Me, also test somethings
- Class init and MPP
- Parallel messages
- Solver messaging
- Field objects
- Object/field ids across nodes
- Serialization and persistence: data
- Serialization and persistence: messages
- Multithreading options.
- Array Elements.

...........................................................................

Working on SWIG.
- varargs in commands: Avoid them. Let the Genesis parser wrapper
	code deploy the correct one.
- Commands: Many of them use the shell object as a global. But
	there is a strong assumption of string based object identification.
	That is why . and .. make sense. 
- Should we deal with Field objects rather than strings? it would be nice
	to be able to use the scripting languages to do assignments
	etc on these rather than just replicate the GENESIS setfield/getfield
	commands. In other words, we should be able to do
	/foo/bar = /zod/caprice.
For now:
- Use shell commands with string args
	(exception is setfield and getfield, which have typedefed args.)
- Do not use varargs.
- Do using namespace shell::, but from the viewpoint of a single instance of it
	as if it were a global. Looks like I need to provide a lot
	of little wrapper functions. Alternative is to make them static
	functions of the shell class.

Begun on a test program

=============================================================================

24 Jan 2007
Got the little test program to work with SWIG and python, after much
muddling around. Now to use it to set up a useful system.

I'm sure if I knew more SWIG I could figure out how to represent objects
from MOOSE within Python directly and access fields as though they were
local entities. That can wait, but the only issue is if I get started
with the current approach, will it need to be rolled back? If so, will
it be hard to? I think it should be fine either way. Let's do it.

OK, got the whole of MOOSE to compile with Swig.  Easy after the earlier
prototyping. Currently I have named it 'shell', obviously should be
pymoose or some similar name. Also the funcs in it are still dummy ones.
There are still issues with having the .py files in the right place. This
is a bit odd, as it means we have to have multiple files available to
run python. I guess there is some standard way around this.

Anyway, this is a good time to check it in.

=============================================================================
25 Jan 2007
Now to implement the basic parser commands. Will fill out as I go along.
The other bit is to tie it into the GENESIS parser too, in parallel.
Part of the latter process will also help with internode commands, since
I need to serialize shell function calls using a single function that 
speaks argc, argv.

I've asked Eric Mueller who I think was the PyNest person, about how it is done.
Also wrote to our buddy Joe Svitak.

Now some nomenclature. We need specifically to decide how to name fields.
The confusion arises because Finfo names for MsgSrc, MsgDest, and SharedMsg
may look similar. Let's do this:

- All MsgDests are just given a regular lower case name, such as 'child'
- All SharedMsgs likewise.
- All MsgSrcs names should be suffixed with a Src: 'childSrc'

The reasoning is that MsgDests are often treated like functions, so we
don't want confusing names. SharedMessages are always composites, so
src and dest do not make sense and the same name is useful for either end.

Implemented Neutral. Python sees it and can create and delete it.
Checked in. This should be version 73.

Started on Neutral unit tests. Segv.

Progress on the cleaning up of messages upon deletion.
Struck by an issue with conn indexing in SimpleElement. Cleaner approach is
to provide connBegin( unsigned int src ), connEnd( unsigned int src )
as iterator ranges.
But first lets fix the current problem and check it in before
redoing the interface.

Now working on doig the interface. There is a small expansion in number of
functions but it does keep MsgSrc out of the public interface for 
SimpleElement. Still pegging away at it.

=============================================================================
26 Jan 2007

Did makeover of eliminating MsgSrc and MsgDest return functions from
SimpleElement. Also other cleanups.

A bit stuck on the Neutral test, but I suspect that what is happening is that
I am cleaning up the children which alters the conn_ vector even while I
use an iterator for it.

Perhaps need to do Delete in 3 stages:
1. Mark elements for deletion.
2. Clean out messages to non-marked elements
3. Delete.

We can't merge 1 and 2 because inter-object messaging may not occur in
the same sequence as marking. 
We can't merge 2 and 3, because then there would be already deleted child
elements being queried about whether they were marked.

This would also remove the responsibility of cleanup from ~SimpleElement,
which is not up to the job.

Much messing around later, we have something that works.  Deleting turns
out to be surprisingly complicated. There are also other pending things to 
delete on the SimpleElement, later. For now check in. 
This was version 75.

Implemented Finfo::isTransient as a test when deleting SimpleElements,
need to work out unit tests. Perhaps create a dummy Finfo or so and
have it do assertions when it is deleted. OK, done, works.
Checked in as version 76.

Some interesting ideas from implementing Neutral:
- Fields for parent, child (array type)
- Don't want Element::delete to be a message called from parent. Actually
	it should be called from self. And at this point the child operations
	involve 3 calls. Delete should be a single call.
- Messages visible as Element/Field combos, using node-independent
	representations of each.
- Global Element identifier? This comes up in context of parent/child fields
	Also makes sense for Python linkage
	Also makes sense for parallel implementation.
	Two possibilities:
		- Each node has vector indexed by id, for all Elements.
			Off-node Elements point to appropriate postmaster
			for resolution.
			- Fast to access # to Element
			- Need help to go the other way, or each Element stores
				its own index.
			- One ptr per Element. If we use lots of arrays,
				this isn't too bad. Otherwise, we may
				end up handling 1e9 Elements.
			- Not clear how to deal with distributed arrays.
				Possibly local ArrayElement would have to
				keep track of node partitioning.
		- Each node has one vector indicating message ranges and
			their node ids. Other vector handles local Elements.
			- Terribly slow to access, possibly need map for first.
			- Gets worse with greater node decomposition.
- Global Finfo identifier.
	Easy to implement for fixed Finfos. 
		Relative: Each class has its own, starting from 0.
			Needs first to look up object, then Finfo.
		Absolute: All defined fixed Finfos get their own id.
	Hard to do for transient Finfos.
		Has to be some form of relative indexing for each Element.


Immediate stuff:
- SWIG and parser working
	- Need Element heirarchy
		+ Need Create operation. Let's put it on Neutral
		+ Need Delete operation, discussed above. On Neutral
		+ Need getfield for parent, also discussed above.
			- This led to discussion of what is returned.
		- Need getfield for named child in order to get paths.
			- Assoc mem array Finfo?
			- Block messaging to and from it so no dynamic form?


Implemented several of the ops in Neutral. Created an Element::id().
Compiled. Yet to use and do unit tests.
Checked in as version 77.

=============================================================================
27 Jan 2007
The Neutral::create operation turns out to be pretty useless for in-code
use. As it is a RecvFunc call, it does not provide a way to return the new
Element. This may be OK if we have the 'el ^' equivalent command from
the script, but for in-code purposes it is a pain.

Need to work through use patterns for an Element id integer.

=============================================================================
28 Jan 2007

Analyzed the use patterns for eids. The bottom line is that they add little
to the internal computation of MOOSE, but they would be a useful
interface and scripting construct, especially as we go parallel. Here is the
analysis.

Uses: 	1. Unique parallel element id
	2. Persistence and changing data holders
	3. Interface: RecvFuncs and Elists

Alternatives:
	U1:	String path: Lengthy. Needs traversal.
		Elm ptr + node#: Ptrs are a bad thing to refer to across nodes.
		Not constant when object is moved between nodes.
	U2:	Fine for string path.
		Elm ptr approach would involve changing all references. Ugh.
	U3:	String path is fine.
		Elm ptr is ugly.

Use cases:
	1. Elists across nodes:
			- Value assignment
			- Message setup
			- Loops
		This is an issue somewhere between scripting and the shell.
		The shell would benefit from compact elists across nodes,
		if it could parse the job out between nodes.
		Arguably, the original wildcard is still more compact and
		can also be parsed between nodes.
	2. Handle for script languages
		Still need to get a feel for how SWIG would use it. Want to
		have elements appear with all their fields when referred to.
	3. Array elements: Do we have a unique id for each or treat them
		as a single one?
		This is an interface as well as costs issue.
	4. Messages sending element ids around
		No experience with this, but conceivably higher-order and
		algorithm objects might like this. Certainly cleaner than
		passing element pointers around.
		For example, the shell object might want to use eids instead
		of name strings a lot of the time. Of course, this complicates
		the internode shell commands which were hitherto using strings.

Level of exposure/API:
	- Don't bother for anything at the data flow level.
	- Use partially at shell level
	- Use extensively at script level, but no use for old GENESIS parser.

Problems and solutions.
	- Cost.
		Array form:
			1 big vector of element ptrs, indexed by eid. Off-node
			elements refer to other postmasters.
			Each element has its own eid.
			- Exorbitant memory use 
			- Especially bad if we have unique indexing for arrays.
			- Access is very fast.
			- Very simple.
		Range-bound tree:
			Each tree leaf has low and upper bound, and location
			for start, which could be an array index or node #.
			SimpleElements on a big vector, can use leaf
			info to compute their eids.
			- Very low memory use until objects start to get
			seriously shuffled between nodes. Unlikely to happen.
			- Would handle unique indexing of arrays very nicely.
			- Access log N, but tolerable if mostly contiguous.
			- Complex.

...........................................................................

With this in hand, move on to define the Shell object that the parsers
have to talk to.

One constraining requirement: Shells on different nodes must talk to each
other. Earlier we just passed strings so a single RecvFunc could handle all.
This is a bad idea because it puts a lot of parsing back onto the Shell.
Options:
	Massively shared message.
	Block form of regular message with distinct segments for data.

I think the massively shared message will work. Let the postmaster figure
it out.

...........................................................................
Another frequent issue: Finfos. 
- Could be global. Element independent fids. This would fail for
	local finfos such as dynamic ones or extended fields. Also,
	how would you deal with array finfo indices?
	- Dynamic finfos with same name could be picked up using 
	global fids.
	- Array finfo indices could be an optional arg.
	- In any case the script has to refer to the element at some point
	to get back the ids. But perhaps if it reuses them... Or does
	it use them at all times?
- Relative finfos. This means that all finfos with the same name have the
	same number (fid).
	
	Or I could stick with strings for finfos. They are short too.

For now stick with strings.
...........................................................................

Finally begun a bit of coding with Shell.cpp, to start to implement some
of these. The first step is path2eid and eid2path. Partly done.

=============================================================================
Jan 29 2007

Now need a function to return a vector of uints for message dest elements.
Will later need one to additionally return info about the finfos that
they target.
Since I'm doing all this in the Neutral, I want a systematic way to
pass in an argument (say a finfo name) and get back information. Something
like a value, but a looked up value. Or think of it as a get with additional
argument(s) to specify what to get. This is easy to composite as two
messages, one with the arguments and one with the return value. In other
words, a shared message.

How to implement. Shared Finfo needs a list of ftypes and where it is a dest,
of RecvFuncs. Perhaps use pairs, and src funcs could be dummys.
Need a composite Ftype for typing comparisons.

=============================================================================
Jan 30 2007

Many intermediate steps on the way to getting a functioning shell.

- Implemented SharedFinfo and SharedFtype
- Implemented Neutral::lookupChild
- Implemented set( Element* e, const string& finfoName, T val )
- Implemented set for zero-arg finfos.

Now it compiles and passes unit tests, but I haven't begun the many tests
that will be needed for checking all the above. Anyway, time to check it in.

That was revision 78. 
On other fronts: Niraj has successfully compiled and tested a somewhat earlier
revision on Windows. The main issue was that the RecvFuncs being passed in
were referenced directly, rather than using &funcname. A few other minor
fixes also done. Unit tests still work. Checked in.
This should be revision 79.
=============================================================================
Jan 31

Added in revision 80 with a little documentation.

Worked on unit tests for SharedFtype. Passed painlessly. Checked in as
revision 81.

Worked on unit tests for SharedFinfo. Very painful. Compiled, does not pass.
Lots of work to be done here. Checked in as 
revision 82.

=============================================================================
Feb 01 2007.

Begun unit tests. Initial error turned out to be in SharedFtypes. Fixed. Now
messages are formed correctly. Later error turned out to be bug in 
DynamicFinfo::match(connIndex). Fixed, clears unit tests. This means
that shared finfos seem to work. Checked in as
revision 83.

Two separate issues with handling all heirarchy and shell ops through
RecvFuncs:
- Looking at the Neutral, it seems like we need a way to move many of the
DestFinfos and even SrcFinfos off the default list, and only make them when
they are needed. Save us a lot of space.
- Many of these calls are multi-arg and require a return value. So
some kind of message is needed, the set/get commands don't work. So lots
of quick message creates and deletes.

=============================================================================
Feb 02 2007
One possibility is to use something like the get() function but with 
extra args. We will also have to ensure that the operations get passed to
the required node by shell-to-shell communication so that the get() is a
local function.

This enhanced get() would also help for array finfos. How would we 
set it up? Using 
bool getByLookup( const Element* e, const Finfo* f, T1& v, const T2& lookup )

OK, now how would we use it? 
- Could automatically set up as a SharedFinfo, much like triggers and 
data parts were in ValueFinfos.
- Avoid using DynamicFinfos for arrays. Actually arrays would be a good
test case.

=============================================================================
Feb 03 2007

Working on a LookupFinfo, done a version for LookupFtype.
Problem in the match() function. All is similar to the ArrayFtype but how
do we deal with the index in the match operation? We may have to refer it to
the Ftype to convert. 
- Or, we could permit exactly two types for lookup:
int and string. But we may want a continuous lookup: eg., lookup table.
- Or, just block the indexed match operation. This would eliminate all direct
accesses to fields, and insist that we access by lookupGet/Set or by
messages with an extra arg.
- Or limit it to types where conversions to and from strings have been defined.

=============================================================================
Feb 04 2007
Slowly working in the LookupFinfo and associated classes. Initial compile
worked and didn't foul up any existing unit tests. Now added LookupFinfo
unit tests and there are plenty of compile errors.

=============================================================================
Feb 05 2007
Marched through huge set of compile errors arising out of definitions of
LookupFinfo and LookupFtype and setgetLookup. Compiled. Cleaned up unit tests.
Works both for assignment and for ArrayFinfo style messaging to specific
index entry. But haven't tested yet for shared messages. Anyway, time now
for checking lots of stuff in.
This was version 84.

Now to go on to the shell and SWIG stuff, which is what set all this off.

Begin on unit tests for the shell. Usual croaks.
=============================================================================
Feb 06 2007
Really baffling bug in Shell.cpp::eid2path. Name being build up for path
is not getting set properly.
Turned out to be most likely due to some strange properties of the 
ASSERT macro set up using #define. Possibly the function was being called
multiple times in the macro without my realizing it.

Various other headaches, most fairly ugly. Anyway, now completed this small
set of Shell unit tests for create, eid2path and path2eid. Time to check
it in.
This was version 85.

=============================================================================
Feb 07 2007
Added le command to shell. This necessitated making a suitable function in 
Neutral to give an elist of children. Still not sure how best to tie this
into the parser. Anyway, checked it in.
This was version 86.

Now to tie in the two main parsers, SLI and Python.

Initial part of tying in Python went fine. But when I try to run it there are
issues with initialization of the root element. Trying to do it through
sttic initialization, but the ordering is not good.

Sorted out some aspects of initialization, and did Python test too. After
various fixes, seems to handle create and le within Python. Checked it in.
This was version 87


Now shifting over to SourceForge based subversion so that development
can be spread out more. The revision number there was version 27.
Checked in the past week of work, future updates should be smaller and
more frequent.
This was version 28.
Error in the Makefile for the genesis-parser subdirectory, didn't update
it with the rest in version 28. Checked in new version.
This was version 29.
Niraj tells me there were a few bad files sitting around in the DOCS
directory. I've cleaned them out. Checked in.

Now to tackle integrating the old genesis parser. The interface code for
the old MOOSE is in GenesisParserWrapper.cpp.
Key question: How should the shell communicate with 
	- other shells, e.g, on other nodes.
		Make regular messages, assemble in a big shared message.
		This will entail replacing the current functions in Shell.h
		with field-compatible functions. They will be used both
		in direct set()/get calls, and also in a big shared message.
	- Swig
		Currently we use a set of interface functions that
		accept string arguments. Could readily convert to integer
		arguments too. But it would be best to get inside the
		wrappers so that MOOSE objects look like regular objects.
		It would also be nice to have a SwigWrapper object that
		could talk politely to the shell via messages, the same
		ones that go between shells.
		Should be possible. See this page:
		http://www.swig.org/Doc1.1/HTML/Python.html#n6
	- GenesisParser
		This needs func( argc, argv ) format for all funcs. 
		But it often does ugly optargv stuff, so we will really
		want to have a separate set of functions here to call the
		reference ones for the Shell.
		We have an existing GenesisParserWrapper object from the old
		MOOSE. This could readily be adapted to be an object in 
		MOOSE07, and communicate cleanly with the shell using messages.

A related point: Should data output be handled by the shell directly
(to cout) or should it just be returned to the calling function? If so, how?

Discussed with Subhasis. It seems that the Shell should never handle output
itself, instead pass the data to the calling parser.

Also, many of the object hierarchy functions belong not in Shell, but in
Neutral. Shifting them there.

=============================================================================
Feb 10 2007
Interesting problem with static initilizers as I try to make the Shell into
a proper MOOSE object: The Neutral Cinfo is needed to make Element::root.
It is failing because it hasn't been initialized.

=============================================================================
Feb 11 2007
Nasty recursion issues with the static initializers. After much messing around
I have a system where each Cinfo is initialized using a static initializer
function, which is called both by the MOOSE object for that Cinfo,
and also by the static initializers for any derived classes.

There are a fair number of development lines now pending for the scripting:
- Getting integration with the GENESIS SLI.
- Getting shells to talk to each other
- Filling in more shell functions
- Implementing the id wrapper class for SWIG
	- Implementing Finfo parsing to generate SWIG/python class wrappers.


Working on GENESIS SLI. First issue:
Most of the funcs that get added to the parser vocabulary need to talk to
MOOSE objects. In the old code I had the parser include a field for the 
Shell and GenesisParserWrapper. Here I want to do it all using messages
from the GenesisParserWrapper. I have a bunch of void( * )(argc, argv, Shell* )
functions that get into the vocabulary. Can I eliminate the Shell*? Should I?
Each of the funcs needs ultimately to send messages and call setfuncs.
Note that for Python I just use the eids.
=============================================================================
Feb 13 2007.

Building the GenesisParserWrapper around the idea that it will be connected
to its shell by messages, and that the GenesisParser object knows the id
of the Element it is on. It needs this to pass to the various functions that
have to send messages around, especially to the Shell.

Now major cleanup to do on the GenesisParserWrapper to use the id and
messaging rather than the Shell pointer it had previously.

=============================================================================
Feb 14 2007.
About halfway through a very messy recompile of GenesisParserWrapper.

Getting close
Need a systematic way of finding the appropriate src/dest index, or even
better, for having them enumed by the name of the field.

=============================================================================
Feb 15 2007.

Managed to get compilation to work, still to test. Old unit tests are fine.
Will need a lot of cleaning up of src/dest indices.

Implemented biophysics/Compartment. This is really for Subhasis to go ahead
with an example class for the Python implementation. Should be functional,
except that it needs proper scheduling to work. Compiles, old unit tests
work, new ones still to implement.
Checked in to the SourceForge site. Now at revision 34.

=============================================================================
Feb 27 2007

Put in code to inherit finfos. Things fall apart here in several ways.
- The indexing of local fields is shifted. This messes up UnitTests.cpp:458
	and onward. Trivial.
- The numbering of messages just got even worse. I need to initialize
	some static fields with the message names so that I can send things
	easily. Either that or define wrapper funcs.
- There will be a proliferation of message slot requests. Most of these
	will sit unused but occupy space. Various measures:
	- Allocate slots only as needed. Always parent, not always child.
		Expand slot vector as message creation requests occur.
		- Ordering of slot vector needs to be so that common ones
		are sooner.
	- Many finfos, even src and dest ones, need not have default slots
		given. The finfos are used rarely so we can put in a finfo
		reference in the finfo array if needed. This is like messages
		to fields.

I have addressed the first two problems above. Unit tests were far from
trivial because indexing issues were everywhere. At the end of this we have
implemented two things:
- class inheritance and managing message slot access issues that result
- Generating a slot index from the finfo name so that the send() command
does not need to use hard-coded indices.


=============================================================================
Mar 01 2007

Resuming work on the genesis parser interface. Plan:
- Set up a shared message on Shell and on the GenesisParserWrapper.
	All the little funcs go back and forth through this
- Start with ce, pwe, le, create, delete.

Done first pass of implementation on the Shell. All these still remain to be
done on the GenesisParserWrapper.

=============================================================================
Mar 02 2007

Got Shell stuff to compile. Reveals an issue with the getSlotIndex: the
shared messages don't record names of individual parts of the finfo. Should do.
Checked current version in before going on to deal with the 
GenesisParserWrapper sending input to the Shell.
Checked in as revision 36.

Now dealing with GenesisParserWrappr.

Implemented GenesisParserWrapper side of parser message.
Compiled, unit tests OK, but not tested for specifics.

=============================================================================
Mar 04 2007
Working on getting SLI to be created, to talk to shell, and to run.

Did all of the above. Compiles and SLI is invoked. Currently the only thing
it does properly is to quit. le causes a core dump. Anyway, good time to
check it all in. Possibly some issues will crop up with the python interface.

Moving on to getting the functions to work, starting with le.
Ran into a morass of problems when trying to use sendTo. The issue seems to
be with the conn indexing. Introduced a whole bunch of unit tests for
the Conn::sourceElement and Conn::sourceIndex() functions.

Tracked down the problem: I was including both the Source and Dest vectors
in the counting for indexing of msgSlots in the shared message. Should have
used Source separately.
Many things now work: pwe, le, ce.
create sometimes works but:
- doesn't do Neutral (but does neutral!)
- doesn't do create neutral foo (but does create neutral /foo)
	- when we create foo, it puts a blank-name object in, it seems.
- doesn't create any object on anything but /
Most of these are now fixed.

Time to check in. 
This will be version 39

=============================================================================
Mar 06 2007
Delete works.
le looks at root element list if the specified path is not found
More generally, I need to implement unit testing for these functions.

Fixed le.
Implemented unit tests for GenesisParser. Set up tests for le, pwe, ce, create,
delete. This would be a good time to check it in, but I don't have net access.
For now, just copying the whole source tree into a temporary subdir:
mg3_rev40 because this would have been rev 40.

Continuing with the main branch.
Immediate goal is to get system to point where we can run the rallpacks,
preferaby a bit further so we can also run the Purkinje demo sans graphics.
This will also fit in with the solver code from Niraj.

Sub-goals:
- Parser upgrades: *echo, *showfield, *getfield, *setfield, *addmsg, *alias,
	reset, step
- New objects : channels, ca_concens
- Scheduling.

Working on getfield. This involves the implementation of string conversions.
strget is now working, but getfield is not.

=============================================================================
Mar 07 2007
getfield now works. Time to do another pseudo-checkin, which would be rev41.

On now to strset and setfield.

These now work and have been put into unit tests. Another psuedo-checkin, rev42.

Tried to echo the fieldList. Barfs. Fixed. It was a little problem with the
recursion in getting fields.

Also fixed problem of what to return when fields don't exist. Now it barfs
the same way GENESIS does.

Got showfield to work. Set up unit tests too. Time for another pseudo checkin:
rev43

=============================================================================
Mar 08 2007
Got the addmsg to work, but it does not go through the Shell. May need to
revisit later.

Got the alias to work. This is just an internal parser command.
Got listcommands to work too. This is also an internal parser command, easy.

Pseudo-checkin rev44. Now to put these incrementally onto the SourceForge
server. Incremental is best both for the historical sequence and to figure out
what happened if things break.

=============================================================================

Mar 10 2007
Begun work on HHChannel. So far only set up the .h and the Cinfo initializaton
stuff for the HHChannel. Some changes to the old mus variant of the HHChannel.
In the current version the channel has to handle its own process, rather than
be driven by the compartment. Compartment can jolly well wait for a new clock
tick to see what the channel had to say.

=============================================================================
Mar 11 2007.

First pass on implementing HHChannel. Compiled, all funcs in, but the unit
tests aren't done yet and nor is the HHGate, needed for HHChannel function.
Anyway, it goes through the regular unit tests and time to check it in.

=============================================================================
Mar 12 2007.

Working on HHGate. Two issues:
- Need to manage a couple of encapsulated Interpol classes. Would like to
use the automated inheritance of assignment operations, but the basecode
features for this do not yet exist.
- Need to work out how to manage initialization of the HHGate.
	- Have another bunch of messages from each Channel. This gets expensive.
	- Every time Channel fields are set, a new HHGate is created.
		- The HHGate is reused if the Channel is copied.
	- Do simple assignment on creation of HHGate. 

Dealt with idea for second issue. Now need to implement Interpol, test it,
and then come up with basecode features to let me put Interpols as nested
fields within the HHGate.

Implementation in progress...

=============================================================================
Mar 13 2007.
Implemented Interpol.
Done unit tests for Interpol. Somewhat painful, caught some unpleasant
and unexpected bugs. Time to check it in. Then we go on to incorporating
it as a component of HHGate.

Now working on NestFinfo, which was partially implemented a while back
and then dropped. We need it to implement the HHGate which contains 
two Interpols. Got the basics implemented, and it compiles. Set up unit
tests for NestFinfo, and those fail.

=============================================================================
Mar 15 2007
After much messing around with NestFinfo and related files, seems like the
best solution is to bypass the problem. Instead require that any nested field
look like a child element. The child element is almost the same as 
Neutral except that it may not be deleted directly, and it takes its
data value from the nested field.
Details:
- We create the HHGate. It has two Interpol objects nested in it.
- As soon as it is created, the postCreate function is called. For most objects
	this does nothing, but in this case it creates two child SimpleElements
	using the addresses of the Interpols as data.

We need now to have a callback when an object is created.

This is going OK, but it raises a problem in Cinfo::Cinfo because it requires
for the first time that we handle overriding parent fields with fields from
derived classes. Among other things, we need to match up slot numbers and this
turns out to be an absolute can of worms. Perhaps I should also guarantee that
overridden fields are type compatible.

Done this the hard way, added to all Finfos as a required function. For
several of them I need to shift to the .cpp.

Finally, all done, and we get the nested Interpols created with the HHGate.
Many changes done, time to check stuff in. That was revision 47. Now
we can actually go ahead with the channel stuff.

Starting on setting up the scheduling. On close examination, it seems 
like we don't really need the sched object. All operations should be doable
through calls to the jobs.
Slowly working out what happens with the ClockJob.
=============================================================================
Mar 16.
Very preliminary work on ClockJob. I am changing the ClockTickMsgSrc class
of previous versions into a much simpler TickSequencer class, which will
just send out appropriate messages to the child ClockTics rather than 
manage them directly. Lots of changes need to be set up together.

=============================================================================
Mar 17.
The earlier version used a separate class to juggle the sequence. I think
this can be done using regular messages and the clock ticks themselves.

Slow grind through implementation, long way yet to go. Should be able to do
a dummy compile soon enough.

=============================================================================
March 18, 2007
Implemented first pass at ClockJob and Tick objects. Compiles. They are each
about 80% complete. I have restructured the earlier rather complex and 
specialized scheduling code to use distinct objects and clean messaging.
It is still a bit commplex, but no more than the algorithm demands.
At this time I don't need the Sched object at all, a Neutral will do.
Next stages:
+ complete the sorting and message set up in the Clock Job
+ complete unit tests for the scheduler
+ Implement the SLI drivers for the scheduler: setclock, useclock and so on.
+ Unit test for biophysics objects.
- Connect scheduler up to biophysics objects, unit tests for action potl

=============================================================================
March 21, 2007

Next stage implementation of ClockJob. This time I put in the sorting of
ticks. This involves deletion of messages, which turned out not to have
been implemented yet for Finfos. So I went to all the Finfos and did
the implementation. This required that Elements handle the four Conn 
access functions: connSrcBegin/End and connDestBegin/End.
Compiled, no unit tests yet.
This was checked in as revision 49.

Put in a utility function Neutral::create for creating objects.
Fixed some bugs in the recent implementation of the dropAll in several
of the Finfo.cpps.
Further work on implementation of the scheduling.
Implemented and passed unit tests for scheduling.

Checked in as revision 50.

=============================================================================
March 23, 2007
Implementing the SLI drivers for scheduling. The useclock function requires
the use of Finfo::numIncoming and Finfo::numOutgoing. So another round
through all Finfos to implement these functions.
Then another pass through the GenesisParser and Shell to set up the 
function calls. Still a few loose ends, but the existing unit tests pass.

=============================================================================
March 24, 2007.
Checked in. This was version 51.

Need now to implement wildcarding so that the useClock function can be
implemented. Where does it go?
GenesisParserWrapper: 
	- Syntax is not really consistent for other parsers.
	- But it may be useful for other parsers, though syntax may change.
Shell:
	- Accessible to all parsers
Neutral:
	- Accessible to all developers as a generic function. Will we need it
	in other, non shell/parser code?

Put it for now with the Neutral.
Did cleaning up, remarkably little, of the old mus version of wildcard.cpp.
I am currently at the wildcardRelativeFind function which is just before the
unit tests.
=============================================================================
March 25, 2007.
Now on to unit tests for wildcards. A particularly ugly bug appeared,
manifesting not in wildcards but in the genesis parser. Used valgrind, that
showed up an unitialized value in the GenesisParser structure. Miraculously
the problem went away when I initialized it. Valgrind rules!

Now I have a decent set of wildcard tests. One critical set that is missing
still is for field value comparisons. This needs a way for Ftype to do the
comparisons in a general way given the object and a string value. Later.

Another thing pending is to clean up the deallocation of the data part of 
objects. Later.

Checked in stuff as revision 52.

Connected wildcarding between SLI and shell.
Got the SLI drivers to work, some prelimiary unit tests on this. Can't complete
the tests till I have operations working to show messages.
Checked in stuff as revision 53.

Now begun unit tests for biophysics. Did tests for compartments, fixed
bug in compartment messaging in the process.

Checked in as revision 54. Some strange hiccups with SourceForge.

=============================================================================
March 27 2007.
Begun unit tests on HHChannel. Uncovered bug in basic message handling,
that manifested when all children were deleted and then a new one made.
Got to automatic construction and removal of HHGates depending on HHChannel
gating powers. Time to check it in.
Checked in as revision 55.

Valgrind again helped track down a problem, this time with argument usage
between HHChannel and HHGate. I am perhaps asking too much of the gate
function, and it should not be dealing with all this info. I will switch
the numerical integration from the gate back into the HHChannel. This
reduced the number of values being passed around too.

Did major overhaul to accomplish all this. Compiled, back into unit tests.
=============================================================================
March 28 2007

Got HHChannel and HHGates to talk nicely again, got unit tests for reinit
to work.

Checked in as revision 56.

Implemented the action potentials unit test. There is a small nagging
difference between the waveform on MOOSE and the original GENESIS waveforms,
but for now it is pretty clear that the basics work fine.

Checked in as revision 57.

Next: Build the plot object and then it should be possible to run something
close to the squid demo from the earlier version of mus.

Stages, rough order
* Table object to handle output from sim runs.
* Complete biophysics library: Ca concen, Nernst, SynChan, SpikeGen
- Cell reader
- HSolver
- Parallel stuff
- Python pass 1
- Kinetics library
- Dumpfile/kkit read
- Stimfile read capability
- OB sim capability
- SBML read/write
- kinsolvers: ODE, RK5, LSODA, G1, mixed, smoldyn
- Stoichiometry matrix ops: Stoich test
- FLTK graphics.


Compled table, it requires inheritance from interpol, and this is not
working.

=============================================================================
March 29 2007
Table compiles. On to unit tests.
Much effort later, unit tests cleared. Especially ugly because of the zillions
of options in the table class.

Checked in as revision 58.

Working on porting over the old moose squid demo. Numerous problems.
Fixed strSet/strGet for LookupFinfo.
Remaining:
- reset, step need to be activated in GenesisParser
- I need a plot object. The table is nice but does not have a way (yet) to
get values by requesting them.
+ I need to set up a return message from the table that would be used when
	INPUT was the message name. Goes and asks for values from fields.

=============================================================================
March 30 2007

Many updates to Shell and GenesisParser to handle reset, reinit, step, 
showclocks etc. Still does not work with squid demo. For some reason Vm
is not getting scheduled.

A bit of a diversion: Implemented showmsg, with the idea that it would help
me debug the problem with Vm. Fairly involved. Completes old unit tests
but the function itself barfs.
Now fixed. It is a big help. Shows that the Table Vm was indeed connected
up to t0. So why is it not saving data?
Also shows up some oddness in sched: Multiple messages going from
sched/cj to t0.start
Various oddnesses are present. If I repeat a useclock command it croaks.

Well, this is unsatisfactory, but I have made a whole lot of changes and
the old unit tests still pass, so I should check this mess in.
Checked in as revision 59.

=============================================================================
April 1 2007
Jokes aside, still struggling with the test script. I have now added 
further unit tests on the scheduling of different kinds of objects, and
there is no sign of the problematic behaviour I see with the actual script.
Anyway, check in these unit tests.
Checked in as revision 60.

Fixed one of the problem cases in the script.
Now it looks like there is a problem in the SimpleElement::connSrcEnd
function. It was not taking next_ into account but when I try to do this I get
another crash.
Valgrind reports other problems too.

Sorted out problem. The send function uses connSrcEnd to mean only the current
src, not taking into account the next src_ entry if any. I need a separate
function to get the entire list of conns.

Now to implement this alternate way of getting conns. Implemented
connSrcVeryEnd function that many commands should use instead of connSrcEnd.
This seems to have fixed problems with the showmsg command and also with
redoing resets after a simulation is run, and also with repeating the
useclock command. Valgrind is also happier.
The nan problems with the squid demo remain.
Turns out that the table filling was a failure. All entries were zero.
Just got confirmation that the DynamicFinfos for each table assignment are
not cleaned up: all 150 entries for the table were there, but all were zero.
Even when I reassigned them they stayed at zero.
Added another check in LookupFinfo.cpp unit tests, that is cleared. So it
is something in Shell or in GenesisParser.
Fixed: The generalIndex (a void* in DynamicFinfo) was not being set to the
appropriate type for LookupFinfo.
I need now to put in a check that the tables for beta do not get
too close to zero. If they do, then checks will have to be inserted to
avoid divide by zero errors.

For now a small check on the reinit.
And it runs! There is a minor hiccup with the step function using the time
argument as total time, not incremental time. Fixed.
Checked in as revision 61.
Next:
+ enable reuse of DynamicFinfo slots if they don't have messages.
+ Clean up DynamicFinfo: many functions are not used.
+ Get rid of ArrayFinfo.
+ Have freeing of index in DynamicFinfo on destruction.
+ Fix up deallocation of data in elements on destruction.
+ Implement GenesisParser conversion of old message types and table lookups
	so that squid demo can be identically run on genesis and moose.
	Keep this as a target for future sims.
+ Then, move on to Ca concen and stuff.

=============================================================================
April 2 2007.
Lots of cleanup work on DynamicFinfo, got rid of ArrayFinfo.
Checked in as revision 62.

=============================================================================
April 3.
Implemented two freeings: 
- Index of dynamicFinfo on destruction/replacement of the DynamicFinfo
- data_ fields of SimpleElement.

Unfortunately the latter does not seem to work. Clears unit tests but 
valgrind shows no difference in unfreed memory.

Now the destroy is being called, and we run into the double-free problem with
HHGate.
I will need to have two variants of thisFinfo on the Cinfo, one of them
having a flag to prohibit deletion.
I will also have to check for the thisFinfo flag in SimpleElement::delete.

OK, seems to work. Now valgrind finds 1089 /16797 non-freed blocks.
A closer look at the freeing of indices by DynamicFinfo. That too fails
and barfs.
Now that is fixed. But valgrind does not find any fewer non-freed.
Just for the heck of it, I went through and freed Finfos in the vectors
on the Cinfos when destroying the Cinfos. This made it 711 / 16797 blocks.
Some leak is still quite substantial, should track it down. Later.
Should check in but no internet.

Trying now to set up the squid test to run with GENESIS. Mostly there, but
getting nans. Once it works I'll work on parser till it can handle this
script.

=============================================================================

April 5.

Implemented a script for doing the squid demo in GENESIS. It is called
squid_gen.g

Working through the genesis parser backward compatibility to get it to read
this script in. First implemented the message and class conversion.
Currently it handles the table assignments and TABCREATEs for HHChannel.

An issue with the messaging from fields to shared messages such as the
inputRequest of a table or the plot of a graph object. The ValueFinfo
does not seem to recognize it. Turns out it is because the dynamicFinfo
does not know how to handle shared messages as a source. Need to implement.

Checked in as revision 63.

=============================================================================
April 6.
Got the Shared msg from DynamicFinfo to work.
Checked in as revision 64.

Now the only obvious thing remaining for the squid_gen.g to work in MOOSE is
the tab2file.

Did a quick and dirty hack for the tab2file. But there was another issue,
because MOOSE had confusing naming for the inject field and INJECT message.
Sorted that out. Now MOOSE runs the squid_gen.g script too.
Checked in as revision 65.

Implemented CaConc. Unit tests in progress. Done.
Checked in as revision 66.

Implemented Nernst. Unit tests in progress. Done.
Checked in as revision 67.

Implemented SpikeGen. Unit tests done.
Checked in as revision 68.

Working on SynChan. Implemented field part.

=============================================================================
April 7
Implemented most of the rest of SynChan, but its interface requires a rethink
of the channel interface.

Channels in GENESIS and in the current MOOSE design use a separate channel
message and process message. The merit here is that the flow of info is staged;
there are no return messages.

Channels in the earlier MOOSE had no process message. The channel message
triggered their calculations, which went back immediately in a return message.
The merit of this is that it eliminates a lot of extra messaging: speed and
space both. In principle this would also be good for a solver based 
calculation. 
An issue is the handling of CaConc. It may have multiple Ca channel inputs,
so it has to have a Process message to schedule its updates and assignments
of channel values.

For now: stick with the GENESIS compatible design. Fancy stuff is for the
solvers. Later if the return messages from channels look useful we can
change.

Made fixes, but now that I'm into unit tests I find that there is an issue
with the managing of the synapses_ vector. This really needs to be updated
as soon as a message is added _or_ dropped. The clean way to do this is
to equip the DestFinfo (or a derived SynFinfo) with a callback to manage
SynFinfo on the add and drop functions.
For a first pass, trying to set up unit tests for SynChan. Still stuck.

=============================================================================
April 8
For now we'll implement the non-deleteable SynChan. That has passed its unit
tests.
Checked in as revision 69.
That is it for the basic biophysics. Now to get some compatibility fixes in,
leading into readcell capability and the hsolver.

Trying out the original GENESIS squid demo. Of course tons of barfing, but
let's incrementally fix things up.

- Implemented element_list (aka el) command in the parser.
- Tried to implement addtask command as a feed-in to useclock, but this
	cause an assertion error. Tracked it down to the use of the
	form 'CLASS=' in wildcards. There is still some fragility there,
	but fixed for now.
- Cleaned out assorted objects left lying around in the object tree after
	unit tests.

Currently there are 190 errors when I run the original squid demo.
Many of these are simply missing object classes.

Checked in as revision 70.

We now need to implement the copy function. It should be easier and faster
than the old variants, because we use very few pointers. I think the following
should work:
- Copy all SimpleElements without assigning parents etc.
- Duplicate all the DynamicFinfos.
- Recreate their data and copy the values
- Build a map of all the new vs old element ptrs.
- Do a simple copy of the Conns, MsgSrc, MsgDest vectors.
- Go through all new Conns replacing old with new ptrs.
- For all off-tree messages, add a connection to the appropriate src
	and tie up (if in halo mode) to the new tree. Otherwise drop these
	connections (current behaviour.)

=============================================================================
April 9.

All this copy stuff implemented and compiles, not yet tested.
Also implemented the GenesisParser and Shell interface to do it.
Confirmed that it does not yet work. But the old unit tests do work, and enough
changes have been made to require a checkin.
Checked in as revision 71.

Some progress. Various unit tests set up, but the proper copy syntax is not
complete yet.
Much struggling later, turned out that the problem was a really subtle one
where when I used the default constructor T( T ) it bypassed the necessary
Element::Element constructor that set up the ids. Fixed. Added into 
unit tests. Unit tests passed.
Checked in as revision 72.

=============================================================================
11 April 2007
Begun work on cellreader. Trying to compile.

=============================================================================
12 April 2007
OK, compiled in this very skeletal form.
Preliminary variant of readcell works and sets up compartments and their
messages.

Bleargh. Another hour of fighting with subversion/SourceForge. Again SF had
messed up the commit. It is quite a pain to fix things up later. The best
solution seems to be make a backup copy, do an svn revert -R, do an
svn update, and then fix anything still pending.

Now to tackle the compartment parameters.
1. Dimensions. Simple option is to provide xyz coords for compartments. 
This is assumed by a huge range of functions, too.

Did this. The test cell is now the venerable mit.p from my thesis: 286
compartments. Reads in the coords correctly and assigns passive properties
correctly, in at least a couple of the compartments at either end of the cell.

Checked in as revision 74.

=============================================================================
13 April 2007.
Let's try to get the channels in.

Channels are connected in but not set up properly. At least part of the
problem is that MOOSE is not correctly handling all the exotic functions
used to set up channels in standard GENESIS simulations.
Began to implement some of these: setupalpha, setuptau.
Also fixed sundry bugs that crop up as we use the system in new ways.
Checked in as revision 75.

Implemented setupalpha and setuptau. Some table values are now getting
filled.
Checked in as revision 76.

Evidently the shared table code is not working either. The messages that
should tie all the HHGates to the prototype do not form. Instead, at least
for K_mit_usb, the HHGates are duplicated on each channel.


=============================================================================
14 April 2007

first priority: Get the axon to work. Incrementally working through error list.
- TABFILL call now works for channels.
- many aliases are now defined in the .g
- The addalias command is implemented
- The ^ shorthand for recently created elements is implemented.
- Bug in setupAlpha fixed.
- various bugs in the test_axon.g file fixed.

At this point the axon simulation gets set up (using vast amounts of memory,
because all tables are duplicated) but it does not work.
Checked in as revision 77.

Looked at graph curves. Clearly the graphs are not displying correct ss
value.

=============================================================================
15 April 2007
I had not implemented the tweakalpha and tweaktau functions, except as 
dummies. Now I have tested the curves for the channels in GENESIS and
MOOSE, and they match except that GENESIS does use spline smoothing to
set up the curves. There is a glitch in Na_xb.plot in both as well, and I
am tracking it down. It is at -15 mV. The glitch adds exactly the value of the
A curve to the already summed B curve.
The channel set up uses only the setup_tabchan (setupalpha) function.
Fixed the bug.
Fixed the current injection. Now I get action potentials with the 
test_single_compt.g simulation. Hooray!
Also get action potential propagation with the test_axon.g simulation.
Another Hooray!.

Checked in as revision 78.
Looking back at the roadmap from March 28. We now have 3 items under
control. I should add another one, to streamline the use of global objects
like the HHGate. Also a better way of doing function lists would be nice,
to avoid the huge overhead we currently have.

Stages, rough order
* Table object to handle output from sim runs.
* Complete biophysics library: Ca concen, Nernst, SynChan, SpikeGen
* Cell reader
+ HSolver
+ Parallel stuff
+ Python pass 1
+ Kinetics library
- Dumpfile/kkit read
- Stimfile read capability
- OB sim capability
- SBML read/write
- kinsolvers: ODE, RK5, LSODA, G1, mixed, smoldyn
- Stoichiometry matrix ops: Stoich test
- FLTK graphics.

First, a list of fixes that are pending to the messaging system as we
may have to tackle them for the solver and parallel messaging:
- Wasteful implementation for multiple functions in a message using
'next' in the MsgSrc. Problem is that different messages need different ranges.
But the distinct functions of shared messages do not, so they should not be
in different ranges.
- Wasteful pre-allocation of MsgSrc and MsgDest arrays. Can we have them
set up just in time? Can we even set the rare ones on DynamicFinfos?
- Cinfo has a thisFinfo and a noDelFinfo to represent objects where the
	data part should not be deleted. Perhaps this should be a different
	Element class. Option in Create? Better an extField.
+ Copying of prototypes should be aware of cases where the prototype is global.
	Perhaps this concept also applies to parallel prototypes.
	Again, perhaps a distinct Element class.
- Have all SimpleElement operations been put into Element as virtual functions?
- Traversal of messages back to source and through intermediate functions.
	Requires additional info in Finfos and some tricks in the traversal
	functions.
- Naming of functions in the SharedMessages so we can use a named lookup.
- Mapping of SynFinfo to synapse msg# index breaks down on deletion.
Also, some additions that will come up when we handle solvers and parallelism:
- Intercepting set/get calls when an object is solved.
	- Could use a replacement Element* 
	- Could use an entire set of replacement Finfos that forward the
	request to the solver.
	- Could just replace the ThisFinfo to intercept the solved fields
	in a generic way. It could actually handle the whole solver stuff,
	thus avoiding having to tread on any object-local code at all.
- Intercepting messages when an object is solved.
- Providing a dest function based on the calling Ftype in the RespondToAdd
	of the postmaster
- Intercepting all return messages when we attempt to go off-node.
- Intercepting cases where multiple messages go to same node, and having
	the divergence occur on the postmaster of the dest node.
- Handling sporadic messages like action potls, commands, object shifts.
	Need a table like a synapse, that keeps track
	of target node index for the sporadic message, and this plus any
	data is all that goes out. Target node index may have high fan-out.


In the meantime, a small step: Implemented move command.
Checked in as revision 79.

=============================================================================
16 Apr 2007
Small beginning to handling global elements (no copies, only dup of msgs)
Using flag GlobalMarkerFinfo;

=============================================================================
17 Apr 2007
More small progress, implemented most of the functions for global elements
but still need to put them all together in Copy.cpp and to do unit tests
=============================================================================
18 Apr 2007.
The copyGlobal stuff turns out to be quite messy. Now I've set up unit tests
in Copy.cpp, and they are not clearing.

Finally tracked it down. I was appending Conns to the list when doing 
Finfo::incomingConn and outgoingConn functions. Should have instead cleared
out the list. 
Now: unit tests work. test_single_compt.g works. test_axon.g works, and using
showmsg I verified that all the messages point to the library channel gates.
Furthermore the memory use is quite respectable.

I realize that I should do away with the GlobalMarker, DeletionMarker and other
individual Finfos for setting flags. Instead the ExtFieldFinfo is just the
thing to provide flags and anything else. Later.

Some updates from Subhasis, but a lost #include was the only issue with it.

Checked in as revision 83.

=============================================================================
19 Apr 2007
Traversal for messaging. Time to set up virtual messages that represent
logical flow of information within an object. For example, process triggers
VmSrc.

Finfo has incomingConns and outgoingConns functions... fills up provided
vectors. Conn src and dest are current element. Conn index has to help us
use Element::findFinfo( unsigned int connIndex ) to lookup Finfo.

Sporadic messages: typically the commands from one shell to another.
Also action potls.

Note that each postmaster handles a specific remote node.
Here is the partick call sequence.
	0 Post irecv
	1 Tick calls process for outgoing objects.
	2 Post send out id and data together.
	3 Tick calls process for local objects.
	4 Poll for posted irecvs. As they arrive send out contents locally.

Here are the events on the postmaster.
0 Post irecv. Minor problem here because we don't know how much data is to
	come. Typically the main messaging will use lots of space so we can
	be reasonably comfortable with that size buffer. Otherwise we have
	to plan multiple cycles of sending till the whole thing comes.
1 Func arrives because of clock ticks reaching outgoing objects.
	Recvfunc and other type info provided by Ftype of source itself.
	For the sporadic messages:
	- Id of message is found from conn->targetIndex.
	- Id goes into one buffer, data into another. Increment position of
		second buffer by data size. The second buffer is dynamically
		allocated.

2. Post send. This happens frequently if no computation is being run,
	otherwise interleaved with lots of processing.
	- First 2 datums: # of messages and total size.
	- Then the two buffers are appended and sent off.
	- All nodes likewise.
	Repeat till done. This is tricky though.

3. Local process stuff: this does not affect the postmaster other than give the
	data time to flow.

4 Poll for posted irecv. When data arrives, Look up id. Call func. with args.
	For sporadic messages:
	- Check identifier. It points to a msgslot and an ftype to do data
		extraction.
	- Use function provided by ftype to extract correct # of bytes,
		advance pointer, and call correctly typed function on the slot.
	

At initialization time:
Here we need bootstrap the message addition process so that the inter-shell
messages get set up. Master node sends these messages to all other nodes.
Additionally, we may also need to set up fully connected messages between
all shells for handling independent message formation and data transfer
requests.

At message addition time:
	- Identify src and dest nodes
	- Check if same field is a msgsrc to this node.
	- Now we are on src node.
		- query message to check clock tick and if they are sporadic.
		If sporadic:
		- From src node, the respondToAdd function on the postmaster
		must convert ftype into a string to send over. Assemble
		this string, target id, target finfo, and clock tick/sporadic
		flag. Assemble into a message and send this data over as 
		above.
		THIS IS NOW ASYNCHRONOUS. WE DO NOT WAIT FOR AN IMMEDIATE
		RETURN. SEE ABOVE FOR CALL SEQUENCE
		- The recvFunc for this message creation message does checking
		- If all is OK, it builds the message on the far side.
		- It sends back a message with status and any shared message
		requirements.
		THIS COMES BACK WHENEVER THE NEXT TICK OCCURS. PERHAPS MANY
		ARRIVE.
		- The recvFunc for this completes the checking and does the
		setup on the originating side
		- recvFunc may also trigger a flag to tell the scheduler?
		parser? Shell? that the message addition is done, and certain
		operations that were held up can resume.
		This is important if there is a script dependency on completing
		the message. We'll need to establish which functions are 
		permitted in the script. There was a polling function in 
		the earlier version which served this role.

Handling return requests:
	- Identify any messages that are return messages; check if they
		are permitted variants.
		- Ones attached to globals. Here the global should be 
		duplicated on the remote node
		- Non-globals where the message must be instant.
		Here we should flag an error.
		- Non-time-critical returns, e.g., plots. Here we assign
		the return message the same tick as the request by following
		through the dependencies. It will be a timestep off in the
		display, not critical. Could even be corrected post-facto.


.............................................................................

Working on setting up the skeleton of the compilation and the postmasters.

Compiles.
=============================================================================
20 Apr 2007.

Got the initial skeleton code for PostMasters to work, verified using MPI.
Checked in as revision 84.

Set Makefile flags back to non-MPI version to make life easier for other 
developers.
Checked in as revision 85.

Starting on impementation of ParFinfo, though perhaps this should be 
ParFinfoDest. Another set of classes for ParFinfoSrc and ParFinfoShared.

=============================================================================
21 Apr 2007.
Worked out roughly how to handle the actual parallel data transfers.
The approach does not care if the messages are sporadic or scheduled.
It makes one key tradeoff: Puts the target index in each message. This would
be needed anyway for all sporadic messages. At the dest end all it needs is
an array to lookup the target index and return the Ftype* of the attached
message. I could go one indirection less by returning the parIncomingFunc
of the attached message.

The other option is to use a more rigid addressing scheme to get each
datum into its place for scheduled messages. This would require additional
storage for addressing at the sending end, but would use less data for
transfer. Sporadic messages would not benefit. Time about the same.

From benchmarks, bandwidth rises (but sub linearly) with message size. That
means that doubling message size does not quite double message time. There
is also a latency cost, which again does not quite double with message size.
Up to about 256 bytes it is almost flat.
We are talking about 10 usec for 1 K, and 41 usec for 16K. 100 usec for 65K.
For 100 molecules, we go about 10-100x real speed, say 1 msec dt. So we do
a calculation cycle in about 10 to 100 usec. If all of the molecules
diffuse, we need to send 100x12 bytes each way. Here we are about balanced
comm:comput in the worst case, and very comfortable otherwise.
For 5000 molecules we would have a linear scale in comput time, say 500 to 
5000 usec. Communicaton is now 60K bytes, taking ~100 usec.
So the communication is comfortable to interleave, even if we use a faster
solver.

=============================================================================
22 Apr 2007.
An issue here: our sendTo index may not agree with the index given to the
message from postmaster to dest on the target node. The reason is that the
outgoing index is set up so that the recvFuncs are ordered.
Options:
	- Another lookup table for the sendTo index
	- Munge the outgoing function so that all the targets are on the
	same MsgSrc slot and with the same sendTo index as at the originating
	postMaster, but they each have to store their own recvfuncs.

Here is how it works (assuming all messages set up, not worried about sched
at this stage)

- Regular object Send invokes the Ftype1<T>::parOutgoingFunc (or equiv)
	which comes from its own Ftype.
- This calls getParBuf which steps through the parallel outgoing
	buffer and returns the location for value assignment.
	The parOutgoingFunc does typecasting and assignment.
- Outgoing buffer has Nitems, id0, data0, id1, data1...
- All the data gets shifted over to the remote node.
- Postmaster loops through arrived data buffer. id<n> looks up dest Conn
	as well as a templated Ftype::parIncomingFunc.
	VARIANT 1: Regular msging.
	- parIncomingFunc calls the appropriate sendTo<T> function and typecasts
		the data.
		- Advantage: Regular messaging calls for setup.
		- Disadvantage: 
			- Message ordering does not match. Another lookup 
			needed between id and targetIndex. Need to maintain.
			- Terribly slow if we use regular func/msgIndex
			lookup for SendTo.
			- Extra cost of all the MsgSrc entries for different
			dest recvFuncs. We are not using the extra info.
			Unless we do something clever with it for the 
			scatter msgs.
		- Scatter msgs: Extra info in lookup, but it would be a 
		messy iterative call of multiple SendTo.
		- Each message needs:
			Conn: from regular array
			MsgSrc data structures: 3 uints, one RF*, one Ftype*
			Conversion table for lookup of targetIndex from id.
			Further field in conversion to handle scatter.
			Every scattered target needs all but the MsgSrc.
	VARIANT 2: Special msgs. all conns in one big MsgSrc slot, separate 
		recvFunc array for dests.
	- parIncomingFunc is passed the recvFunc, typecasts it, and
		calls it with the Conn.
		- Advantage: Cleaner call sequence. Less indirection.
		- Disadvantage: Unusual messaging. Will need special 
			handling for add/drop
		- Scatter msgs: Flag pointing to range of targets. 
			Rather simple handling of multiple target types.
		- Each message needs:
			Conn index, RF*, Ftype*, scatter::next

	As an alternative, we could just do scatter messages by many 
		explicit connections through the postmaster.
		would be very costly in highly connected networks.
	Or put a fan-out object after the postmaster. Hard to manage.

	VARIANT 3: Use the MsgSrc array as the lookup, with the Slot being 
		given directly from the id (possibly with offset so regular
		messages can live safely below.).
	- parIncomingFunc calls send<T> and typecasts the data
		- Advantage: Almost regular messaging for setup. But some
			redundancy in use of MsgSrc as indices now match ids,
			not unique functions. 
			- Fast.
		- Disadvantage:
			- Memory cost of MsgSrc builds up if lots of unique
			targets.
		- Scatter msgs: Handled cleanly in MsgSrc using existing code.
			Very economical and fast if high scatter.
		- Each message needs:
			Conn: from regular array
			parIncomingFunc array
			MsgSrc for each unique id. Good for high scatter.
			Some cleverness in doing this variant of MsgSrc
			management. Actually the insertConnOnSrc seems to
			do this absolutely painlessly. Only issue is
			MsgSrc size management.

Variant 3 seems neatest, provided I can cleanly deal with the MsgSrc 
management.

.........................................................................
Finally, after much planning, now down to the implementation.

- Implementation
	- Set up the Ftype code
	- Set up ParFinfo
	- Set up add/drop code.
	- Set up ParTick
	- Set up message transfer ops
	- Set up bootstrap

Ftype coding done. This has involved setting up the appropriate functions
for the base Ftype0, Ftype1, Ftype2 and Ftype3. Also several serialization
functions that give us quite a bit of generality including for transferring
vectors and strings.
Stuck on compiling SharedFtype, but it is mostly grinding through the
steps now.

=============================================================================
23 Apr 2007.
Compiled. No new functionality, but the hooks are there for parallel
messaging to be set up.

Checked in as revision 86.


=============================================================================
24 Apr 2007.

Almost all the pieces in place now. Remaining:
+ ParTick
- Clean up postmaster funcs.
- Set up Shell-postmaster messages.

=============================================================================
25 Apr 2007.

Further work on PostMaster.
Implemented ParTick. 
Compilation time.

Checked in as revision 87.

=============================================================================
26 Apr 2007.

Incorporating ParFinfo into the compilation.

Working out how to handle the issues of insufficient information in the
current add and respondToAdd argument lists.

	add( Element* e, Element* destElm, const Finfo* destFinfo )
	respondToAdd( Element* e, Element* src, const Ftype *srcType,
		FuncList& srcFl, FuncList& returnFl,
		unsigned int& destIndex, unsigned int& numDest )

Additional info needed: 
	- id of the target element.
	- Name of the target Finfo.

These are available at the point where the script call happens.
They are lost when we call 'add', because it has to go to the postmaster
(not the dest) and to the 'data' message (not the dest Finfo).
The 'add' function is ubiquitous and we don't want to mess with it.

Solution 1:
	Implement a variant on add for all Finfo classes. Ugh.
Solution 2:
	Provide a wrapper element e, generated on the fly, that
	stores the id and destFinfo name, but provides a handle for
	the originating element to use its regular 'add'.
Solution 3:
	Likewise, but with destFinfo.
Solution 4:
	Generate a regular element on the fly, put some data in it with
	this info. Don't bother clever stuff with OffNodeElement type,
	as all we need here is a handle and SimpleElement will do.


Set up something like solution 2. Still excruciatingly messy. 
Compilation nearly there. Implemented OffNodeElement to handle the extra
info that goes into the off-node messaging. Must remember to delete the
OffNodeElement when done.
Still need to fill in stuff which puts the additional info in the 
OffNodeElement.

=============================================================================
27 Apr 2007.
Successfully compiled. Incorporated OffNodeElement and some updates to
Ftype classes to handle function generation for messaging.

Checked in as revision 88.

Still much to be done, but we should have enough infrastructure to
send information between two nodes if the message setup is hard-coded.
Time to test.
- Confirmed creation of all postmasters.
- Failed trying to connect from object to postmaster.
	Two issues: 
	- Do we use MsgSrc vector for all postmaster messages?
	Yes, because we need unique indexing. If we used that and the 
	MsgDest we'd have two sets of indices.
	- How do we handle its allocation?
	Should be safe just to do a resize or push_back when messages are added.

=============================================================================
28 April 2007.
Still need another fix to the messaging logic. We need a separate Conn from
each MsgSrc in a shared message to the PostMaster. This lets us assign the Conn
id to the destination MsgSrc id, otherwise there is ambiguity.
Then the MsgDest array becomes a mirror of the MsgSrc array on the recieving
PostMaster.

Tryign to compile. Looks like our 'off' element is being retained as a ptr
after it is deleted. I can really add a couple of fields to the postmaster
and accomplish much the same. Let's try that. Check it in first for reference.

Checked in as revision 89 

=============================================================================
29 April 2007.
Now using the PostMaster itself as the holder for the extra info when 
creating off-node messages. Just add a few fields. This lets us eliminate
the ugliness with a Union for Element* and node#, and also the OffNodeElement.

That works, or at least, it passes the limited initial unit tests.
Added a few more tests and it looks like the initial phase of parallel 
messaging is beginning to take shape.

Checked in as revision 90 

As a little side-project, finished implementation of Molecule, implemented
Reaction, compiled, yet to do tests.

=============================================================================
1 May 2007
Flurry of activity: I had checked in the kinetics changes, then Subhasis
checked in lots of stuff for PyMOOSE, and Niraj checked in his solver code
as a branch. Also my regular work laptop died so I will hold on for a while
about doing parallel stuff.
Some design thoughts about parallel stuff, lost with the laptop:
- Give all RecvFuncs an id. There are only about 10-20 per class.
- Pass MsgId, FuncId, data in internode messages.
- Note that if there are distinct target funcs for a given message,
  the FuncIds will differ. No need for further management of 'next' MsgSrcs.
- Don't use MsgSrc on dest node. Use a MsgDest-like structure, indexed
	by MsgId, and holding only the dest Conn ranges. Function is looked
	up by FuncId.
- When making a message, the originating node gets back 
- As before, a dummy RecvFunc is needed by the MsgSrc on the src node.
	We get this by querying the target Finfo for the funcId, and using
	it to find the appropriate dummyFunc (indexed by the same funcId).
	This dummy RecvFunc has the funcId hardcoded in (but I don't know
	how just yet) along with the type conversion stuff.
- In most cases this local query is fine, but we may have messages that
	use DynamicFinfos. Those have to go to the target node to get
	the funcId, and when the report comes back they are redone.



Anyway, I have just work on the enzyme class today. Almost there.

=============================================================================
2 May 2007
Enzyme class completed, compiled, not yet tested.

Checked in as revision 94

=============================================================================
4 May 2007

Implemented unit tests for molecules and reactions. 
Checked in as revision 95

Time to set up solver messaging now that Niraj has implemented the Hsolver.

- We'll intercept all calls to Finfos by having a replacement ThisFinfo.
	The ThisFinfo sports a set of alternate Finfos that are generated
	by the solver. These alternate Finfos are checked first and work like
	this:
	- get: first query the solver for the field value and bung it into
	the field. Finally the 'get' command extracts data from field.
	- set: do the local assignment then put the modified field into the
	solver.
	In both these, the solver provides replacement set/get functions
	- DynamicFinfos: same as set/get.
	An existing DynamicFinfo has its set/get replaced.
	- MsgDest. Here a function is called on the target object. Unless
	I mess with the Conns, there is not much I can do. Instead the 
	solver could extract relevant info from the object using separate
	calls. Issue is that this would require cooperation from the
	object, which violates the idea that solvers should be invisible to
	the object builder.
	Counter point is the synapse. Here the efficiency of the operation
	is pretty critical so we cannot afford extra calls to transfer data
	from object to solver. Somehow the original message should be 
	cleanly redirected to the solver.
	So the only solution, as considered below, is to go through and
	replace all the messages and their funcs.
	- MsgSrc. These can mostly be left alone. They will typically be
	silent, because the Process message is not called. Solver can
	forcibly trigger the remainder. A special case is return messages,
	but those mostly work through the dynamicFinfos.
	
func( const Conn& c, T value ) {
	static_cast< Obj* >( c.data() )->field_ = value;
or
	static_cast< Obj* >( c.data() )->func( value );
	
}

The func is stored on the src. We need to replace it and the target
of the Conn. 

// Note that this only changes the Conn part of the messaging. The
// functions have to be handled separately.
Conn::redirect( Element* newTgt)


// this is called for a field on the object oldE that is going to
// be replaced by newE and newF. srcFl is filled with functions that
// the newE provides to replace those from oldE. destFl comes back with
// functions that the original target wants us to call. Of course, 
// destFl could have been extracted from the original element.
// 
Finfo::redirect( Element* oldE, Element* newE, const Finfo* newF,
			FuncList& srcFl, FuncList& destFl );

Actually we just need to delete the old and add the new.

// Here is is how we would replace a destination func. Suppose we had an
// external ion channel to replace.
// Original:
void Compartment::channelFunc( const Conn& c, double Gk, double Ek)
{
        Element* e = c.targetElement();
        Compartment* compt = static_cast< Compartment* >( e->data() );
        compt->A_ += Gk * Ek;
        compt->B_ += Gk;
}
// Replacement.
void HSolver::comptChannelFunc( const Conn& c, double Gk, double Ek)
{
        Element* e = c.targetElement();
	Hsolver* hs = static_cast< PostMaster* >( e->data() );
	SolveCompt* sc = hs->lookupCompt( c.targetIndex() );
	sc->handleExtChannel( Gk, Ek );
}


Next step: Implement KineticHub and StoichMatrix classes based on the 
old MOOSE versions. The goal is to have something to code toward with the
solver code.

=============================================================================
5 May 2007

Working on Khub.
One level in: we want a ValueWrapperFinfo for solvers for use in the 
modified ThisFinfo of a solved object.

There is a single shared message between solver and ThisFinfo of solved
Element. This handles all the traffic for value set/gets, including any
messages through DynamicFinfos.
- Solver end has LookupFinfos for fields.
- The solver end of the SolverFinfo has an array of 
	- Field finfos. These use the Conn::targetIndex() to look up the
		field in the solver. The assignment call comes to them
		how?
	- MsgDest finfos. These are illustrated above. 
		Note that they behave very differently 
	- Rare MsgSrc finfos. These re
- The zombie end of the SolverThisFinfo has a matching array of regular 
	fields
	- (Q: what to do if the fields themselves are LookupFinfos?)

- We index the fields with an enum.
- We assume all fields are doubles. This also handles bools, ints, etc.
	In the case of other things like strings we need to have a
	separate mechanism. Hopefully rare.
- The ValueWrapperFinfo stores index and the original ValueFinfo from the
	class, and dips into its set and get funcs as needed.
	


=============================================================================
6 May 2007

Setting up infrastructure for kinetic solvers. Ported over most of the stuff
from earlier MOOSE, still need to complete the implementation of KineticHub.
It all compiles but no tests yet.

Checked in as revision 96

To test it: I'll set up a diffusion chain of reactions and load it into
the solver. Check: 
	+ loading, 
	+ creation of Stoich matrix
	+ Computing derivatives.
	- Add enzymes into system.
Then: 
	* Check variable extraction from the diffusion chain.
	* Check parameter assignment in the diffusion chain.
	* Check incorporation of existing messaging in the diffusion chain.
	- Check incorporation of new messages (readouts) in the chain.

Implemented unit tests for loading model into the Stoich class, and 
creation of stoichiometry matrix. Loads of bugs cleaned.

Checked in as revision 97

Implemented unit tests for computing derivatives. Sign fix put in RateTerms.

Checked in as revision 98

=============================================================================
7 May 2007

A little side-tracked as I prepare to set up messages to the KineticHub
preparatory to building the SolveFinfos. 
Worked on SharedFinfos so that they take regular Src and Dest Finfos as 
entries, rather than the TypeFuncPair which had insufficient info.
Fixed many Finfo files as a result.

Checked in as revision 99

Connected up KineticHub, messages succeeded. Now to do the zombie messages.
Hub has: 
For reactions: index for RateTerm, Element* for reacn.
For molecules: Vector of S and Sinit, elist of mols.


First pass at SolveFinfo meant to replace ThisFinfo on the solved elements.
All the required ops are handled skeletally. No compile yet. The
msgSlot stuff is untidy.

Still need to define a counterpart Finfo to the SolveFinfo.

=============================================================================
8 May 2007

Field access now working for zombies. Some initial unit tests done, but
more work required to make it general. The basic approach as discussed,
was to replace the 'ThisFinfo' with a SolveFinfo, and that intercepts
set/get calls for each object. Yet to handle messages or object
creation/destruction.

Checked in as revision 100

Generalized the field access stuff. Now working both for molecule values
and for reaction rates. 

Checked in as revision 101

Remaining:
+ Document it.
- Deal with enzymes
* Deal with existing messages.
- Deal with new message requests
* Deal with existing DynamicFinfos.
- Deal with changing mode of molecule
- Deal with changing mode of enzyme

But the core concepts are in place and working, and the rest is turning
the handle.
=============================================================================
9 May 2007
Cleaned up hub deletion: needed to get rid of SolveFinfos and put back
zombies. Also think about messaging.

=============================================================================
10 May
Slow wok on handling messaging. Most works but message doesn't.
=============================================================================
11 May
still struggling to find timeto work on message redirection. gdb reports
a problem on KineticHub.cpp:698
srcFinfos[ i ]= c.targetElement()->findFinfo( c.targetIndex() );
Something funny happens when the finfo is returned from findFinfo.
Valgrind it. No obvious mem issue found.

=============================================================================
13 May 2007
Finally got the message redirection stuff to work. 

Checked in as revision 102

=============================================================================
14 May 2007
Looks like for the DynamicFinfo all we need is to replace the set and get
funcs from the altered Finfos.
=============================================================================
15 May 2007
A closer look shows that it is not so simple.

DynamicFinfo --> dest: Here the DynamicFinfo must call a dest function
with a value it looks up using an access func. Here in principle we could
replace the 'get' access func.

DynamicFinfo <--> dest : Here we have the DynamicFinfo receive a trigger
from the dest, do a lookup, and call the dest recvFunc with its looked up 
value. Here again we could replace the 'get' accessFunc. The trigFunc is 
independent of access funcs and could stay.

DynamicFinfo <-- dest: Here we have to give the dest the accessFunc for the
origFinfo encapsulated by the DynamicFinfo. Have to redo the message.

A clean and comprehensive way to do all this is just to rebuild the dynamic
finfo by replacing all its messages. We already have a powerful func for 
doing this in the form of redirectDestMessages.

We might save a little setup time in the first two cases if we replace
the access funcs. But we would still need to do the redirect, so it would
be a messier coding solution.

OK, implemented the solution where we rebuild the DynamicFinfo completely.
Now to test it.

A bit stuck. The message claims to be formed but the value it gets is 
the unzombified value from the object. Redirection does not seem to be
happening, but the redirection function is called. It uses a very odd looking
Conn in the redirection.
More fundamental issue with getting values from zombie. Works at first,
but not later.
Ooops, lots of errors. I was doing an assert on dret=<num>
Should be ==.

Now that it is fixed, I'm still stuck at the same place. The second time I
try to do zombie field access I fail.

OK, I see it. In the second attempt at field acces, we are going through the 
DynamicFinfo because a message has been set up. This DynamicFinfo is confused.


=============================================================================
16 May 2007

Fixed up the implementation via DynamicFinfo. It had been looking up itself
instead of the Finfo provided by the solver. Now it works, passes unit tests.

Did a bit more work on the solver documentation.

Checked in as revision 103

Also added unit test to show that new DynamicFinfos, added after solver is
in place, correctly forward requests to the solver.
Checked in as revision 104

=============================================================================
17 May 2007
A little work setting up Enzyme unit tests preparatory to tying it to
the solver.
=============================================================================
18 May 2007
Partial implementation of Enzyme unit tests: Explicit enz. Barfs at the stoich
unit tests in TestKinetics.cpp.

Completed Enzyme unit tests for Implicit enz also, as well as switching
between explicit and implicit. Fixed bug in Stoich unit tests.

In the meantime several updates seem to have been checked in by Subhasis to
deal with the python wrappers.
Checked in as revision 108

=============================================================================
19 May 2007
Made logo.
=============================================================================
20 May 2007
Implementing SimDump feature. Compiles, not yet folded into operations of
Shell.
Checked in as revision 109

=============================================================================
21 May 2007
Cleaning up incorporation of SimDump into GenesisParser and Shell.
=============================================================================
24 May 2007
SimDump compiled.
Cleaned up really nasty parser bug for non-existent include files. Turned
out to be a double free.
Headache getting simObjDump count to match with the actual simUndump call.
Turned out to be a problem handling blank strings. Need a different separator.

OK, an intermediate fix: Earlier I was not including blank strings as valid
arguments. Now I am. Now it loads in and assigns values for molecules and enz,
and also looks like it sets up messages correctly. Time to check it in.
Checked in as revision 110

Working on separator. Now it handles arguments in quotes even if they
have separators in them.

Next issue: Handling the plot messages.
That done.
Next issue: foreach is not handled properly.
Also: Graphs do not save values. All values are nan.

=============================================================================
25 May 2007
Finally got a kkit model to load and run. Now to fix up the foreach and so
on for setting up the plots automatically so I can run any kkit model.

Fixed up the set command to set fields on multiple objects.
Successfully loaded up and ran all the simple models and the Kholodenko 
oscillatory MAPK model.  Plotting is still ugly.  Foreach remains to fix.

Checked in as revision 111

First pass on the Kintegrator. Trying to compile a framework.

Well, surprisingly the unit tests suggest it works first off, at least
with the Forward Euler default integration scheme. I need a testable
model to run here. Maybe something diffusive.
Tried out a 100-compt model with slightly faster diffusion. Still need
to test the decay curve against an exponential.

=============================================================================
26 May 2007
Checked in as revision 112

Trying now to examine entire set. This involved converting the free-floating
end molecule to a buffered one. This reveals all sorts of problems with
the Stoich and other parts of the solver.

Need to write out the solution scheme and redo.

Done. It turns out to be a simple matter of excluding the rows for 
buffered molecules. At some later stage this would be a good way to toggle
buffering. I have two buffered molecules now in the model, and it all
works. Also implemented a nice simple unit test for diffusion.

Now starting out on the GSL implementation.

=============================================================================
28 May 2007
Finally getting close to the GSL stuff. Some retrofitting needed on
Stoich.cpp, compiled it without the GSL stuff to make sure the old code still
works. Yes. Passes unit tests. Now on to GSL portion.

Also looked at CVODE. Fortunately it has the same functional form as GSL
for its core stepper function, which Stoich provides. CVODE also seems to have
parallel solver capabilities, something to keep in mind.

OK, GSL integrator works. Haven't really stretched it yet nor analyzed its
stepping patterns, but it passes the basic unit tests for 21-compartment
diffusion using rk5.
For the purposes of the checkin, I have compiled it without the GSL flags,
so as to preserve the plain vanilla version with minimal library dependencies.

Checked in as revision 114

=============================================================================
29 May 2007
Running through the various routines. Quite disappointing. Turns out that 
rk4 is often a problem due to excessively small dt. It seems to be invoked
within gear2 as well. Then, rk8pd gives too big an error. Surprisingly,
rk5 is nice and quick. Perhaps I need to relax the relative accuracy
criterion for the GSL...

Gone through the whole set:

rk2.Err=	3.24919e-07,	accRequest= 1e-06,	Copy:Call=   2455:4799
rk4.Err=	7.16957e-09,	accRequest= 0.0001,	Copy:Call=  10621:31790
rk5.Err=	5.49466e-06,	accRequest= 1e-06,	Copy:Call=   1131:3808
rkck.Err=	3.4423e-06,	accRequest= 1e-08,	Copy:Call=   2757:9605
rk8pd.Err=	7.513e-05,	accRequest= 1e-07,	Copy:Call=   2337:16310
rk2imp.Err=	3.71797e-05,	accRequest= 1e-06,	Copy:Call=   8513:25481
rk4imp.Err=	0.000347163,	accRequest= 0.0001,	Copy:Call= 105781:110877
gear1.Err=	3.78904e-05,	accRequest= 1e-06,	Copy:Call=  14638:73190
gear2.Err=	0.00025797,	accRequest= 0.0002,	Copy:Call=  75823:83406

Clearly, RK5 handles this kind of problem the best. RK2 is surprisingly good
too. RK2imp takes honours among the implicit methods. RK4 is surprisingly
bad throughout. A bit of optimization in the SparseMatrix will help
memory a lot and possibly speed too.

Anyway, let's check this in before fooling around with SparseMatrix 
optimizations.

Checked in as revision 115.

Now saved again, with compile flags set not to use GSL.
Checked in as revision 116.

Tried compiling with O3. Unit tests fail in a strGet call. When I patch around
that with a -g compile for the basecode, it compiles. After a few fixes 
in the unit tests it clears everything. I had intended to time the above
numerical integration calculations to compare with a proposed rewrite of
SparseMatrix, but the thing is too fast now for hand timing. Put in a
gettimeofday call and it comes to about 1.62 sec (ave of N=3).

Note that there are loads of spurious warnings with O3 about uninitialized
variables, even though they are actually OK.

Much messing around with SparseMatrix reimplementation. Now it works.
Recompiled with the O3, and ran it... Hooray, nearly 2x speedup:
0.88 sec (ave of N=3).

Some more cleaning up of SparseMatrix pending, but good to check it in now.
Checked in as revision 117.

Rearranged Makefiles to keep it easy for other users to compile without
GSL or optimization.
Checked in as revision 118.

Various levels of cleanup needed:
	- Simundump should work for bigger and harder models
	- Handle tables in kinetic sims
	- Automatic solver creation for simdump files.
	- Benchmark against old moose, esp for rk5.

Next major steps:
	- Parallelization


=============================================================================
31 May 2007.

Looking at overall structure for parallelization.
We have two kinds of data transfer:
Synchronous: Every time step, exactly same data, same sequence.
	Examples: Diffusion messages. Dendro-dendritic info.
	Requires: 
		- Call sequence matches conn sequence on remote node
		- MsgDest vector entry for each func.
		- Func/MsgDestIndex vector entry for each func
			( We can't merge them because of bidirectional msgs)
		- Some identification from ParTicks to the set of msgs to call.
		- Individual msg entries for multiple targets: single fan-out.
	Features: 
		- Minimal data transfer
		- Fast at the node level because func calls all grouped
Asynchronous: Random times, random orders.
	Examples: Synaptic info. Cross-node Shell commands.
	Requires:
		- MsgDest vector (also needed for bidirectionality)
		- Global Func management
		- Func id + msg index to be tranferred for each hunk of data.
	Features:
		- Arbitrary ordering, easy setup
		- Multiple fan-out on remote node.

Plan: Start with asynch. See how it works and design synch as needed.


Started. Implemented FunctionData class, got it set up to record creation
of functions used in ValueFinfo and DestFinfo.
We will have problems for the old-style (deprecated) sharedFinfo usage of
functions as those do not get initialized into the FunctionData.
Turns out that there are currently about 150 functions used.
I'll incrementally clean up.

Checked in as revision 119.

Started implementation with a simple extension of Element::element().
If the looked up element is off-node, it returns a postmaster and 
assigns the Id to a field in the postmaster for further processing.

=============================================================================
1 June 2007.

Stage 1 of parallel message testing: Get one postmaster to send info
to another. I have set up a dummy rawAddFunc in Shell, which will be 
triggered by a message from the postmaster. For starters, just see
if I can do this cross-node triggering step.
Along the way I converted Shell to use the new form of Shared Messages.
Seems OK.
Set up automatic creation of message between Shell and PostMaster at 
startup. This involved shuffling
initialization code so that a Shell is created by default on all nodes.
Earlier it was tied to creation of a GenesisParser. There will be implications
for Subhasis to handle, because the Python parser also creates a shell.
For general use I have compiled this without the parallel flags for checkin.

Checked in as revision 120.

Starting to run with ParTick talking to the PostMaster. Turns out that
I do need pretty continuous polling if the nodes are to keep up with each
other, even when no work is going on. Will need to work out a way to
throttle this on idle.

Currently the message to ask for polling doesn't seem to work.

Why are there 19 MsgSrcs on the ParTick? The pollSlot, which is the one we 
want, should have a slot of 14. Most of these are blank - much work to do
there.

Aaargh, got it. The slot lookup was referring to Tick, not to ParTick. Now
polling is OK.

Next:
- Implement a function on originating postmaster to take and post
	the command string.
- Implement a function on receiving postmaster to unserialize
	slot and function as well as command string. Send this to the shell.
- Implement originating function to take string from an 'add' operation.
- Perhaps do for other, more complex types than strings.
- Implement receiving function on shell to intepret add string and do it.
- Implement originating function to do the whole 'add' operationn.

=============================================================================
2 June 2007

Working on setting up the async call. Two issues.
1. The Ftype call has no way to internally specify identity of target func.
	Here again it would be nice to have functors.
2. We don't know identity of target func till we contact target node.
	2.1 We cannot even associate a Conn with a target func because same
	conn may handle many calls.
	2.2 In principle at 'add' time we have some idea, but it is compromised
	if there are dynamicFinfos overriding functions.
	2.3 We could initiate the 'add' on the target node, where the func is
	known. But doesn't work for shared messages, so we may as well do it
	all the same way and pass back the Func number.


Solution:
- All shared messages use a variant of the 'add' operation that unshares them,
	that is, assigns a separate Conn to each MsgSrc. 
	(?)We still permit sharing of conns between Src and Dest.
	Net result: Unique function identity for each Conn.
- There is a matching vector of RecvFuncs to the Conn vector.
- Sync messages use a variant of the serializer that just puts the values
	in the array.
	- Receiver marches through the Conn vector and matching funcs and
	refers to the sync data.
- Async messages use a variant of the serializer func that also sends the 
	conn index.
	- Receiver looks up Conn index from recvBuffer and uses it to
	find Conn entry and RecvFunc to apply. Marches through recvBuffer.

Some notes:
- I thought of a nice solution where buffer ordering allowed economical use
of a minimal Func array. Also good for speed. But buffer ordering is not
simple to set up due to scheduling complexity. Also interleaving of
funcs is likely.


OB: 256 nodes. 50K mit 5M gran. Say 20K per mit = 1e9 connections. Assume
	almost all are off-node. Then total usage = 
	outbuf space 	= NConn * 8 bytes.
	inbuf space 	= NConn * 8 bytes.
	Func ptr space	= NConn * 8 bytes.
	Conn space 	= NConn * 4 * 12 bytes
	MPI space	= NConn * 24 bytes.
	Synapse obj 	= NMit * nCompt * 48 bytes (negligible).

	= NConn * 96 bytes = 96 Gb.
	Total cluster capacity is 256 Gb. Somewhat alarming. However, if
	half of these are node-local then it is much better. Even more so
	if we do intelligent messaging on-node using shared memory.

Net result: The contribution of the func ptr usage is small enough not to worry.
Another important point: We _really_ want to use threading. It will be 
faster and save a lot of memory.

We can handle the postmaster func calls much more efficently like so:

template< class T, RecvFunc F > char* destFunc( const Conn& c, char* data )
{
	T arg;
	data = unserialize( data, arg );
	F( c, arg );
}

This template will need to be set up when we do the Finfo. Ugh.

=============================================================================
3 June

Alternatively have the Ftype provide the function using the stored Recv
Func:

char* ( *PostFunc )( const Conn& c, char* data, RecvFunc rf )
{
	T ret;
	data = unserialize< T >( ret, data );
	rf( c, ret );
	return data;
}

Trouble is, we now need to store both this func and the original RecvFunc
at the destination PostMaster. We could trade a bit of speed in and do:

pollFunc{
...
	for ( unsigned int i = 0; i < nMsgs; i++ ) {
		msgId =  *static_cast< const unsigned int *>(
			static_cast< const void* >( data ) );
			// the funcVec_ has msgId entries matching each Conn
		funcId = funcVec_[msgId]; 
		rf = funcData_[ funcId ].recvFunc();
		pf = funcData_[ funcId ].postFunc();
		data = pf( conn_[ msgId ], data, rf );
	}
...
}

where we instead store everything in the func lookup table and index it.

All of these have the issue that they bypass regular messaging stuff,
especially the MsgSrc vector. That is necessary because of the huge amount
of space used by MsgSrc.

Implemented all this. Many changes to Ftypes. Compiles. Now to start on tests.
Passes old unit tests. Yet to start testing data transfer.
Checked in as revision 121.

Now began trying to transfer some string data. Compiles but crashes on 
transfer.

Now got data transfer to work. Moderately fiddly, much work yet to do to 
generalize and clean up. Tested for 1, 2, 3 and 4 nodes. A small step here
but it finally sees us over a major hurdle.

Checked in as revision 122.

Solved problem with msgId overruns: The unserialize for strings was not
advancing the pointer by the correct size of the string.

Now onto the problem of setting up messages. I have simplified the test
case so that we send a simple message from data to the shell for the rawAdd.
Later I'll look into shared message targets.
After various changes and updates to the ParFinfo, it works. I create
a message from PostMaster::data to Shell::rawAdd, and I am able to send data
to the shell from a remote node. Works for 2, 3 and 4 nodes.

Checked in as revision 123.

=============================================================================
4 June 2007
Let's now see if we can send data all the way through via messages. I'll
make a table for each node. The local node table will source data to the
same numbered table on remote nodes. 

Set up this test. Seems like data is being transferred but it is
not arriving correctly. 

OK, problem seems to be mismatch between conn indices. If we use the same 
Conn vector for incoming and outgoing
msgs, we need to create both ends of the message at the same time.

Had to fix up mapping between Conns and FuncIndex.

Starting to work!!! Tested with 2, 3, 4 nodes. Now to put it into 
clean unit test form.

Much messing around later, it is mostly set up with unit test form.

Checked in as revision 124.

A bit of minor cleanup and compiler flag changes to get it to work without
the parallel stuff.

Checked in as revision 125.

Next step: Do the entire messaging from a single command that sends the
request to the remote postmaster to handle the remote message setup.

=============================================================================
5 June 2007
Issue with ids being passed in the rawAdd string. Something funny about the
targetId assigned to the postmaster.

=============================================================================
6 June 2007
Incremental progress. Shell.cpp is dumping core for some reason around
line 428.

=============================================================================
7 June 2007.
More incremental progress. Now I have some of the message requests coming 
through with all fields correct, and which could be used to set up the rest
of the message. The earlier unit tests are now problematic as they don't
work with the whole system. 

Another, perhaps bigger problem is that the system is too picky about 
message type matching. Once we've converted to string type info, I do not
know how to test for type equivalence when one is a derived class of the
other. One option is to globally register not the functions, but the finfos.
These have the advantage that they can be easily and globally specified
through the string className::fieldName.

=============================================================================
9 June 2007

Some fairly major steps to do:
- Replace the naming of sub-finfos within a shared message to shared:sub
* When passing type specification use baseFtype() func so as to have
	compatible field matches on remote node.

For starters, check current stuff in (including merge with Python stuff
from Subhasis). 
Checked in as revision 129.

Fixed up the type specification passing by implementing baseFtype().
Also cleaned up things a bit with the implementation of 
basecode::ParallelDummy to avoid having dummy definitions in an obscure place.
Checked in as revision 130.

Modified makefile to generate non-parallel version for more general developers.
Checked in as revision 131.

Various organizational things to get into parallel:
- Fix up Cinfos to automatically do scheduling.
* Return size of objects: data and msg parts.
+ Add a load estimation field to Neutral so all classes inherit it.
	Either that or put it in Cinfos. If it is public we can do more things.
- Fix up Finfos to provide internal msg info.
	- Add flag for whether MsgFinfo should allocate permanently or
	on the fly. If anyone uses the Slot then it may have to be permanent.
- Fix up Shared messages between nodes
- Connect up the main Shell messages.
- Fix up ParTick scheduling for resting and running times.
- Decide how to access each node.
	- Field on each obj.
		- Does it cascade downward?
	- /node1, /node2 etc: Ugly. Alternatively send into postmasters.
	- Enhancement of move command. But it doesn't tell about current obj.
	- Use a special shell command.

=============================================================================
10 June 2007
Minor checkin for fields for memory and CPU usage.
Checked in as revision 132.

More or less implemented SharedFinfo::addSeparateConns. Now need to implement
the converse, respondToSeparateConns. Alternatively I keep it one-way
because SharedFinfos can be handled either way.

Now successfully compiled, passes basic unit tests but not parallel tests.

=============================================================================
11 June 2007

Stepped through message creation process. The conns, and MsgDest arrays
at either end are being correctly handled. 
Problem in ParFinfo::respondToAdd. Doesn't talk nicely to SharedMessages.

Getting close. Some of the data is going across nodes OK, but there are still
errors. I'll check it in now because there are perhaps too many accumulated
changes.
Checked in as revision 133.

=============================================================================
12 June 2007
Need to clean up the alignment of conns in parallel messaging. Three
vectors need to be aligned:
FuncId
Conn on src
Conn on dest.

The problem is that message addition/deletion can renumber Conns.
One option is not to use absolute Conn indexes, but only those within this
DestFinfo. Then deletions of conns must be reported.

The place where the ConnIndex is assigned is:
	PostMaster::test ~595 where we send out strings directly.
	PostMaster::getAsyncParBuf where we pass the targetIndex into 
		innerGetAsyncParBuf.
	PostMaster::respondToAdd ~446 where we send out data for the
		rawAdd function on the remote node.
The place where the ConnIndex is read out is:
	PostMaster::innerPoll ~370 where we extract it from the string.
The place where the FuncIds are set is:
	PostMaster::addIncomingFunc which is called by 
	ParFinfo::add and 
	ParFinfo::respondToAdd

Let's use relative indexing.
This helps a lot. Also implemented a test function to confirm that the
connId system can handle multiple target funcs.
Checked in as revision 134.

Set up with non-parallel compilation settings for other developers.
Checked in as revision 135.

Fixed up some remaining bugs, cleaned up unit tests, cleaned up a lot of
cout debugging.
Checked in as revision 136.

Next steps:
- Adding the cross-shell messages. Or is it multiple msgs from parser?
- Managing Ids across nodes: 
	- After any create op (single or multiple) circulate a packet with info
	- Create stuff locally, assign temporary ids, then update.
	- Dish out id slots to nodes, and require new obj formed within them.
		Circulate update packet again.
		Or JustInTime: only if target unknown, get it from where?
		Or all nodes send info to master and update when needed.
		No creates allowed till new set of ids provided.
	- Do a preliminary scan of the request on the master node and decide
		how it is to be partitioned. Attach the id(s) to the request
		and update them locally. Only send the request to the specific
		target node. This gives a single point of reference for
		model creation decisions.
	- Have a single master id list on node 0. All nodes update it.
	- Create everything on node 0 and ship it out. Obviously silly.
	
- Complete inter-node messaging with duplicate of table test.
- Node-specific creation. Make some proto objects located on specific nodes.
- Inter-node copies
- inter-node move
- Test shared messaging with a reaction on 3 nodes
- two-level scheduling: setup vs runtime

=============================================================================
13 June 2007

Designing id arrays. The current plan for management is:
	- Do a preliminary scan of the request on the master node and decide
		how it is to be partitioned. Attach the id(s) to the request
		and update them locally. Only send the request to the specific
		target node. This gives a single point of reference for
		model creation decisions.

This means that master node can set up ids as it likes.
Slave nodes need to fill in the ids for their local objects as they make them.
The master node must provide the id to the slave node when it passes the
create request.
Whenever the master node issues a cross-node command to a slave (messaging
or object transfer), it must first provide info on node assignment for the
target, then the slave node gets the actual command.

1. All nodes have a vector of Element* for the ids. 
2. The master node vector is authoritative.
3. All unknown slave node ids point to the postmaster for the master node.
4. Node-id updates are sent as a vector of uints with a uint to identify 
	start of block. Such vectors are interpreted to put the correct
	postmaster* into the local id vector.
5. Global object creation requests are sent to all nodes. The resultant
	objects are locally present on all nodes but have the same id.


To start off on this process, I had to fix up the getSlotIndex so that it
uses sharedFieldName.subFieldName syntax. 
Various fixes done following this.
Checked in as revision 137.

Funcs needed from master to slave shell:
create( type, name, parentId, childId )

get( id, string field ) // getfield with string return.
getSrc( string )
set( id, string field, string value )


/These possibly could be done using several elementary steps. On the
other hand, the funcs already exist.
setClock( int clockNo, double dt, int stage )
useClock( id tick, vector< id > path, string func )
resched()
reinit()
stop()
step( double time )

listMessages
listMessagesSrc

copy( id, id, string )
move( id, id, string )

add( id, string, id, string)

Lets start with the first 4 funcs.

Need to make a Ftype4. Did so. Compiles. Passes unit tests.

Checked in as revision 138.

Now need to try out the master-slave messages and create special objects
exclusive to the nodes for starters.

=============================================================================
14 June 2007
A little stuck trying to make master/slave messages between shells across
nodes.
OK, got it. Here there are more dest messages than src, and the calculation
for # of slots for the shared message assumes otherwise. Problem is that
this works fine for regular messages, and it is only when we attempt
parallel messages that we lack the space.

Yup, confirmed that that is the problem. Did an ugly hack to allot more
space by a name comparison. Now it is stuck in the polling.

Thought the poll stuckness was due to the addition of the master-slave
messages. I was wrong. The poll is stuck even if they are absent.

OK, tracked it down. Something in the running of the previous unit tests
matters. I had eliminated the unit tests from all except node 0.

Doing resched and reinit of cj at the right place fixes things to where they
were, but the new master-slave messages still cause problems. This time
it is a core dump, something that can be managed.

Now things seem seriously adrift. I am not able to get the Michael Caine
message to go out. The kind of crash is dependent on # nodes. 

Tracked down one major issue: Because I am not doing unit tests on other
nodes, the id numbers (of lots of created objects) are out of sync 
between node 0 and others.

Now I've pinpointed all changes: Backtracked so we do all the unit tests
on all nodes. Backtracked the master-slave messaging. This version works
for 2, 3 and 4 nodes. Check it in as a reference point.

Checked in as revision 139.


=============================================================================
15 June 2007

Debugging in progress. Checking if message structure and functions are
OK. Seem OK so far. The FunctionDatas match.

Fixed the problem: I was not setting up the incomingFunc_ vector on the 
postmaster correctly due to bad calculation of conn indices.

Along the way I had to change the FunctionData so that it stores the Finfo
associated with the Func. This provides a lot of additional info.

Also had to update various objects to phase out the deprecated TypeFuncPair
for SharedFinfo, because the FunctionData only gets filled with the
new form.

At this point it passes tests up to 2 nodes. New problem: dies when creating 
the parser, but only if # nodes > 2.

Anyway, many files updated so it is time to check it in.
Checked in as revision 140.

Got the Master-Slave data transfer to work, but there is an issue with the
field recv func: there might be asynchrony. May need more identification info
to go back.
Still barfs for 3 nodes.

Turns out there is an unassigned conn coming up. When execution reaches this
the null Element pointer in it causes problems.
Next is to track this down.

=============================================================================
17 June 2007
Cleaning up stuff trying to track it:
- Fixed an unassigned field problem with the DestIndex in SharedFinfo::add.
For some reason it did not crop up earlier.
- Put in assorted assertions to test for empty Conn::targetElement().
- Replaced the deprecated SharedFinfo initialization of GenesisParserWrapper
	with the new version.

None of these helps. We still pass the 2-node, and barf at the 3-node
tests. The empty Conn remains. Anyway, check it in.
Checked in as revision 141. This checkin is to the new 'moose' site, 
switching over from moose-g3.

OK, tracked it down. The MsgSrc indexing of begin and end increments by one,
but there is a block of conns for the parallel dest that need to be skipped.
This also explains why it fails only for >= 3 nodes, when we have multiple
originating messages. 
For the 2 node case we have:
src_:   begin, end, next, func
11:     0, 1, 0, unknown func
12:     1, 2, 0, dummyFunc
13:     2, 3, 0, dummyFunc
14:     3, 4, 0, dummyFunc

For the 3 node case we have:
src_:   begin, end, next, func
11:     0, 2, 0, unknown func
12:     2, 4, 0, dummyFunc
13:     4, 6, 0, dummyFunc
14:     6, 8, 0, dummyFunc

and so on.
Other possibilities: 
- If we know the number of targets ahead of time (unlikely) we could
	simply assign blocks for each func.
- We could put each new target onto another slab of the Src, using the next ptr.

In the end, fixed it without messing with the MsgSrc. I realized I have to
keep the Conns sequential for each Func, that is, for each entry in the
MsgSrc. So the solution is instead to be a little smarter with how I
identify which Conns to use for successive funcs.

This works! One oddity is that all the nodes seem to be sending each other
slaveCreate messages, though the testMess function should only be
called for node 0. Anyway, this is a major step forward and needs recording.
Checked in as revision 142.

Figured out the problem. The response to the Get call, recvGet, has 
to be sent back to a message with a certain offset from the incoming
conn, because of misalignment of the matching src and dest fields. This offset
depends on the number of nodes. Horribly messy. Even if we sort out the
offset for return messages, other forms of sendTo will have a problem.

Offset was fixed by the simple expedient of advancing the 'get' call in
the Shell::master/slave to the first subField. The sendTo problem remains.

At this point we're ready to fill in the hooks for the Master/Slave
messages. Then we can begin on the list below.

- Set up node-specific Id handling
- Complete inter-node messaging with duplicate of table test.
- Node-specific creation. Make some proto objects located on specific nodes.
- Inter-node copies
- inter-node move
- Test shared messaging with a reaction on 3 nodes
- two-level scheduling: setup vs runtime


Did a reference checkin at this point with flags set for non-parallel 
compilation.
Checked in as revision 143.


=============================================================================
18 June 2007.

Need to manage ids. It will be a major pain to decouple all of the 
Element based code to do so.

Element creation: Here we need id assignment
Element::Element( unsigned int id )
( checks size of table and assigns it. What about the ones skipped? Refer
to node 0 for all slave nodes. )

~Element: Set id to zero, but the info also has to get to node 0.

Element::element( id ): Lookup element on id, no problems except that the 
number may be too high. Return 0 if so. Rename to Element::find.
If it is off node it assigns the target id into the postmaster and returns
the postmaster. Need a direct hook into the postmaster to do this faster.

nextId(): returns next id and expands id vector.
lastId(): returns most recent id. Only should work on master node.

All this could be low-level. The issue is where we decide which node
to use. Need NodeManager.

Begun work on it.
=============================================================================
19 June 2007.

Need to provide a user-level create function which insulates them from the id
business.
Need to provide low-level functions where id is specified. These are
dangerous as id may be occupied. Will need asserts.

Here is an instance where a create should happen on a remote node without
the master node supervising ids:
When setting/unsetting the explicit vs. MMEnz field on the enzyme object,
we create and delete an enzComplex object. What happens?

=============================================================================
20 June 2007
Need to backtrack a bit for the ids.
We need a scheme which combines per-node allocation of ids with master-node
assigned ids.
Furthermore, we need a flexible way to handle arrays so that the minimum
number of ids are used up. 

Refer to the DOCS/IDS section to see how I plan to implement this.

Done a first pass at the implementation. Now I need to go back, clean up
the Element::Element functions, prepare a checkin, and incrementally 
incorporate the Id and IdManager into the system.

Some second thoughts on setting aside ids for globals. It is really the 
job of the shell to work out what to do when an object is a global. 
For now let's try to get our first pass implementation working.

Need to bring in the ids, slowly working through compiles.
=============================================================================
21 June.
Slow plodding through files to put in the ids.
=============================================================================
22 June.

Some more thoughts on the ids. Rather than put all unassigned ids in separate
pre-allocated places, I can simply put aside a scratch area of ids for
local node use. This scratch area would be the same segment of ids,
say 1 to 1000. Whenever an id is needed externally the whole scratch set is
promoted to the filled set. Whenever the scratch set is filled, the whole lot
are promoted.

Moving ahead with implementation, compiling halfway through basecode now.
=============================================================================
23 June
Done basecode. Working on shell.

Finally the whole thing compiles, and fails to run even the first test.
Something bout Element::root in the static constructors.

=============================================================================
24 June.
Finally have a working compile and passing the (non-parallel) unit tests.
Way way overdue for a checkin.
Checked in as revision 146. Along the way Subhasis has done some 
	Pymoose checkins.

Got parallel version also to work. Finally we're back to where we were a
week ago. 
Checked in as revision 147, in parallel compile form.

Converted back to non-parallel compile form. Also converted a couple
of moose class specs from the deprecated TypeFuncPair form to the newer
Finfo* based form.
Checked in as revision 148, in non-parallel compile form.

=============================================================================
25 June.
Further cleanup of TypeFuncPairs. The biophysics directory is now clean.
Checked in as revision 150, in non-parallel compile form.

Further cleanup. The kinetics directory is now clean.
Checked in as revision 151, in non-parallel compile form.

Next I need to resume parallel coding. 
- Implement the ElementWrapper for off-node objects
- Implement an IdManager class so we can set node control thresholds.
- Devise a test case where after a certain number of objects are formed
	on one node, the next set get exported. Pass messages between them.
	This would first be the same table example I currently do in other
	ways.
- Do a serious test case involving shared messages, such as between 
	diffusing compartments.

=============================================================================
26 June
The wrapper turns out to be easy to do as a SimpleElement. Did so.

This is taking shape, but there are a couple of minor problems:
- ~Element zeros out the id if it is non-zero. We can't store our temp id there.
- ~SimpleElement expects a non-zero Finfo* in the vector. Need to put one in.

Set it up. Seems like we don't actually need postmaster pointer: the id
has it already. Compiles but dumps core.

=============================================================================
27 June.
Got the unit tests to work with the completed ElementWrapper.
Checked in as revision 153, in non-parallel compile form.

Tests failed in parallel compile. Tracked down to error in IdManager::childId.
Single node tests now work. Multinode tests fail.
Checked in as revision 154, in parallel compile form.

=============================================================================
28 June.
Various attempts to get the system to compile with O3 and to run. The 
compilation works with lots of error messages. The run fails because
of problems with template specialization. I find that the str2val and
val2str funcs fail to go to the specialized form.

Tried making a BaseFtype1< T > class in DerivedFtype.h. The idea was to
have this function set up a pure virtual reference to the get< T > function,
so the system would know for sure that it has to look for a specialized form.
Failed.

=============================================================================
29 June.
Trying to define the specialized functions in the original header,
DerivedFtype.h. Seems to progress, but it complains now about lots of
uninitialized variables (perhaps a different set from before).
ProcInfoBase* is the most common. Vector< double >* is another.
The good news is that it now compiles and runs with -O3, real fast.
It runs the kholodenko.g test too. We're in business.

Fixed ProcInfoBase* strconvs.
Checked in as revision 156, with -O3 compile flags.

Trying now to run the kholodenko simulation with the kinetic solver. It
is a long and ugly script to set things up for now. Setup happens but the
thing dumps core when we try to run it.

That was because I tried to call /integ reset. Now it works with a general
reset. But it gives flat lines for all molecules. Fast, though.

=============================================================================
30 June 2007
Working on the kinetic solver. The fast calculations were because there were
no calculations. The enzymes were not being set up. Now I have some progress
there but the output is not working. Also it is incredibly slow.
May need to redo the way I set up plotting.

Seems to go into the enzyme calculations, in RateTerm.h, but for some
reason it is doing the general rather than 1-substrate form, which is slower.
Was doing a -ve value.

OK, now it is much faster but still not seeing the waveform.
Checked that the numbers do seem to be changing with time.
Hacked in an alias for the conc field to look at n. Clearly it oscillates,
but the freq is wrong.

Ran it anyway, runs in about the same time as the old MOOSE: actually
about 10% slower. Perhaps fixing the MMenz calculation will help.
That also is almost the same time.

Need still to sort out why we have a mismatch in the exact solutions.
Anyway, we can compile and run all this, so time to check in all the changes.
Checked in as revision 157, with -O3 compile flags, and including the GSL libs.

Analyzing the discrepancy in output. It persists for all cases: mmenz,
enz. There are two aspects.
1. The first timepoint is already nonzero: some time elapsed before data 
	comes out. 
2. The reactions go too fast.

Point 1 improves, of course, if the dt is forced to be much smaller. Point 2
remains a problem.

rk4 is even worse.

Gear2 is spectacularly dreadful. In all cases, though, the time-course is
affected, not so much the steady states. Looks to me like I am misusing
the GSL integrator.

Yup. I was changing values in S_ used to calculate yprime. But S_ was also
used for the current value y_. Cost for fixing this is a whole lot of
memcpys. I think they are fast though.

This fixes the numerical values. Major step. I still have a memory leak
in the allocation of y_.

Now let's see how this affects the speed.
Marginally slower, maybe another half second - about 5%. The little check
I had put in for timestep doesn't seem to matter here.

So far so good. Let's try now to get our regular benchmark suite of models
to work.

acc4_1.6e-21.g loads. Runs 2x slower under new moose than old. I suspect
SUMTOTAL isn't working either.

Fixed SUMTOTAL loading into system.
Checked that it works OK at least so far as the default ee method goes.
Confirmed that rk5 doesn't handle sumtotals.
Looks like the default ee method does handle them. Also it is way faster:
takes 11 sec as compared to 23 for rk5. The ee method in Genesis is,
if anything, a bit faster at 10 sec. rk5 takes 12 sec in the old moose.

=============================================================================
2 July 2007
Working on completing functionality for kinetic simulations. Implemented 
a sumtot RateTerm for the solver, implemented a test script in demos.
The plain MOOSE reads it in correctly and gives the correct output. The
solver does not. Nothing obvious in the genesis_parser conversions.
Will need to gdb it.

The data assignment and processing within the Stoich seems to be going OK.
This looks like a problem with zombification.

Yup. The system is not finding the finfo associated with the specified conn.
Furthermore, the two allocated finfos don't have a name. finfo_[1] has
recvFunc of KineticHub::setMolN, which is good. This should be the one
to respond to the lookup for the conn.

Story goes on: numIncoming on the finfo is zero, numOutgoing is 1. Why? We
have plenty of examples where the conversion works.

OK. Valgrind picked it up. I had put the sumtotal in the rates vector,
but that vector is very precisely tied to the velocity vector which only 
has size equal to the variable molecules. I need to put sumtotals separately
or extend the velocity vector to manage sumtots.

Did that. Still didn't work. Finally tracked down issue to 
KineticHub.cpp:redirectDestMessages which was munging sumtotals even if
they were within the simulated tree. Fixed that and finally the sumtots
work. Phew. Should now be able to handle many of the models in DOQCS.
Tried out the acc4 model. Takes a long time to run, possibly the initial
conditions. The match with the GENESIS version is poor: obviously same sim,
but curves are all a bit off. Need to try GENESIS version with greater acc

=============================================================================
5 July 2007
Merged in code changes from Subhasis, which incorporates the Id system into
the PyMoose code.
Confirmed that the sumtotal stuff still works.

=============================================================================
6 July 2007
Next I need to resume parallel coding. 
- Implement the ElementWrapper for off-node objects
- Implement an IdManager class so we can set node control thresholds.
- Devise a test case where after a certain number of objects are formed
	on one node, the next set get exported. Pass messages between them.
	This would first be the same table example I currently do in other
	ways.
- Do a serious test case involving shared messages, such as between 
	diffusing compartments.

Working through more Id-related headaches. Current issue is that the tests
for creation of postmasters in PostMaster.cpp:513 use the id() call which
returns a wrapper. Would like to have a way to return the postmaster when
it is legal.

Fixed this. Now problem in the genesis parser test commands, line 2401.
Check if element is created on expected node.
=============================================================================
7 July 2007
Turns out element should be created on expected node, but the system doesn't
wait for the create to complete and issues an le request right away. 
Furthermore, even when we fix up the creation, we have a problem because 
there is no message to go from parent to child element.
See Shell.cpp:610 in staticCreate.

Anyway, to get the current tests over with, I bypassed this problem and tried
again. Seems OK except that it turned up another bug. I think that the 
SolveFinfo doesn't work well with the Finfo::match( Element*, connIndex)
function. Yup, it just returns zero. Fixed.
Checked in as revision 160, with -g and parallization compile flags.

Trying now to run the kholodenko simulation with the kinetic solver. It
is a long and ugly script to set things up for now. Setup happens but the
thing dumps core when we try to run it.

That was because I tried to call /integ reset. Now it works with a general
reset. But it gives flat lines for all molecules. Fast, though.

=============================================================================
30 June 2007
Working on the kinetic solver. The fast calculations were because there were
no calculations. The enzymes were not being set up. Now I have some progress
there but the output is not working. Also it is incredibly slow.
May need to redo the way I set up plotting.

Seems to go into the enzyme calculations, in RateTerm.h, but for some
reason it is doing the general rather than 1-substrate form, which is slower.
Was doing a -ve value.

OK, now it is much faster but still not seeing the waveform.
Checked that the numbers do seem to be changing with time.
Hacked in an alias for the conc field to look at n. Clearly it oscillates,
but the freq is wrong.

Ran it anyway, runs in about the same time as the old MOOSE: actually
about 10% slower. Perhaps fixing the MMenz calculation will help.
That also is almost the same time.

Need still to sort out why we have a mismatch in the exact solutions.
Anyway, we can compile and run all this, so time to check in all the changes.
Checked in as revision 157, with -O3 compile flags, and including the GSL libs.

Analyzing the discrepancy in output. It persists for all cases: mmenz,
enz. There are two aspects.
1. The first timepoint is already nonzero: some time elapsed before data 
	comes out. 
2. The reactions go too fast.

Point 1 improves, of course, if the dt is forced to be much smaller. Point 2
remains a problem.

rk4 is even worse.

Gear2 is spectacularly dreadful. In all cases, though, the time-course is
affected, not so much the steady states. Looks to me like I am misusing
the GSL integrator.

Yup. I was changing values in S_ used to calculate yprime. But S_ was also
used for the current value y_. Cost for fixing this is a whole lot of
memcpys. I think they are fast though.

This fixes the numerical values. Major step. I still have a memory leak
in the allocation of y_.

Now let's see how this affects the speed.
Marginally slower, maybe another half second - about 5%. The little check
I had put in for timestep doesn't seem to matter here.

So far so good. Let's try now to get our regular benchmark suite of models
to work.

acc4_1.6e-21.g loads. Runs 2x slower under new moose than old. I suspect
SUMTOTAL isn't working either.

Fixed SUMTOTAL loading into system.
Checked that it works OK at least so far as the default ee method goes.
Confirmed that rk5 doesn't handle sumtotals.
Looks like the default ee method does handle them. Also it is way faster:
takes 11 sec as compared to 23 for rk5. The ee method in Genesis is,
if anything, a bit faster at 10 sec. rk5 takes 12 sec in the old moose.

=============================================================================
2 July 2007
Working on completing functionality for kinetic simulations. Implemented 
a sumtot RateTerm for the solver, implemented a test script in demos.
The plain MOOSE reads it in correctly and gives the correct output. The
solver does not. Nothing obvious in the genesis_parser conversions.
Will need to gdb it.

The data assignment and processing within the Stoich seems to be going OK.
This looks like a problem with zombification.

Yup. The system is not finding the finfo associated with the specified conn.
Furthermore, the two allocated finfos don't have a name. finfo_[1] has
recvFunc of KineticHub::setMolN, which is good. This should be the one
to respond to the lookup for the conn.

Story goes on: numIncoming on the finfo is zero, numOutgoing is 1. Why? We
have plenty of examples where the conversion works.

OK. Valgrind picked it up. I had put the sumtotal in the rates vector,
but that vector is very precisely tied to the velocity vector which only 
has size equal to the variable molecules. I need to put sumtotals separately
or extend the velocity vector to manage sumtots.

Did that. Still didn't work. Finally tracked down issue to 
KineticHub.cpp:redirectDestMessages which was munging sumtotals even if
they were within the simulated tree. Fixed that and finally the sumtots
work. Phew. Should now be able to handle many of the models in DOQCS.
Tried out the acc4 model. Takes a long time to run, possibly the initial
conditions. The match with the GENESIS version is poor: obviously same sim,
but curves are all a bit off. Need to try GENESIS version with greater acc

=============================================================================
5 July 2007
Merged in code changes from Subhasis, which incorporates the Id system into
the PyMoose code.
Confirmed that the sumtotal stuff still works.

=============================================================================
6 July 2007
Next I need to resume parallel coding. 
- Implement the ElementWrapper for off-node objects
- Implement an IdManager class so we can set node control thresholds.
- Devise a test case where after a certain number of objects are formed
	on one node, the next set get exported. Pass messages between them.
	This would first be the same table example I currently do in other
	ways.
- Do a serious test case involving shared messages, such as between 
	diffusing compartments.

Working through more Id-related headaches. Current issue is that the tests
for creation of postmasters in PostMaster.cpp:513 use the id() call which
returns a wrapper. Would like to have a way to return the postmaster when
it is legal.

Fixed this. Now problem in the genesis parser test commands, line 2401.
Check if element is created on expected node.
=============================================================================
7 July 2007
Turns out element should be created on expected node, but the system doesn't
wait for the create to complete and issues an le request right away. 
Furthermore, even when we fix up the creation, we have a problem because 
there is no message to go from parent to child element.
See Shell.cpp:610 in staticCreate.

Anyway, to get the current tests over with, I bypassed this problem and tried
again. Seems OK except that it turned up another bug. I think that the 
SolveFinfo doesn't work well with the Finfo::match( Element*, connIndex)
function. Yup, it just returns zero. Fixed.

Analyzing requirements for scheduling internode message during simulation 
setup.

Most commands can go on asynchronously, provided there is a rollback or 
error reporting mechanism that identifies where in the earlier commands things
went wrong:

create
delete
move
copy
pwe
ce
addmsg
setfield

Some commands can only return if the info is updated:
le
getfield
showmsg
el

Options:
- Insert a 'poll' in every shell operation. 
	- For commands that need updated info, repeat this poll till some 
	completion flag comes in.
	- When waiting for user input, poll every second or 100 msec.
- Run poll on separate thread: Can't do because of BlueGene arch,
	not to mention issues with multithreading.


Runtime organization:
- We need a call to the postmaster every Tick.
	- If we have threading, then we will need to subdivide the Tick
	but there is only one cycle of postmaster calls at the end of
	all of these.
- Scripting calls are added as async requests any tick, and get sent out on
	the same tick. I don't need to deal with other forms of update as
	this is pretty immediate.

Setup time organization:
- Set up a ParTick on a separate job, which is run on all slave nodes and
	on the master node whenever the system is waiting for input. It
	polls to clear input, and then sleeps for a little bit before
	the next cycle.
- On all nodes, have the shell do a poll before most commands.
- This would actually be a nice way to handle keyboard input too:
	It would allow control-p for previous command
- There is an infinte loop in GenesisParser::myFlexLexer::Process. 
	This does the tty and calls the yyparse() command.
- We have another infinite loop in myFlexLexer::LexerInput. But I don't see
	it called.

=============================================================================
8 July 2007.

So, overall:
- do NOT set up the cj/t0 at startup. Set up instead pj and cj,
	and pj/pt
	- All ticks must be connected to postmasters.
		- Later when we do operation scanning we can selectively
		connect up only those ticks which need parallel messaging.
		This is a rather weak optimization.
- In due course do auto scheduling of the objects under t0, t1 etc. Till then
	apply useclock and setclock to build these.
- pj and pt are immediately hooked up to the postmasters.
- pj is invoked by shell for once-off polling with 1 step (runtime 1, dt 1).
- On master node, pj is called in an infinite loop by the input-polling 
	loop of the parser
- On slave nodes, pj is called in an infinite loop by the main function.
- In both infinite loops, there is a small wait after the poll is complete.
	This is to lessen the idle load.
This balance between once-of and infinite polling is tricky. A script must
switch between them


Setting up to generate objects on specified nodes as a test.

Mostly set up. I have had to implement a new function for creating objects
on specified nodes. The actual creation test is on hold till I check in the
assorted changes and fixes so far. This set works with 2, 3 and 4 nodes.
Checked in as revision 161, in parallel compile form with debugging.

The Shell::testMess is coming along nicely now, with node-specific creation
of objects and assignment of values. Tested on 1 - 4 nodes.
Checked in as revision 162, in parallel compile form with debugging.

Next to put in a function for handling the polling using pj within 
shell commands.

OK, I have polling going on between testMess calls on the master node. How
to set up on slaves? Best approach may be to provide a shell function that
does polling till the quit command.

Seems like I get a near-race condition if I set off the polling. I tried
to do the equivalent by setting it off for 200 steps, and it took a long
time to unwind the calls. Need to trace to see the execution order of the
polls on different nodes.

Order seems OK. Tracked down a problem with an uninitialized dt in ClockJob.
Now another issue comes up with 3 nodes where it looks like a pointer problem.
Valgrind can't deal with it.
Overall, we are getting close to being able to set the system to work with
polling on the slave nodes.

=============================================================================
9 July 2007
Working on yesterday's problem. 
- Dies only on slave nodes, 3 nodes not 2.
- Identical trace
- Initiated from ClockJob::startFuncLocal, line 287
- SimpleElement::srcRecvFunc: line 371 is actual assertion.
- in ClockJob::startFuncLocal, info_ data is garbage. Info should be 
	properly initialized at this point. 
	- Info garbage is identical between the two slaves.
- Aha: The element actually is named node0 in both cases, presumably the
	postmaster that should be handling this. Looks like we sent a message
	to the wrong target.
	Something funny with the c.e_

Checked if it was the use of TypeFuncPairs in ClockJob. Nope.

OK: there are serious issues with the args in ClockJob and Tick::reinit.
Fixed lots of stuff there, still same problem with 3 nodes.
One possibility is that the Conn vector on the shell is being rearranged 
while the polling is in process.
Yes. That is it. The operation requested by testMess creates a child on the
shell, thus rearranging the Conn vector. Nasty.
Options:
	Shell becomes readonly for messaging
	Preallocate space on the Conn vector (limited hack)
	Objects in general keep a block on modifications till messaging is done.

Confirmed diagnosis by shifting test objects to be children of root.
I've set it up to work through all tests, preparatory to tackling the issue
of non-blocking terminal I/O so that the master process can also keep polling
the postmasters.
Checked in as revision 163, in parallel compile form with debugging.

Implemented nonblocking i/o for terminal. I also have sample nonblocking
code for Windows/PHP. This still does not fix the blocking of the loadfile
on the command line, but I hacked another carriage return in and it now
does that too. Then there was an issue with the loss of the control characters.
I finally have something that does most of what I need: nonblocking, but
uses the canonical control character handling so the tty is nice. 
Checked in as revision 164, in parallel compile form with debugging.

Implemented the postmaster polling from all nodes now, including master.
Tested from 1 to 4 nodes.
Checked in as revision 165, in parallel compile form with debugging.

=============================================================================
10 July 2007
Fixed subtle bug in copy, reported by Niraj: Issue with sequencing the 
removal of conns going outside tree and to global objects.
Checked in as revision 166, in parallel compile form with debugging.

Niraj found and fixed another bug, this one in SimpleElement::lookupRecvFunc.
A bit of fine-tuning the polling of the postmasters.
Checked in as revision 167, in parallel compile form with debugging.

Niraj pointed out yet another problem: I had not been testing in the
serial form. Fixed.
Checked in as revision 168, in serial compile form with debugging.

=============================================================================
18 July 2007
Seriously bogged down in other stuff. Worked out plan to update the 
Cinfo to handle scheduling info, and also worked out how to manage solvers
for automatic scheduling of objects:

=============================================================================
24 July 2007
Other stuff continues. I need to set up some major changes in Cinfo and 
scheduling soon though.

Updated to the most recent revision, 172.

The scheduling ideas were:
1. Each object connects up to the scheduler upon creation. 
	- Exception for objects on /proto and /library
	- Need to unschedule objects when they move to /proto and /library,
	 and vice versa. This means that we need callbacks when operations are
	 done on messages. The Cinfo needs a callback function for
	 message operations.
2. Each class knows where to connect its instances.
	- This is defined in Cinfo
	- Biophys stuff goes to t0 and t1
	- Biochem stuff goes to t2 and t3
	- Graphics stuff goes to t4, t5 and t6.
	- These clocks will need to be predefined.
3. Solvers do Just in Time (JIT) scheduling of their zombies
	- They scan the new entries on the clock ticks
	- Solvers live on /solvers/biophys, /solvers/biochem etc.
	- Eventually we will implement a SolverManager class to handle
		issues of model partitioning among solvers.
		This solver manager will replace the neutrals for 
		/solvers/biophys etc.
	- For now the shell handles this. It puts all connected compartments
		on a single solver. 
	- We need a variant on hsolver for lots of identical single compt
		spiking models. Useful for stimuli.
4. All this scheduling can be overridden by the user. This is mostly for
	BC, and we need a flag which tells us whether the user wants to
	ignore explicit scheduling from old simulations, or pay attention to 
	them.

Set up scheduling operation in cinfo. Now to set up ticks and then the
elements to use them.

Ticks set up and compartments can use them. Now to set up good initial timings.

Partly done, in main.cpp. 
Need to do a reset etc so that the thing is ready to use.

=============================================================================
25 July 2007
Implemented auto-scheduling of biophysics objects, but not for hsolver.
That still needs quite a bit of organization.
Checked in as revision 173, in serial compile form with debugging.

Now I put in the kinetics objects. But we get problems because of the unused
t0 and t1 taking up a long time. Tried to eliminate the unused ticks. Now
I get core dumps around line 152 in SchedTests.cpp on the unit tests.

Fixed it, still core dumps, now in the main::scheduling function.
Nasty one. The Tick::reinit is calling the RecvFunc for a compartment,
no idea why.

=============================================================================
26 July 2007.
Finally tracked down problem, it was in ClockJob::reschedFuncLocal.

Now chugging through all sorts of fixes for the autoscheduling, using
automatic scheduling of the kholodenko model as a target point. Currently
stuck on earlier unit tests.
Fixed that, also solved yet more issues with the scheduling. Now the
kholodenko model loads and runs using (mostly) the builtin scheduling. I
need to implement a subclass of the table to pretend to be a plot, and more
to the point, to have the appropriate default scheduled tick. Currently there
is no easy way to determine how to schedule the tables.
Checked in as revision 176, in serial compile form with debugging.

Designing a biochem solver manager.
- Needs a general mode indicator: EE, ODE, stochastic, spatial, stochmesh,
particle.
- Needs a scale range for adaptive behaviour: over what range is it adaptive?
	Needs rules for adaptive behaviour.
- Needs options for specifying a specific method if many are available.
- Needs rules for deciding between aternate methods, eg, alternate ODE
	methods.
- Needs guidelines on parallel behaviour too.

Starting out with a first pass implementation using ClockJob.cpp.
=============================================================================

27 July 2007
Got the automatic kinetic solver stuff set up. Loads and runs kholodenko
model. Got sidetracked into wrapping up a whole lot of the minor
unfinished field assignment stuff in the kinetic solver.
Checked in as revision 177, in serial compile form with debugging.

=============================================================================
13 August 2007
Begun work on ArrayElement with Raamesh. 
Design decisions:
	- use a separate creation function from Cinfo.
	- Store data values in an array (not a vector)

Issue: size field currently refers to # of entries, not size of object. Should
	we store size directly or continue to use cinfo access procedure.


Stages to implementing ArrayElement:
1. Creating with array of objects.
2. Accessing fields in array (using wrapper element)
3. Ensuring that generic messages apply to all objects in array.
4. How to get specific messages to go to individual objects in array.


Implemented the basic class and did a simple unit test for creation. 

=============================================================================
14 August 2007

Implemented example directory with a simple averaging class. Unit tests
connect 3 together and run for 19 steps. An identical calculation is done
in a .g file.


Working on wrapper element for ArrayElement lookups. The one for PostMasters
is just a SimpleElement, but here we need to do some clever stuff with the
data lookup, so we will need to implement a separate class. May as well
derive from SimpleElement: Lots of code to be bypassed.

Setting up, compiles, but doesn't work because our test Element does not
have a ThisFinfo or Cinfo. perhaps the Cinfo should be an Element field?

Instead set it up using an array of Interpols. Lots of potential tests,
but only bare bones one done so far.
Checked in as revision 181, in serial compile form with debugging.

=============================================================================
17 August 2007.
The basic checks for the ArrayWrapperElement are fine, but now we come to 
a design issue: How to handle lookup of Elements?
- Add an index field to ids
- Add a generic extension field to ids.
- Add other extension to Id so it acts like the ArrayWrapperElement.

Let's just do the first. Simple and obvious. Doubles Id size.
Can add a special index, MAX_INT, to indicate entire ArrayElement.
Leads to various changes on the IdManager.
Higher-dimension arrays, or arrays that contain arrays, will need something
better. Later.

A related problem: Suppose I make: 
cell
cell/soma
cell/dend

Now I turn this into array elements: cell[1..10]
In GENESIS, I would see
	/cell[5]/soma
Here, I would see 
	/cell[5]/soma
	and also
	/cell/soma[5]
How to resolve?
	Basically comes down to how we traverse array element children.
	What we actually see is a single tree. At each level we can do
	indexing. The key is to set up the parsing so it does it right.

Implemented an index field within the Id. Need now to modify the getElement
function to take the returned ArrayElement and put a wrapper around it if
there is an index. But it still doesn't clear unit tests.
=============================================================================
18 Aug 2007
OK, it was just a matter of doing a clean recompile. Now to move on to
accessing arrays.
Going on OK in Neutral::getChildByName, but there is a GENESIS syntax issue
here which
unfortunately trickles down to the base code. GENESIS takes an un-indexed
element as element 0. If we do the same, it comes up here. Problem arises
because C syntax takes the un-indexed array name as referring to the whole
array. Best I can do here is to add the syntax that foo[] means the whole
array. This extends GENESIS syntax but does not break it.

Working on handling lookup. Next to handle creation of arrays.

=============================================================================
19 Aug 2007
Checked in as revision 182, in serial compile form with debugging.

=============================================================================
10 Oct 2007.
Updated to version 203.
=============================================================================
11 Oct 2007.

Redesign plans for solver autoscheduling: Develop new manager classes.
Subha has already set up a 'cell' manager class. This is meant to be created
under a cell tree, and then it manages set up of a solver that manages
all the child compartments and channels.
I will create a similar 'kinetics' manager class that does a similar thing.

The rule is that objects do NOT get solved by default, only when these managers
are set up. Cellreader and kreader will set up managers.

Also we revert to a single clock created by default. Later we'll figure out
how to get solvers to negotiate timesteps with each other.

=============================================================================
12 Oct 2007.

implemented shell of KineticManager class to act as controller for solving
kinetic models. Lots yet to be done.

=============================================================================
13 Oct 2007
Continuing work on it. The Manager class now knows about the GSL integrators
as well as having hooks for a lot of others. Croaks when I try to 
set the method.
=============================================================================
14 Oct 2007
Now getting to set up the solver scheduling. There are serious issues,
reported earlier by Raamesh, of the thing crashing when reset.

I have also cleaned up the clock ticks. Now only t0 and t1 are created 
by default. 
I have also cleaned up the printouts during unit tests. Now much less junk
is printed.

Time to check this mess in before going on to next stage of fixing kinetics
solver.

Checked it in. Now at revision 205.

Now to tackle reset problems with solver. 
Resched should do the following:
	- Check if the object list has changed
	- If so, clear out old ones and reload matrix. When clearing out
	old ones, must put the latest state values back into the old objects.
	- Currently don't try to do this incrementally. Too complex.

Reinit should do the following:
	- Restore all initial conditions. This is a purely internal operation.

Reset does resched + reinit.

Step should do the following:
	- Check for change of object list. If so, do a resched.

Now all the steps are in order. Kkit automatically sets up a KineticManager
so that instead of waiting to change the method, we get a core dump right away.
The dump is because the ThisFinfo has been replaced on some elements with
a SolveFinfo, but the message from the solver is no longer there.
I have put in a lot of stuff that ought to clean out old simulations so that
they are ready to be re-solved, but it isn't doing the job.

Last thing: tried to get it so that upon deletion the KineticHub cleans up
all the solved objects. Crashes now during unit tests.

=============================================================================
15 Oct 2007
After much messing around, figured out why the crash occurs. It has nothing
to do with the stoich stuff. Simply that we used the hard-coded index
0 for the childDest message, but in the KineticHub we override the childFinfo
with a new one and the current ugly system then uses a new index.

Fixed. Now unit tests pass. The solvers now run without crashing but do not
give any results. Time to check in this mess.
Checked in as revision 206, in serial compile form with debugging.

Seems like the KineticHub is not created. On closer inspection it seems
like it interferes with the listing and access to child objects including
itself. This is what happens if we start out with new children on an object:
If we create any object before the hub, the hub becomes invisible.
If we create any object after the hub, the object becomes invisible.

Fixed. Turned out to be related to the earlier problem. I was using a new
target function for handling child messages to the hub class, so the MsgSrc
should have been going to the connSrcVeryEnd rather than connSrcEnd. 
Fixed in several places. The kholodenko demo still does not work, though.
Also when I change the method to ee and reset it dumps core.
Checked in as revision 207, in serial compile form with debugging.

Now to tackle the issues with the demo.

Seems like the main issue was just that it wasn't initialized properly.
Unfortunately the bog-standard reset command is pretty ugly as it rebuilds 
the whole mess.
Did a test of rerunning the model multiple times. Seems promising. But it
still dies when I change the method to ee.

Fixed the crash when the method changes. But now EE does not give any output
at all. Other things look fine.
The clock ticks are connected up OK. I think it is the input to the table for
the output graphs that gets messed up. Anyway, this is a good intermediate
point to check it in.
Checked in as revision 208, in serial compile form with debugging.

=============================================================================
16 Oct 2007
Ascertained that the plot messages remain intact when going from GSL to ee
solvers. So the issue is, how is the plot message set up and cleared during
rebuilding the stoichiometric system.

Found that the existing function redirectDynamicMessages works fine in
either direction. Used it, works right off. So we can now switch between
solved and unsolved simulations. Test program is DOCS/Demos/test_kinsolver.g

Checked in as revision 209, in serial compile form with debugging.

Now to see if sumtotal works with the solvers.

No, it doesn't. And the reason is that the solver SumTotal class works through
molecules only. What I need is an extRateHandler that forces various 
external calculation entities to do their stuff for the specified time and dt.
Due to variable timestep algorithms, the time may be non-monotonic.
The outcome of these calculations goes into the mol array as a dummy, and then
the SumTotal will finally be able to use it.

Rather than this, note that the only likely external input is a table. This
needs to be managed by the solver to handle variable dt methods. So we really
need to work on incorporating tables that live in the kinetic object tree.

Turns out I had anticipated almost all of this. I had a silly error in the
KineticHub code that deleted the internal sumTot messages. Now fixed, and
the internal sumTots work. On now to external sumTots. The problem here
is managing timing, which may differ for internal steps of the solver, and the
external clock tick of tables and other inputs to the sumTot. 
In the current version I just assume that the dt is small
enough that a little bit of jumping around by the solver won't mess up the
output.

Checked in as revision 212, in serial compile form with debugging.

Implemented a test case for sumtots with tables. In GENESIS/kkit such
beasts are handled using the SLAVE message, here I want to stick to sumtots.

=============================================================================
17 Oct 2007

Got table input into the regular EE method to work, and also set up loadtab
from kkit dump files. The solver still does not handle it, and still does
not work to restore EE function if the mode is switched back.

Checked in as revision 213, in serial compile form with debugging.

Five things before I can use this in production mode:
* Get the solver to handle the tables.
- Get the SolverManager to do intelligent things with timesteps
+ Get the loadtab to handle the -continue statement
* Fix up the plots.
- Profiling and benchmarking.

Working on the first. seems like we have problems around line 378 of
KineticHub.cpp: although all looks like we successfully redirect the
message, it does not appear when I look for it from the command line.

I think that the first round of redirecting is fine, but when the solver
is deleted the 'clear' command does not properly put the message back, so
subsequent rounds all fail.
It is hard to put the message back. See line 604 in KineticHub.cpp

=============================================================================
19 Oct 2007
Instead of struggling with putting back the sumtot message, I left it there
and made an extra one for the solver. This seems to work.

Checked in as revision 217, in serial compile form with debugging.

Fixed up plots. This involved some fixes in the genesis parser for the
el (getelementlist) command, as well as some to the table object.
Checked in as revision 218, in serial compile form with debugging.

=============================================================================
20 Oct 2007
Trying to implement loadtab -continue. Seems OK but weird things now happening
with plot saves:
If I do 'save' alone it works
If I do 'do_save_all_plots' alone it fails
If I do 'do_save_all_plots' after the run is done, I get plots on both
If I do both 'save' and 'do_save_all_plots' internally, in either order,
	both fail.
The failure doesn't seem related to plotting, but to the data values.

There is some scripting issue here. I can toggle the problem by 
commenting out a single line, where I define an unused string variable.
Anyway, after all this the thing clears tests for bigtabsumtot.g, which 
loads tables in using the -continue command. Unfortunately, it does not
clear a test for doing the simulation repeatedly with different solvers.
Problem now is that we don't trust the scripting.

Still have this problem, but fixed another issue with the reset of tables
acting as buffers for incoming data in lieu of xplots.

Checked in as revision 219, in serial compile form with debugging.

Attempting to compile with optimization. By turning off NDEBUG a whole lot
of nasty holes turn up because I was doing operations in the assertions, and
the subsequent code depended on some of these. Struggling now with the
kinetics library where there are some solver issues with the optimization,
even when NDEBUG is on again for the kinetics dir only.

=============================================================================
21 Oct 2007
Finally managed to compile with optimization, but all the unit tests are still
in place. More to the point, both the optimized and debug versions dumped core
with the first serious benchmark model, acc4_1.6e-21.g.
After some work it turned out that I had not allowed for cases where 
the model has both classical MM and also explicit complex enzymes. Fixed.
Works, but for a 4x difference between two plots at the 1e-8 uM level. That
is probably a matter of numerical resolution.
But the other two benchmark tests still fail.

Set up the benchmark directory with tests, a preliminary RESULTS file,
and outputs computed by the old moose.
Checked in as revision 220, in serial compile form with debugging.

I put in a check for the nan in the sparse matrix.
I think the error is simply because the initial dt is too big.

Yup. Confirmed. For the nonscaf6 benchmark simulation the internal dt 
settles down to about 0.6 msec. Ugh. The actual location of the internal
dt is in the GslIntegrator class.

Put in a fair amount of work to implement the estimation of required dt.
Mostly works, but there is a problem with molecule values which are redirected
back to the solver S_ array, which is not initialized. However, if I 
explicitly initialize it at this point the solver setup becomes impossible
to use on the fly during runtime.
I should set up new S_ values from the objects themselves, but the same
initialization issue applies.
For now I'll set up the dts based on initial conditions. Poor compromise.

Anyway, it now handles the nonscaf6 case with an intelligent guess for
a starting dt. Still barfs at the mega.g simulation, but time to check it in.
Checked in as revision 221, in serial compile form with debugging.

Confirmed that the issue is the use of array braces for parent objects,
specifically groups.
I now have the odd situation that my tiny test model, test_undump.g,
successfully crashes MOOSE but the big model, mega.g, loads properly
and at least it begins to run. But there is some problem with the timestep,
keeps going smaller, down below 400 nsec. Tried implicit solution. This has 
an internal dt of 10 usec, but falling, and does not look any better.
EE gave a -ve time! Need to sort all these out.

=============================================================================
23 Oct 2007
Figured out why we have a crash in test_undump.g. The ksolver reinit
creates and deletes lots of elements that are also scheduled to be reinited,
thus invalidating the iterator for reinit.

This raises the question of why reinit has not messed up other objects.
Probably just luck of allocation of the vector out of t0.
- queue reinit operations. I need some kind of queueing operations anyway
	for other kinds of runtime creation of objects.
- Make a safe iterator for reinit. This won't help for other runtime operations.
- Reorder the iterator to put the kinetic object at the end
- Have an exclusive tick/stage for the KineticHandler.
- Don't even call the setup function from the scheduler. Call it from the shell.
	For example, at the start of the 'step' function. Problem is that
	there may be many handlers of different kinds. Even so, this is
	useful.
- Provide a special message on cj to do things at 'start'.

Tried the quick and dirty. I put KH on a separate tick. Dirty yes, quick no.
Stuck somewhere else now, in the Tick::reinit function where it looks like
again we have a rebuilding of a iterarator.


=============================================================================
25 Oct 2007

Trying to handle queueing this way:
- Add a 'inQ' flag to ProcInfo. This indicates if the command is coming
	through the usual messages or through a queueue.
- Any operation (process or reinit) that needs orderly rescheduling, must
	trap this flag and push itself onto the queue. 
	Ideally through a return msg, 
		(but there are issues of hardcoding funcs to lessen memory use.)
- The queue is operated after all ticks are done (otherwise too many checks).
	Just a matter of rerunning the function with a different flag.

Before I jump into this, let's confirm the iterator issue.
Yup. Confirmed. But also realized that I should not do this stuff on reinit,
only on reset. Shifted it over. Now I have an ugly direct call from shell to
/kinetics to do a resched.
At this point the nonscaf benchmark seems to be OK, and I have resolved the
issue with the undump of mega as well as the test undump file. However,
mega does not run properly and goes into dt < 1e-6.

Ran in kkit. This confirms that we get recommended dt ~1e-9 for the mega model.
Perhaps the problem is not a bug after all. Then how does the old MOOSE handle
it?

Anyway, did a checkin of the current version.
Checked in as revision 228, in serial compile form with debugging.

Now let's see if we can get the thing to run without the assertions and
unit tests.
No, crashes right off.

Went through many files cleaning up asserts. It works now for kholodenko.g
but fails to handle Demos/test_solvertabsumtot.g

=============================================================================
26 Oct 2007
Slowly working through the possibilities.
- when the asserts and unit tests are turned on, the tabsumtot.g file works
- when asserts are on but unit tests are off, tabsumtot.g fails.

Now to individually remove unit test operations from likely places.

A stroke of luck: first thing I tried (in Table.cpp) showed misbehaviour.
Tracked it down to creating and destroying 1 vs 2 table instances, without
any other stuff. 2 instances works, 1 fails.
Most things are identical: xtab and field values.
Here is the version that works:

showmsg solve/hub
INCOMING MESSAGES onto /kinetics/solve/hub
MSG[0]: into child from: [ /kinetics/solve ].childSrc
MSG[1]: into molSum from: [ /kinetics/xtab ].outputSrc
MSG[2]: into child from: [ /kinetics/solve ].childSrc
MSG[3]: into hub from: [ /kinetics/solve/stoich ].hub
MSG[4]: into molSolve from: [ /kinetics/B, /kinetics/A, /kinetics/C, /kinetics/D, /kinetics/tot1, /kinetics/tot2 ].process
MSG[5]: into reacSolve from: [ /kinetics/kreac, /kinetics/forward ].process
OUTGOING MESSAGES from /kinetics/solve/hub
MSG[0]: from hub into: [ /kinetics/solve/stoich ].hub
MSG[1]: from molSolve into: [ /kinetics/B, /kinetics/A, /kinetics/C, /kinetics/D, /kinetics/tot1, /kinetics/tot2 ].process
MSG[2]: from reacSolve into: [ /kinetics/kreac, /kinetics/forward ].process
moose #11 > 


Here is the version that fails:
showmsg solve/hub
INCOMING MESSAGES onto /kinetics/solve/hub
MSG[0]: into child from: [ /kinetics/solve ].childSrc
MSG[1]: into molSum from: [ /kinetics/xtab ].outputSrc
MSG[2]: into child from: [ /kinetics/solve ].childSrc
MSG[3]: into hub from: [ /kinetics/solve/stoich ].hub
MSG[4]: into molSolve from: [ /kinetics/B, /kinetics/A, /kinetics/C, /kinetics/tot1, /kinetics/tot2, /kinetics/D ].process
MSG[5]: into reacSolve from: [ /kinetics/kreac, /kinetics/forward ].process
OUTGOING MESSAGES from /kinetics/solve/hub
MSG[0]: from hub into: [ /kinetics/solve/stoich ].hub
MSG[1]: from molSolve into: [ /kinetics/B, /kinetics/A, /kinetics/C, /kinetics/tot1, /kinetics/tot2, /kinetics/D ].process
MSG[2]: from reacSolve into: [ /kinetics/kreac, /kinetics/forward ].process

Note the small difference in molecule sequencing involving D. Shouldn't
matter, but...

Additional headache: the timestep calculator is returning inf, even when
the simulation works.
Fixed this, but there are still problesm with the tabsumtot.g test.

=============================================================================
27 Oct 2007
I've been stuck on this bug too long, and need to move on to the Smoldyn
interface. Note it as a major outstanding issue, but continue with the new
stuff.
Checked in as revision 230, in serial compile form with debugging.

Now on to implementing the Smoldyn interface. Design is that the KineticHandler
sets up a geom object as well as the solve object. The geom object is the
same as the surface object used in Smoldyn, and is home to a number of panels
which can be rectangles, triangles, spheres, cylinders, hemispheres and disks.

The molecule class has to be derived to have an extra Diffusion field, and
a set of xyz vectors that aren't located on the object, but only in the
Smoldyn equivalent.

I've downloaded the Smoldyn source but it is still an older version (1.73).

OK, the source is current (1.74). 

Some questions for Steven:
1. How do you assign the number of molecules in a pool? 
2. Where (in space) are they put, or taken away from?
3. What is 'identity' of a molecule.
4. Is there a concept of nInit, that is, an initial number of molecules to
	act like a boundary condition every time the simulation is rerun?
5. Can one get total volume/area from a surface?
6. Is there an economy of calculation to partition a single large Smoldyn
	simulation into two smaller ones that communicate with each other
	through teleporters?

First steps: Implemented Particle object, derived from Molecule, and
implemented skeleton of SmoldynHub.
Checked in as revision 231, in serial compile form with debugging.

=============================================================================
2 Nov 2007
Put in hooks for SmoldynHub into KineticManager. Doesn't do anything yet.
Checked in as revision 236, in serial compile form with debugging.

=============================================================================
3 Nov 2007
Working on scanning model path to set up reactions.

Qs for Steve:
1. Why are there 3 rxnptrs in the list of reactions in the simstruct ? Is it
	one for each order of reactions?
2. in the rxnstruct, where are the substrates for the reactions set up? 
	Are they in the prod array? Or does the rxnptr array map one-to-one
	with each entry in the mols array?

Asked Steve. In the meantime,, next step is to decide whether to use the
Stoich calculations to set up vectors for reacs, enz, mols
=============================================================================
4 Nov 2007.

Pros and cons of using Stoich:
Pro: 
	- Deal with the whole of the MOOSE structure in one place. Don't
		have to do messy scanning again.
	- Return reaction structure in an indexed form, in terms of pointers
		off S_, more similar to the organization of the Smoldyn code.
Cons:
	- Need to handle extra mol info for Smoldyn
	- Unnecessary construction of Stoich matrix. 
		- But overhead here is tiny compared to Smoldyn sim.

I think that the Stoich should deal with talking to the MOOSE model, and we
take info from there.

Setting it up thusly. I have redone the SmoldynHub much like the KineticHub
to achieve this, and it is beginning to look like a common base class is
called for. For now, check it in.

Checked in as revision 237, in serial compile form with debugging.

A bit of cleanup work on it, and it now zombifies the model, but of course
doesn't run yet.


Some more Qs for Steve:
1. What is 'root' in simalloc?
2. Does simalloc take care of allocating molsptr?  How about particles?
3. Is molsptr an array, one for each species,
	or a single entry having a lot of particles in it?
4. Do we have a single giant moleculestruct vector for all particles?
5. When setting 'max' for molssalloc, should I put in just the total number
	of particles in the system, or some intelligent scaling factor 
	over this for subsequent evolution?
6. I assume that the simstruct::name entry is an array of names for
	each identity, that is, molecule species.
7. Is there default initialization of some of the parameters such as 
	simstruct::tiffit?
8. What are the three reactions in rxn: zero, one and two molecule?
9. What is 'total' in rxnalloc?
10. What does setproducts do?
11. If I have molecule species A, B, C in reaction A -> B + C, how do
	I set it up?


=============================================================================
5 Nov 2007.
Here are Steve's answers:
>
> 1. What is 'root' in simalloc?

It is the configuration file path.  It is recorded in sim (the simulation
structure) so output files will be saved in the proper directory.

> 2. Does simalloc take care of allocating molsptr?  How about particles?

No.  Both the molecule superstructure and all of the empty molecules are
allocated by the loadsimul function, when it reads the max_mol statement
in the configuration file.


> 3. Is molsptr an array, one for each species,
>         or a single entry having a lot of particles in it?

I'm assuming you mean the simulation stucture element mols, which is a
molssptr, which is a pointer to a molecule superstructure (there is no
molsptr in the code).  It is a single entry, pointing to a single
superstructure.  The superstructure lists some of information about every
molecule, including diffusion coefficients and drawing information.  It
also contains the lists of molecules.


> 4. Do we have a single giant moleculestruct vector for all particles?

There are actually 3 vectors of moleculestructs (or, more accurately,
moleculeptrs, which are pointers to moleculestructs).  These vectors are
all owned by the molecule superstructure.  They are the vector live[0],
which are active molecules that can diffuse; live[1], which are active
molecules that do not diffuse; and dead, which is just storage space for
molecule structures that are not currently in use but that are available
for reuse if needed.

> 5. When setting 'max' for molssalloc, should I put in just the total
> number
>         of particles in the system, or some intelligent scaling factor
>         over this for subsequent evolution?

It should be the maximum number of particles that might be needed during
the simulation.  Currently, if more particles become required than were
allocated initially with molssalloc, Smoldyn just stops and tells the user
that not enough molecules were allocated.  It would be more elegant if
Smoldyn fixed the problem dynamically rather than just stopping, but
that's not what's done currently.

> 6. I assume that the simstruct::name entry is an array of names for
>         each identity, that is, molecule species.

Correct.  Logically, this entry would be more appropriate as an element of
the molecule superstucture, but it's actually in sim instead.

> 7. Is there default initialization of some of the parameters such as
>         simstruct::tiffit?

Yes.  Most parameters have defaults.  For example, the default for tiffit
is 0, which means that tiff saving is turned off.  Most defaults are
listed in part 1 of the documentation, in the description of the statement
that is used to modify them.

> 8. What are the three reactions in rxn: zero, one and two molecule?

Correct.


> 9. What is 'total' in rxnalloc?

I chose horrendous names when I designed reactions.  total is the total
number of reactions that are defined in that reaction structure.

> 10. What does setproducts do?

A reaction such as C->A+B is simple if it is irreversible.  When it
occurs, the location of the reaction is defined to be the location of C. 
C is removed from the system and A and B are both placed on top of each
other at the reaction location.  However, if it is reversible such that
there is also a reaction A+B->C, then this product placement method won't
work because, at the very next time step, the A and B products are certain
to be within a collision distance of each other and will react.  The
solution is to initially separate the A and B products by a small
distance, if there is a reversible reaction.  setproducts determines what
this small distance should be and then saves the result in the product
template, which is the prod element of the reaction structure.


.........................................................................

Slowly setting up data allocations. Simple but tedious. yet to tackle reactions
and come up with a usable test.
==============================================================================
6 Nov.
More Qs.
1. Should the size of the vectors live[0] and live[1] be independently
	determined depending on # of diffusible and non-diffusible
	entries? Will the molsort function do this?

2. What does moleculesstruct->serno do? Do I need to allocate it?

3. What does the difsort argument in molsort do?

4. simptr->topd: should this be the first free entry, or the size of the
	dead vector?
5. I gather than a zero ident molecule has to be just below the last of the
	entries in the dead list. Do I need to do anything special here or
	will calloc deal with it?

6. How many zero order reactions to define? As I understand we have to 
	define nident + 1 for 1st order, and (nident + 1)^2 for 2nd order.

7. Don't understand args for AddRxn2Struct.

Begun process of extracting info from reactions. Using rates::getReactants
to do so.

==============================================================================
7 Nov
Compiled MOOSE with the Smoldyn set up stuff, but still need to link
the Smoldyn code for an overall executable. Getting there... Steven will
generate separated sets of C files to help to do the engine as a standalone
library.

I should also get the spatial stuff set up.

And if I have too much time, I need to get the original GSL solver into
production mode.

==============================================================================
11 Nov.

Finally got compilation to work with the Smoldyn libraries. Many challenges,
not least simply getting the Smoldyn makefile to generate libraries. Then
I ran into problems with linking in the C libraries, which had me stuck
for a while. Now the MOOSE stuff is checked in, as revision 250.

In the interests of developers working without Smoldyn, I've also checked
in a version which comments out the Smoldyn dependencies from the Makefile.

Checked in as revision 251, in serial compile form with debugging, and with
Smoldyn flags turned off.

Now back to the Smoldyn development. Some fixes later, the test program
(just an enzyme reaction) no longer dumps core and has begun to call the 
necessary functions.
Decision: To put D into the Molecule or keep it in particle?
Pros: 
	- kkit already has D
	- Useful in stoch as well as PDE systems
Cons:
	- Currently few simulations use it.

The Ayes have it.

Set it up. Working on communication between solved stuff and Smoldyn.
Enzymes look OK, molecules/particles not so.

Checked it in.
Then update the Makefile to get rid of Smoldyn dependencies.

Checked in as revision 253, in serial compile form with debugging, and with
Smoldyn flags turned off.

==============================================================================
13 Nov.
After much joint coding with Steven, got Smoldyn to correctly run an
enzyme reaction. Major step forward. A huge number of loose ends remain to
be cleaned up, and then I need also to get the spatial stuff in place.

Checked in as revision 260, in serial compile form with debugging, and with
Smoldyn flags turned on.

Then removed the Smoldyn compile flags and checked it in again.

==============================================================================
17 Nov

Some days of meetings with the visiting CRL team.

Beta release: 7 Jan 2008

Goals:
Production kinetic simulations
Production neuronal simulations
Action-potl communications in parallel
Smoldyn first pass incorporation into MOOSE


Today's work: Working on interface

Got lookup of 'n' to work. I may have also eliminated the need for the
special SolveFinfo.

Need to fix the conc field in particle so it looks up the N, which is working.
This is going to be complicated because it has to refer to the surface,
unlike the old compartmental molecule, which had its own internal calculation.

Got around it for now by referring to the Molecule:: base class operations
to look up conc. Now the simulation can plot out molecule concs as it
goes along. Assignment is yet to be sorted and I'll need to work with Steven
to get that set up.

Checked in as revision 262, in serial compile form with debugging, and with
Smoldyn flags turned on.

Then removed the Smoldyn compile flags and checked it in again.

==============================================================================
18 Nov.

Things to do with Smoldyn:
- Get the individual molecule positions: Should be linear.
- Set the molecule concs: Need to get instant diffusion func from Steven.
	Instead how about a reseeding algorithm.
- Control molecule rates on line.
- Implement surfaces: Lots to do here. Design:
	- /KineticManager|
			 L/solve----------------|
			 |			L/hub
			 |			L/stoich
			 |			L/solver
			 |
			 L/geometry-------------|
			 |			L/surface-------|
			 |			|		L/panels
			 |			|		L/panels
			 |			|
			 |			L/surface-------|
			 |			|		L/panels
			 |			|		L/panels
			 |			...
			 |
			 L/Other kinetic managers
			 |
			 L/model reacs.

The idea is to have a complete specification of all surfaces on the manager.
The norm will be one, but other things may happen.
Additional managers come in when we want to merge multiple methods.
To make it flatter we could have a single manager but multiple solve 
directories, and multiple geometry (surface) directories?

Issue with that is that each solve needs to be associated with a specific
geometry. Could do by indexing. At some point we will need to formalize
how the solvers and geometries communicate.

At this point, if I have a Surface/Geometry definition, I should be able to
have the molecules get rid of their local volume info and refer instead to
their geometry. Will need to work out in detail. For now let's get the panels
in place.


To check with Steven:
- What do shapes mean in less than 3 dimensions? Are they used?
- What are slices and stacks in sphere?

Implemented first pass for Geometry, Surface, and Panel.
Checked in as revision 264, in serial compile form with debugging, and with
Smoldyn flags turned off.

==============================================================================
19 Nov.
Added skeleton classes for all basic shapes in Smoldyn: 
Disk, Hemisphere, Cylinder, Sphere, Triangle, Rectangle.

==============================================================================
20 Nov
Checked in basic shape classes. 
In revision 265, in serial compile form with debugging, without Smoldyn flags.

To get this to take over volume terms in MOOSE, I need to replace the
Molecule::volumeScale_ parameter with a message that queries the geometry.
This would cost a bit in terms of memory, but is a clean single-point
solution for all molecules and can eventually give dynamic volumes.

I need a new concept, a compartment. This gets volume info from a bunch of 
surfaces in an additive or subtractive manner. The compartment is what 
a given molecule species is associated with. This is needed because the
same surface may be inner or outer bound of different sets of molecules,
or some molecules may be on the surface itself.

Compartments are located below geometry and communicate with shapes on
the same level using messages.

To get this backward compat:
	- Need to set up geometry neutral object automatically
	- Need to set up surface object automatically under geometry
	- Need to set up sphere object automatically on the surface.
	- Need a default compartment on the geometry, tie this to first surface
	- Connect up all molecules to default compartment on creation,
		unless there is a separate named compartment to attach to.
	-- Will need to set up kkit dump of geometry/compartment to dump
		before the molecules are done.
	- Cannot use name Compartment: that is taken by neuronal models.
		How about MolCompt or MolVol or Space or KinCompartment.

Setting it up.
==============================================================================
21 Nov.
The SBML specification of compartments uses the single 'outside' field to
specify relationships between them. If A->outside == B, then B is outside of A.

Here I was going to use exterior and interior messages to surfaces. Can I 
include an equivalent to the 'outside' field? 
Some criteria:
- I must be able to set these up by default or by reading an SBML file.
- I must be able to handle cell membranes: 2-d surfaces in 3D.
- I must be able to talk easily to molecules to replace the existing
	volumeScale field.

Approaches:
- Use surface relationships. If S1 is exterior to A and interior to B, then
	B is outside A.
	- Indirect. Would it be tricky to set up? I will need a shape even
	for a generic compartment.
	- How do we handle exocytosis/membrane fusion?
	- How do we handle membranes?
- Use separate special messages between compartments.
	- Messy. May end up with dual specifications of same info.
	- Membranes can be handled. A is inside memb is inside B
	- SBML uses an 'outside' field.

==============================================================================
22 Nov.

Compartment messaging:
- outside (src): Goes to the compartment outside the current one. No args.
- inside (dest): Comes from the compt(s) inside current. No args.
- exterior (dest): volume, area, perimeter.
- Interior (dest): volume, area, perimeter.
- Return message to molecules: extent: This is an alias for size, but also
	includes dimensionality.

Message contents: outside/inside: nothing.
- from surfaces: vol, area, perimeter.

==============================================================================
23 Nov.

Checked in as revision 266, in serial compile form with debugging, and with
Smoldyn flags turned off.

==============================================================================
24 Nov.
Added in most of the interface stuff for shapes going to Smoldyn. Still need
a complete test version.

==============================================================================
25 Nov.
Completed first pass at surface loading into Smoldyn. Shapes are now loaded,
but the molecules are not yet associated with the surfaces.
Checked in as revision 269, in serial compile form with debugging, and with
Smoldyn flags on

Changed compile flgas again to remove Smoldyn dependencies, checked in again.
Now at revision 270.

To get this reasonably complete, I still need to do the following:
- Expand the test. Put in coordinates and neighbour relationships, and also
	associate molecules with surfaces.
- Implement the association of molecules with compartments.
- Check out a few simple geometries
- Set up kkit to define geometries.

==============================================================================
26 Nov.
Working on the earlier bug with eliminating the unit tests and assertions:
There was a problem running tabsumtot.g. The output was flatlined.
Turns out that the error is present only in the (automatically setup) solver
mode. EE mode handles the tabsumtot fine. The data is actually going from the
table to the molecule, but the solver is not doing anything with it.

For a while it looked like the SumTotal::sum operation was overwriting
the target sumtot value, but now even that does not happen.

Should verify the assignment of the value in the Stoich/Hub from the
external table.

26 Nov contd 

Finally tracked it down. The molSumMap is the list of all molecules that
take sumTotals. However, it is being indexed in KineticHub::molSum
by the # of external objects that connect into sumTotals.

Fixed. The molSumMap should only refer to external objects, and now it does.
It now clears the test for tabsumtot.
Checked in.
Confirmed that it still works when unit tests are reinstated.
Checked in again. Now at revision 276 with unit test compile flags on.

==============================================================================
29 Nov
Doing some benchmarks, continuing from earlier. 40% of the compute time is
in the sparse matrix row calculation, which is already pretty optimized.
Perhaps the data struct of the sparse matrix itself could be improved, 
but other than that I don't see much scope for improvement.
Currently set up to compile with gprof.

Also not clear why the nonscaf models don't work.

==============================================================================
30 Nov
Redid the tests. Turns out that the new MOOSE nonscaf models were correct, the
old ones were not. Compared against GENESIS EE. MOOSE is slow, though.
Also the CaMKII trace is truly ugly.

The mega model is not so nice. MOOSE has trouble going even 20 msec into the
simulation. The dt is stuck around 1.4e-7 s.

I think the basic speed issue with the rksolve is simply that the stoich
matrix data structure is not good for fast calculations. Too many lookups
and hopping around in memory. But I'll fix that later, first get mega.g
to work.

Discrepancy in mega.g remains. Seems to be due to some oddness in how GENESIS
and MOOSE deal with table input to molecules. The mega.g model needs to be
examined more closely on a couple of counts:  
- It is using SUMTOTAL, was the original doing so? 
- Its volumes are completely messed up: Are these funny values ruining the
	calculations? Specifically, would the dt problems go away if this were
	fixed?

For now let us assume that MOOSE is OK for these models, but needs 
optimization. Let us also assume it will clear the DOCQS model tests.
Next: Smoldyn surfaces again.
- Expand the test. Put in coordinates and neighbour relationships, and also
	associate molecules with surfaces.
- Implement the association of molecules with compartments.
- Check out a few simple geometries
- Set up kkit to define geometries.

Setting up script-based geometry stuff.

==============================================================================
2 Dec 2007.
Working on getting Smoldyn to read the surfaces.
Checked in. Now at revision 282 with unit test compile flags on, Smoldyn off.

==============================================================================
3 Dec 2007
Various steps to get Smoldyn to work better with MOOSE for the shapes.
Current issue is that none of the shape coords are being assigned within MOOSE.
==============================================================================
4 Dec 2007
When I create shapes standalone, the coordinate assignment works.
Turned out there was a second 'geometry' object created. Went and fixed up
the object creation code. This messed up a whole lot of unit tests (which 
were by this count themselves broken). Fixed them too. 
Checked in as revision 284 with unit test compile flags on, Smoldyn on.

Checked in as revision 285 with unit test compile flags on, Smoldyn off.

Fixed Neutral::create so that it takes the Id of the new object as an
argument. Often Id::scratchId() will do, but it will eventually be necessary
to handle across nodes. Much collateral damage and many functions to fix to
get it to work again.
Checked in as revision 286 with unit test compile flags on, Smoldyn off.

Smoldyn shape definition still stuck. Turned out to be another basic issue,
this time with the Shell. It was not handling set/get paths correctly if
they were relative to the current element or to the recent element. Fixed.
Smoldyn now sees the shape dimensions, but I can't tell if it is doing
anything interesting with them.
Checked in as revision 289 with unit test compile flags on, Smoldyn off.

At some point need to check the O3 version of the code against the 
original mega model from the AJ project. Perhaps the DOQCS version will run?
Yes, I took accession 84 and it runs. Again, somewhat slower than the old
MOOSE, but the output looks good.

One more model to test: Pragati's production scripts. Preferably to get her
parameter sensitivity analysis code to go.

==============================================================================
5 Dec 2007
Several points to fix for the model. Steven has sent a Smoldyn instantiation
too, to check against.

- Fix coord assignment for starting positions
- Figure out how to set diffusion constants for enzyme complexes
- Check rates

==============================================================================
6 Dec 2007
Now trying to bridge the Smoldyn and MOOSE setups.
1. Tried to run test_smoldyn.g on MOOSE. Doesn't do anything.
	Now does, but mix-up with scheduling, yet to resolve.
2. Compiled Smoldyn on my machine. Had to install multiple libraries.
3. Tried to run the equivalent to UpiCell.txt, which is meant to be the
	Smoldyn script equivalent of test_smoldyn.g. Crashed. Now fixed.

Implemented first pass at getstat and showstat commands to help wit the testing.
Found that sim is indeed going to 20 sec. Something wierd with Smoldyn
stepping, then. 

Checked in as revision 292 with unit test compile flags on, Smoldyn off.

Tracked down problem with inconsistent runtimes. The internal Smoldyn dt was
0.01 but the dt picked for MOOSE by the KineticManager::setupDt function
was 0.008 ish. Need to make sure Smoldyn uses the right dt.

Tried to use setupDt before setupSolver in KineticManager::reschedFuncLocal.
Fails because default rk5 method expects a solver.
If I do it the other way I delete the solver too many times. Also I don't then
get the estimated dt to put into Smoldyn.
Option 1: Just estimate dt, and put it in Smoldyn indept of the setupDt func.

==============================================================================
7 Dec 2007
Kludged together a preliminary estimation of dt, followed by the assignment
to the SmoldynHub to use for setting up the solver. Now Steven has implemented
a dt assignment function but it is not yet released.

Still problematic because dt gets reassigned when the simulation starts.
To a different value.  Not at all clear why it should do so.
OK, sorted out. I had not put in the correct function for looking up enzyme
values.

Checked in as revision 293 with unit test compile flags on, Smoldyn off.

Next puzzle: The smoldyn diagnostics look the same, but the outcome is very
different. 3x fewer P molecules in the MOOSE version, and they seem to be
diffusing much more slowly in MOOSE.

==============================================================================
13 Dec 2007
Trying to get sims to run with same rand num seed as Smoldyn. Added 'seed'
field to SmoldynHub. 

Need a way to reset or reinit the smoldyn run after creating the smoldyn
hub and setting parameters such as seed and the coords of the particles.

==============================================================================
14 Dec 2007
Much progress with the Smoldyn interface. I can now assign the coordinates
of points for initialization before starting off the model. Even better,
the simulations now seem to agree. 

Next two steps:
- Implement multiscale models combining Smoldyn engine with other solvers
	To do this I need to manage two things
	- Coordinate timestep and function calls between SmoldynHub and
	the GslInteg objects. SmoldynHub has to talk to an export list and
	an import list that Smoldyn exposes for transfer of molecules.
	- Do an extension to on the lines of the SUMTOTAL operation so that I 
	can remove molecules from MOOSE objects according to some rule.
	Furthermore, I have to link this rule to diffusion contants and the
	surface that exchanges with the Smoldyn solver.
- Implement threading to put Smoldyn on another thread so it can use its
	OpenGL interface in conjunction with MOOSE.
	The idea is that we need a barrier at the point where Smoldyn completes
	its timestep, so that the OpenGL loop in Smoldyn still believes that it
	is in control, while waiting for MOOSE to synchronize.

Checked in as revision 294 with unit test compile flags on, Smoldyn on.
Checked in as revision 295 with unit test compile flags on, Smoldyn off.

==============================================================================
16 Dec 2007

An additional step to round off the picture above:
- Implement robots: Objects that wrap a biochemical simulation in a
	different level simulation. Example is E.Coli chemotaxis. The signaling
	system computes directions, and the robot handles swimming, 
	interaction between cells, and other things.
	The robot can use either SUMTOTAL or FLUX to talk
	to molecules, and read out n using the usual message.
	- This will need some extra work on the solver side since we will
	often want arrays of robots, each with their own signaling 'brain'.


OK, now on to implementations.
Working on flux terms to handle communication between hubs. Implemented 
skeleton for the KineticHub, but still have not advanced to the point where
the flux terms are actually assigned. That will have to be a job for the
KineticManager.
Also implemented somewhat more skeletal stuff for SmoldynHub. This needs
input from Steven to complete. At this point, though, the KineticManager
should have all the hooks needed for the other work of seting up the flux 
terms.

Checked in as revision 296 with unit test compile flags on, Smoldyn off.
Next stage: the KineticManager has to scan the surfaces and shapes till
it finds the surface of interchange between the methods.
This is defined by an extra flag on the MOOSE surface. 
==============================================================================
19 Dec 2007
Begun work on connecting Smoldyn up to the smoldynHub

==============================================================================
28 Dec 2007
Implemented table TABOP as a backward compatibility feature for old GENESIS
scripts.

Checked in as revision 305 with unit test compile flags on, Smoldyn off.
==============================================================================
29 Dec 2007
Implemented symcompartment for backward compatibility with GENESIS.

Checked in as revision 306 with unit test compile flags on, Smoldyn off.

Implemented a couple of initial regression tests, and the framework for doing
a whole lot more.

Checked in as revision 307 with unit test compile flags on, Smoldyn off.

==============================================================================
30 Dec 2007
Fixed bug id 1860410 which crashes when nonexistent script file given. This
involved messing with the .ypp file, and then I had to redo the Makefile to
rebuild the parser.

Checked in as revision 308 with unit test compile flags on, Smoldyn off.

Now working on the generic readcell and channel setup capabilities.
Two obvious issues:
- Kca_mit_usb does not get created properly. Need to do some table stuff here
	as well as channel stuff.
- Even without Kca_mit_usb, the output does not match properly with genesis.
- Eliminated all channels. Even then output does not match. Suggests that
	my readcell is connecting the compartments backward.
	Reversed it. Now the MOOSE result is on the other side of the genesis
	plot. Am I missing branches? Or is it a clock issue? Or is the
	solver doing things?
	OK: Two discrepancies in settings of simple compartments: Rm and Em.
	Rm for soma is set directly in the mit.p file. MOOSE is not seeing this.
	OK, fixed both. Now the charging plots match exactly without channels.
Restored all channels except for the Kca_mit_usb. Match is pretty close but
	not perfect. Quite likely the cumulative effect of using floats in
	GENESIS. Time to check in.
	
Checked in as revision 310 with unit test compile flags on, Smoldyn off.

Still struggling with the error:
Error: cannot find field: qv.table->table[39]
The call does not seem to go through the expected places in the Genesis parser.

==============================================================================
31 Dec 2007
Fixed a number of field assignment problems, all stemming from hacks done in
the GenesisParserWrapper.cpp to handle channel assignments in tables.

Checked in as revision 311 with unit test compile flags on, Smoldyn off.
==============================================================================
1 Jan 2007

Much grunge work in implementing setupgate. It might be worth it only because
it will facilitate conversion of many old GENESIS channels automatically,
and they will be able to run with the solver. Still some way to go.
Checked in as revision 313 with unit test compile flags on, Smoldyn off.

Fixed bug found by Raamesh where 2-char object names did not get fields 
assigned.
Checked in as revision 314 with unit test compile flags on, Smoldyn off.

Fixed bug in location of created objects that turned up when I was looking
at previous bug. Put in unit tests for this case.
Checked in as revision 315 with unit test compile flags on, Smoldyn off.

Back now to issue of tabgates and vdep_channels. I don't see that the PRD_ALPHA
or SUM_ALPHA messages onto the tabgate are something I can or should
implement. Instead at a later point I need to have a more general form for
such channels that the solver can use as an external channel.

However, I need to put in another set of regression tests that exercise
each channel type one at a time. Also Nernst and calcium. 
To wrap up the 'readcell' for now, I'll eliminate this channel subtype 
from the model.

==============================================================================
2 Jan 2007

Implemented a script to go through many channel definitions and check
the responses: moose_channels.g

Much work to further clean up the handling of tables in MOOSE. This is
nearly done, now the program is stuck in the 'getpath' command.

Checked in as revision 322 with unit test compile flags on, Smoldyn off.
==============================================================================
3 Jan 2007
Implemented getpath and its unit tests.
Checked in as revision 323 with unit test compile flags on, Smoldyn off.

Fixed bug# 1861991 of successive copying of objects connected to globals.
Earlier the 2nd generation copies failed to set up messages to the global.
Incorporated into unit tests.

Checked in as revision 326 with unit test compile flags on, Smoldyn off.

Fixed bug# 1862237 of crash when field value was not specified.
Checked in as revision 327 with unit test compile flags on, Smoldyn off.

Fixed bug# 1862959 of segfault when using ^ for assignment, following 
attempt to create object of same name.
Checked in as revision 328 with unit test compile flags on, Smoldyn off.

Fixed bug# 1862925: No element found error should be shown if ce to nonexistent
element.
Checked in as revision 329 with unit test compile flags on, Smoldyn off.

Now back to the channel regression tests. Turns out all but 5 of the 21
channels work with MOOSE: a pretty good success rate. The bad ones are:
+Ca_bsg_yka: Has table/MULTGATE via the 'output' msg. should be doable.
	Also has Nernsts, though this is only set up in a readcell.
*Kahp_hip_traub91: Tabchannel, taking Ca message, but conc flag not set.
	Table values look good.
	After some munging, turned out to be a GENESIS bug: an uninitialized
	variable was being used.
	At a later stage in these tests should send a value to Ca.
Kca_hip_traub: Uses setupgate but has a PRD_ALPHA from the qv table.
K_hip_traub: Uses setup_table, setup_table3 and SUM_ALPHA. 
*Ca_hip_traub: setup_table on tabgates: does it work? This too uses lots of 
	readcell messaging. This too needs a CONCEN message to hold down.

In addition, there is a small quantitative difference in the peak for 
K_bsg_yka: Uses tweaktau then tabfill: does it work right? Should
	simply compare table entries.

So only 2 or 3 channels don't really work. The SUM_ALPHA and PRD_ALPHA are
too messy and probably too rare to make a high priority.

For now: tweak these regression tests so that each plot goes in on its
own and we can individually rate each of the channels.

I think enough work on channels. On to other things.

==============================================================================
4 Jan 2007
Attempt to get the channels set up with regression tests.
Vastly messy. First the old readcell regression test stopped working. 
Turned out to be due to the newly incorporated automatic creation of the 
solver in MOOSE, which presumably gives a more accurate answer, but 
different from the genesis one.

Then the tests seem to fail a lot more than they look like they should.
Implemented a fractional error margin in the neardiff test. Much better.
Included lots of plots and regression stuff in the subversion checkin.
Checked in as revision 330 with unit test compile flags on, Smoldyn off.

==============================================================================
6 Jan 2007
Implemented passing of globals to readcell. This resolves bug# 1860797
Implemented regression test for this
Reorganized the regressions directory a bit.
Checked in as revision 337 with unit test compile flags on, Smoldyn off.

Fixed implementation of pushe and pope. This resolves bug# 1864443
Implemented unit tests too.
Checked in as revision 338 with unit test compile flags on, Smoldyn off.

Fixed message passing aliases and an initialization bug in SynChan.
Implemented a little regression test for it. There is a 1 dt difference
in the output of the moose and genesis synchans.
There may still be remaining issues with the messaging in synchans reported
by Niraj, but this is a first pass regression test for synchans.

I think I have found the source of the problem. Turns out to be a nasty one:
a problem with message management. When we have a new message with a 
different recvfunc, it is assigned to a linked msgsrc at the end of the 
msgsrc vector. Then the conn is inserted, but updates happen only after the
linked msgsrc, even though the intervening older msgsrcs may now refer
to conns before the linked one. Hence the error.
Can't do updates based on conn indices. Have to do updates based on 
src sequence, starting from originating src and not its linked entries.
Need to pass extra info in to do so.

Implemented and this seems to work partway. It passes the obvious messaging
unit tests but croaks when we get to scheduling. Possibly has issues with
creation and removal of messages, which is done a lot in scheduling.
See dropConn in MsgSrc.h. Should be a MsgSrc.cpp. But it doesn't seem likely,
see calling function SimpleElement.cpp:525: deleteHalfConn.

==============================================================================
7 Jan 2007

The attempt to fix the shared messaging/synchan bug was spiralling into
a tangle because of the way the shared messaging is implemented. This really
awaits the proposed messaging cleanup. In the meantime, checked in the
earler attempt as a branch named /moose/branches/moose_synchan_bug
at revision 341. Then reverted back. Then did a minor fix to the ordering
of the finfos that should patch over the problem till the true fix is done.

Checked in as revision 342 with unit test compile flags on, Smoldyn off.

Some cleanup of demos and regression tests.
Checked in as revision 346 with unit test compile flags on, Smoldyn off.

The kholodenko model dumps core when run without GSL. Issues with 
KineticHandler.

==============================================================================
8 Jan 2007
The release is done!!!!
Fixed the non-GSL version for kinetic simulations. This turned up issues
with the timestep calculation. Improved but not perfect.

Checked in as revision 364 with unit test compile flags on, Smoldyn off.

Fixed bug# 1866549 which was a problem with copy onto objects when using
an absolute path. Put it into unit tests.

Checked in as revision 365 with unit test compile flags on, Smoldyn off.

==============================================================================
11 Jan 2007.
Attempting to fix compilation problem with O3 and GSL. Perhaps step down to
O2. That too fails. So does O. So now trying to compile deugger with -O. 
Should help us track bug.

==============================================================================
13 Jan 2007
Fixed O3 compilation (32 bit version) halfway. Now moose starts up and 
runs OK, but on quitting it dumps core. Something ugly to do with the
MethodInfo structure, I think it is a gcc or STL bug.

Checked in as revision 374 with unit test compile flags off, Smoldyn off, O3.

Found problem. There is another structure called MethodInfo defined in the
biophysics/Cell.h file. This seems to be confusing the compiler, which should
actually have complained about there being two structures with the same
name. Anyway, the system must have been trying to write the data from one into
the struct of the other, and stomping on bad memory. Now runs with O3.
O3 has a mixed bag with the regression tests. The problem with 'copy'
remains, causing it to fail on two of the tests. The GSL is not compiled in,
causing failure with the kholodenko test. Anyway, I'll check in the current
fixes.

Checked in as revision 375 with unit test compile flags off, Smoldyn off, O3.

Fixed copy bug. This fixes all but the moose_kholodenko.g regression test,
which depends on GSL. This is a good version of the O3 binaries.

Compiled with GSL libraries. This clears all the regression tests. This
too is a good version of the O3 binaries.

Checked in as revision 376 with unit test compile flags off, Smoldyn off, O3,GSL

Cleaned up the Makefiles a bit. For some reason the GSL libraries were being
brought in at the main Makefile. They should be done locally unless we have
multiple GSL dependencies, in which case the flags should be passed in from the
main Makefile. We'll need to do this systematically at some point.

Recompiled the whole mess back down to -g, no optimization, so as to get 
back to using unit tests and doing development. This clears unit tests and
regression tests.

Checked in as revision 377 with unit test flags on, Smoldyn off, -g ,GSL

==============================================================================
24 Jan 2008
Set up a branch, msg_2008, for doing development on improved messaging design.
This will mess up everything so best to do it in isolation.
This is based on revision 390.
The first revision here is 391.

Now working on incremental implementation as far as it can go. For now,
setting up new data structs for Conn without messing with the other parts
of the message. Still unable to compile, see SimpleElement.cpp:465
==============================================================================
29 Jan 2008.
Conn now set up, working after numerous headaches arising from deprecating
the Conn::sourceIndex( Element* ) function. Cleared unit and regression tests.

Checked in as revision 395 with unit test flags on, Smoldyn off, -g, GSL

Next to flesh out ConnInfo and its variants.
==============================================================================
30 Jan 2008.
First pass done for ConnInfo and SimpleConnInfo. The latter is now 
automatically inserted as a global pointer in regular conns, which is what they
all are for now. However, there is an element::connect function which 
does not do so. This function needs to be deprecated.

Stuff that can still be done before breaking everything:
	* FuncList code. Note I had done a FuncData struct for parallel stuff.
		* Has to harvest all functions in SharedFinfos
		* Has to manage the FuncLists
		* Has to provide a way to sync lists across nodes.
	* Slot upgrade to include FuncList specification
	- Add further kinds of ConnInfos that could in principle handle
		complex messaging.
	* Change Conn access to pointers.

Stuff to look at before the transition:
	* Element::connect function. It does not have a way to tie 
		src/dest index to Conns.
		- Checked. Need to work out how we're handling Conns to figure
		this one out.
	- MsgSrc/Dest Id sorting out for ConnInfos

Stuff that will break everything
	- Replace MsgSrc and MsgDest with new forms.

Stuff to do after transition
	- Benchmark simple messaging with old and new versions.


Perhaps I should use a pointer for Conns. Several issues either way.
- Will need to refer to a virtual class ptr for ConnInfo anyway for data access
Minor memory considerations
	- Save one ptr in SimpleConn struct, lose it again in virtual table.
	- Possibly save a uint in element index for SimpleConn.
	- Lose space in ptr table and then allocation info.
Speed considerations
	- One or two less indirections for data
	- one more indirection for element info.
	- Cache hopping if conns are widely separated/created far apart.
Organization considerations
	- Cleaner data structs and access. Expandable.
	- Memory management headaches: frees and copies
	- May need special constructor to be efficient.

For now hold off. Doing this will break a lot of stuff.


Setting off on FuncList code. Turns out we have a FuncList name, so I
called it the FuncVec. To set things up automatically in the cinfo 
initialization I still need to
	* modify Cinfo::Cinfo to set up a funcVec for all Shared and 
		Src Finfos.
	* Add a virtual function to the Finfo base class to set up and
		incorporate a FuncVec.
	- Add operations for Ftype::parFuncSync  and Ftype::parFuncAsync
==============================================================================
31 Jan 2008.

Checked in first part of FuncVec implementation,
as revision 398 with unit test flags on, Smoldyn off, -g, GSL

Checked in second part of FuncVec implementation. Still need to complete
other messy tie-ups needed for handling FuncVecs for SharedFinfo.

Checked in as revision 399 with unit test flags on, Smoldyn off, -g, GSL

Now begun on setting up Slots. This involves changes everywhere.
A huge number of hacks at this point. Especially when it comes to
assigning msgIndexes.

Now I've marched the compilation through to Compartment.cpp

==============================================================================
1 Feb 2008
Now done biophysics, into kinetics.
Now done the whole lot. Compiles and runs. When I convert to the new form I
will have to undo some intermediate hacks done to get it to work.

Checked in as revision 400 with unit test flags on, Smoldyn off, -g, GSL

Another thing to do before messing it all up: convert conns to pointers.

Got through: parser, basecode, biophysics, kinetics, all the rest.
Astonishingly it ran and cleared unit tests first time.
Checked in as revision 402 with unit test flags on, Smoldyn off, -g, GSL

Designing iteration through Conn vector and through composite Conns on it.
- Iterate through vector as usual. Need to check for empty Conns.
- Iterate then through special Conns, each of which have their own
	iterators.
- The iterator needs to present a Conn to the target: A simple looking Conn
	with all the usual access funcs.
- We need to be thread-safe. The iterator must refer to the primary Conn.


==============================================================================
2 Feb
Considering a still more radical overhaul of messaging, now possible because
conns are done through pointers. This is the old idea that the conn info
should be shared. Now doable because both sides of the message can point to the
same Conn. In principle this can also do away with the need for 
Conn indexes, which were originally so that the two sides of the conn could
point to each other. 
Cases where indexing remains critical
	- Synapses and any conn-specific target operations.
		We need a stable index here to look up weight etc.
		Note that the index need not be tied to position in Conn vector.
	- SendTo calls
		- Most of these are return calls, trivially (and faster)
		handled through the conn pointer itself if it has full info.
		- Some of these, like synapses, have conn-specific data
		to go out on specific lines. These include solver control
		of specific zombies, and shell sending distinct info to
		specific nodes.
		Here the index does need to be tied to position in Conn
		vector, so it can look it up.
		- Here is an example. Solvers send messages to zombies that
		are used for bidirectional value assignment.
			- If solver calls a zombie:
				Solver must know which internal object is
				tied to which Conn#
			- If a zombie calls a solver:
				Target (on solver) must have indexing so that
				solver knows which zombie made the request.

A related point: If we do away with Conn indices and have a unitary Conn
seen by both source and dest of each message, we need extra care in our
use of 'source' and 'target' terms. This is doable in the code, provided
we have a well-defined direction in which all messages always must go,
even if they are nominally bidirectional like shared messages.

==============================================================================
4 Feb 2008
Wrote a preliminary document for describing messaging for MOOSE programmers.

Issues to solve in the connections
- Separate MsgSrc/Dest tables?
	No. Too messy. have just a Msg table.
- Related: How to identify Src/Dest in Slots?
	Problem goes away if there is just a Msg table.
- How to type-protect Slots?
- How to manage flexible allocation of MsgSrc/Dest?
- How do we ensure that SharedMessages are always connected with the same
	directionality?
	Take the first entry in the SharedMessage. If it is a Src, the
	Shared Msg is a source, and vice versa.
- What is target/dest in a Conn that can be seen from either side?
	The ConnTainer::conn() function takes an argument indicating if it is
	forward or reverse direction, as per info in each Msg.
	Thus the ConnTainer creates different classes of Conn depending on
	direction.
- Can we identify when targets need indexing from Conns, and use the
	appropriate Conns on the fly?
	Not on the fly. But the target Finfo will have enough info to decide.
- How to manage Conn indexing in messages with multiple kinds of Conn? 
	Double index? Cumulative index?
- How to handle Conn iteration on Send?
	See below.
- How to protect against iterator corruption when operations modify conns?
	See below.
- How to set up the msg indices? We need to pre-allocate a certain number
	of msg slots, but many of them are rarely used so it would be
	wasteful to always allocate all. One option is a 'prealloc' 
	argument somewhere in the Cinfo. Somewhere a check will be needed...
	OK, put the check at the message add or respondToAdd step.

==============================================================================
5 Feb 2008

Kinds of aggregate Conns (ConnTainers)
Simple Conns:
- VectorConn: Just a set of simple Conns.
- RegionConnectSimpleConn: Manages regionconnect between simple objects.
	Probably just a VectorConn with additional info about setup call.
Simple objects to arrays:
- One2SomeConn: Single simple Element to some subset in an array.
- One2AllConn: Single simple Element to all in an array.
Arrays to Arrays:
- One2OneMapConn: Both sides are arrays, and there is a one-to-one mapping.
- SparseMatrixConn: Sparse connectivity matrix between arrays
- MatrixConn: Dense connectivity matrix between arrays
- All2AllConn: Both sides are arrays and there is complete connectivity.
- GeomRuleConn: Geometric rule connection. Static vs dynamic.
- RandMatrixConn: Partial connectivity matrix with random rules
- RegionConnectConn: Implementation of regionconnect between arrays.

Iteration Requirements:
- Sequentially go through all connections (send)
- Go to a specific connection, identified by src and dest. Search is OK.
- Go to a specific connection, identified by index. Must be fast.
- Thread safe. Must store info locally.
- Handle insertions and removals. Options here are: 
	- queue for operations.
		Register # of iterators, and handle queue when they go to zero.
		Issue that the queued conns may point to defunct objects...
		So queue would have to be entire operation, and managed by
		clock ticks, not on individual Msgs
	- Register each active iterator and update it as needed
		Expensive.
	- Flag for removed entries. Doesn't deal with insertions. 
	- Integer indexing. Slow.

If I use a Conn as an iterator, I will need distinct variants for each
of these. That means I'll still need the 3-tier version: A ConnIterator,
which is on the stack, a Conn, which is what the RecvFuncs see, and then
the aggregate ConnTainers.

==============================================================================
7 Feb

Things taking shape. Some more qs:
- At what level do we specify the type of ConnTainer? Does the user do
it explicitly (ugh) or do have special funcs that do certain containers,
and let the Msg figure out the rest itself (ugh too).
	- User specifies indirectly, by the src, dest and form of the 
		message 'add' command (post-genesis especially). For example 
		a single to an array[]
		or just array object would set up a One2AllConn. All this needs
		to be parsed ahead of time.
	- User also specifies indirectly by the use of special commands like
		regionconnect.
	- System specifies magically when doing createmap type commands.
	- Msg has to do some figuring if the src or dest is array, in case
		there is an expandable array connection like 
		SparseMatrix, FullMatrix, RandMatrix, One2Some.
		Actually, the operation on Msg should be selected by virtual func
		of Element* so that it does add, addOne2Array, addOne2All etc.


==============================================================================
8 Feb 2008

Current best implementation is All2AllConn.h. It handles the issue of reverse
messaging. 
Need to use this to look closely at VectorConns to see if they still work.
Seems OK.

Now coordinating many code files to begin to pull together the new messaging
stuff. Looking at send.cpp
==============================================================================
9 Feb 2008
Slow progress on VectorConn, which is the most like the old connection scheme.
Working through the functions, the Drop and Traverse functions need to know
the target Msg. This can be done with no extra storage if we template it
in, but if we use local VectorConnEntries instead of pointers we have to
store the remote msg info explicitly. Also we need to decide if the 
two ConnEntries are going to be complementary like the old variant, or
comprehensive with full info. If the latter then we may need to go to the
pointer variant.

I'll keep this issue pending and work through the create/delete/find process
on the All2All to see where things should match up.

Some thoughts:
Need to expand the interface for Conn* to include src and dest Msg#.
Should shift the SimpleConns back to the ConnTainer vector because they
are isomorphic to OneToOne Conns. This will also bring uniformity in the
assumption that each ConnTainer has a unique src and dest element. We can
optimize stuff later.
One issue is that the higher-level description for things like RegionConnect
won't work as planned unless all the created SimpleConns have a pointer to
the RegionConnect object. Hm.


Starting to take shape.
Status:
Msg.cpp, .h: Need to figure out how it stores isDest flag.
ConnTainer.h: OK
Conn.h: OK	:
SimpleConn.h: OK. May need to implement .cpp
All2AllConn.h: OK. May need to implement .cpp
Element: Getting there
SimpleElement: Getting there
send.cpp: OK
send.h: Need to put in the higher N sends.
Finfo.h: Much to do. Shifting a lot of things out of it, let the Msg
	handle all the operations relating to Conns. Add operations remain.
SrcFinfo.cpp: All to do: esp, add func.
DestFinfo.cpp: All to do.
SharedFinfo.cpp: All to do, esp assigning isDest.


==============================================================================
10 Feb 2008.

Marching through. Now doing compilation.

Now working on Copy.cpp.

The ConnTainer::add commands for SimpleConnTainer and All2AllConnTainer
are wrong.

Still need to fix issues of handling 'next' in Msg.

Copy.cpp compiles but only after excising several aspects of copy handling,
especially to do with msg to globals that are not in the tree.

==============================================================================
11 Feb 2008.

Moved the isDest flag to FuncVec, which is a natural place for it.
Still struggling with handling of 'next' Msgs.

Compilation proceeding up to DynamicFinfo.cpp. About halfway through the
.cpp files of the basecode.

==============================================================================
13 Feb 2008

DynamicFinfo is a mess. Currently trying to clean up the 'add' function
at the point where it figures out the FuncId for the trig func, which is
of course created using templating.
For now I'll have to bypass it in order to compile.
Much bypassing later, now getting to UnitTests.cpp. This too is full of stuff
that will need complete rewriting.
Bypassed. Now masses of errors in SharedFinfo.

==============================================================================
14 Feb 2008
Compilation has reached UnitTests in basecode. I should check in as it is
a private branch and there has been so much work.

Checked in as revision 411 with unit test flags on, Smoldyn off, -g, GSL

==============================================================================
18 Feb 2008
Slowly inching through the debugging/compiling process for UnitTests.cpp

==============================================================================
19 Feb 2008
Completed compilation of basecode. Much of the UnitTests have been removed,
because the calls don't make sense in the new messaging.
Checked in as revision 413 with unit test flags on, Smoldyn off, -g, GSL

==============================================================================
23 Feb 2008
Completed compilation of Shell. Several things have been left only as
placeholders, specially stuff to do with array operations like planarconnect.

Checked in as revision 417 with unit test flags on, Smoldyn off, -g, GSL

==============================================================================
24 Feb 2008
Completed remaining library compilation: element and maindir. Huge number of
errors remain in the linking stage.

Checked in as revision 418 with unit test flags on, Smoldyn off, -g, GSL

Compiled and linked. It crashes at once when run, but major step forward
anyway.
Checked in as revision 419 with unit test flags on, Smoldyn off, -g, GSL

Slow steady progress going through unit tests.

==============================================================================
25 Feb 2008
Sent first message, after considerable fixing up of related code. However
~Msg() barfs. Long way to go yet.
Checked in as revision 420 with unit test flags on, Smoldyn off, -g, GSL

Fixed ~Msg. Involved a fair amount of fixing to get the logic of the isDest
sorted out on various Finfos and in the initialization code. Now we're
partly into the class formation tests.

Checked in as revision 421 with unit test flags on, Smoldyn off, -g, GSL

Somewhat stuck some way on in FinfoTest, I suspect that a bad ptr access
has corrupted things. Yup, valgrind confirms that I'm sending data that has
been freed.

==============================================================================
26 Feb
Fixed. It was a problem with the ~Msg(), which was doing a dropAll. Cannot do
so because the Msg vector gets resized, and we don't want to lose messages
when that happens.
New issue: We can attempt to send messages that have not yet been allocated.
One option is to always put SrcFinfos first. As all elements must be a child
of something, the Msg array will always have the places allocated. But this
won't work if we interleave src and dests, which will happen for inheritance.

Could force all Srcs to be allocated during the create function.
Did so. Now have the issue of ballooning # of Msg slots preallocated. Defer.

Checked in as revision 422 with unit test flags on, Smoldyn off, -g, GSL

More serious problem: Need to sort out multi-target-class messages that use
the next_ field.
Linked list with ptrs: 
	- Need special updates in copies
	- Need special updates when deleting.
	- But all these are local to the msg.
Linked list on main Msg array
	- Need special updates when inserting a new msg.
	- Not local to the msg.

==============================================================================
27 Feb 2008
More unit tests now work. Messaging with Finfo::add now works.
Current issue is with the messaging into regular ValueFinfosb in other works
how the DynamicFinfo handles it. See line 800 of UnitTests.cpp

Checked in as revision 423 with unit test flags on, Smoldyn off, -g, GSL

==============================================================================
28 Feb 2008
Currently stuck at UnitTest.cpp:830, but the real issue is that in Send.h
a FuncVec claims isDest() == 0 when it clearly should be 1.

==============================================================================
29 Feb 2008
Fixed the bug. It had ramifications in many places:
Cleaned up FuncVec initialization.
Cleaned up DynamicFinfo message handling.
Cleaned up earlier unit tests
Checked in as revision 424 with unit test flags on, Smoldyn off, -g, GSL

Now bug has moved on to another stage, line 863.
This bug looks like it has to do with other cases for adding dynamic finfo:
adding a trigger message to a value field.

This boils down to asking how we are going to represent trigger func ids.
At present there are no such ids, but we could easily generate the actual
function in the FuncVec.
For the respondToAdd I could: 
	- return the original func id with the idea that the requester knows
	what it wants
	- create a set of dummy funcIds which signify that we really want the
	trigger func
	- Create an additional funcVec with its own id, that holds the 
		trigFunc. The original funcVec would point to this
		id if it exists. This would be an additional verification that
		the Finfo supports trig funcs.

Implemented the third option, it is pretty clean.
Got trig messages into the DynamicFinfo to work.
Next: 
	- Add messages to go out of the DynamicFinfo
	- Handle Shared messages into dynamicFinfo.

Decided to get rid of single outgoing or single trig incoming messages
to DynamicFinfo: complicated and unlikely.

That advanced things to SharedFinfos. Where they are stuck.
==============================================================================
1 March 2008
Fixed SharedFinfos. One key restriction now is that we cannot have a Shared
Finfo sending to itself even on a different element. This is because we
require each Finfo to have directionality: it is either a src or a dest.

Checked in as revision 425 with unit test flags on, Smoldyn off, -g, GSL

Now stuck in LookupFinfo.cpp:330

==============================================================================
2 March 2008
Progress on LookupFinfo. Current issue is that DynamicFinfo needs to know
when to use the original RecvFunc of the finfo, and when to generate one
that uses the lookup index.

Got LookupFinfo to work and clear unit tests. Had to add another FuncVec
for handling the LookupFinfo recvFuncs.
Checked in as revision 426 with unit test flags on, Smoldyn off, -g, GSL

Working on Copy, but it needs to test the elaborate stuff between channels and
Gates. So I had to compile in parts of the biophysics library, which in turn
depend on the builtins library. Now at least it compiles, but the unit tests
are still stuck.
Checked in as revision 427 with unit test flags on, Smoldyn off, -g, GSL

Continuing the attempt to get Copy working. Turns out that the Compartments
etc from biophysics need the scheduling stuff to work. So those too had to
be fixed up and compiled in. That done, the unit tests are still stuck.
Checked in as revision 428 with unit test flags on, Smoldyn off, -g, GSL

Now it is stuck because the sched stuff has not yet been initialized in main.

I need to redo these 'copy' unit tests without any of these dependencies.
One should not need any of this in the basecode unit tests.

Did major overhaul of unit tests for Copy, and it now clears them.
Still need to incorporate more aspects of messaging and DynamicFinfos.
Also issues of messages going to globals need to be tested.
Checked in as revision 429 with unit test flags on, Smoldyn off, -g, GSL

Some loose ends:
	- Msg::target. The pair< Element*, unsigned int> is awkward.
		Subha has suggested a solution for this
	- Need consistent use of index in sends. Where do I get the index from?
		Same solution as above.
	- Hide all uses of iterating through Msg::c_ except in sends.
	- Msg::next. Fill up the implementation
		Needs clarity.
	- Need to fix the proliferation of Msgs.
		Needs implementation to be sorted.

==============================================================================
4 March 2008
Cleaning up deletes. Need to use the STL erase-remove type operation to 
do so without messing up msg->c_ vector. See Msg.cpp:201.

Deletes now working. Still need to fully test that and the copies. Still
niggling issues with the 'next' in msgs. But the tests now clear till Shell.

Checked in as revision 432 with unit test flags on, Smoldyn off, -g, GSL


Msg::next implementation possibilities:
- Separate Src and Dest, keep next on Src.
	- Need unique, compiled in Src for quick sends.
	- Need to prealloc Src so we know where to put next?
	- Dest used for all DestFinfos and SharedFinfos without any src. 
	- Need it only for traversal, so a little speed hit not bad
	- Decide which to look up by comparing fv_ on msg ?
	- Use -ve #s for Dest, use a map to look up the vector< ConnTainer* >.
- Separate Src, Dest, Next.
	- Src and dest alloced as needed
	- Src has predefined indices
	- Dest does a scan-through to find match (minimal # are defined)
	- Next just adds on to end as needed.
	- Messy to manage.
- Single Src, Dest, Next
	- Src preallocated to required #
	- numSrc_ stored in Cinfo.
	- Separate index in SimpleElement to keep track of end of Dest.
	- Next accessed end of Src, no particular juggling needed.
	- Dest accessed at end of Next. Keep the index of end of Next handy
		for starting with Dest and other things.
	- Dest accessed by scan-through to desired #. So it does not need
		any juggling when we insert additional 'next' entries.
	+ Assign msg indices to all Finfos as at present, but do the 
		Srcs first.
	+ Use the same index for the Finfo and the Msg. This means
		copying out the basecode Finfos for inheritance.
	- Need separate access to all 'Dest' msgs. Much cleanup in code.

==============================================================================
5 March 2008
Did implementation of Msg::next and associated code. Now it compiles but
we're back to trying to go through the first few unit tests.

==============================================================================
6 March 2008
Checked in as revision 433 with unit test flags on, Smoldyn off, -g, GSL

Looks like I need to convert destMsg into a separate class and separate
vector. The current arrangement is too messy and prone to error. It may
even save space to convert.

Now things are moving toward the first option above. The really nasty part of
this is that numbers are used for two things: (src) Msgs and Dests. Worse,
sometimes Msgs are at the dest and sometimes not.

Now if we separate the arrays, the thing to do is to put the dests into a 
map, in which case the dest is not even a message, but a vector< ConnTainer* >&
This is no worse than the above two issues, but by putting a distinct
type on it certainly looks uglier. Forces the problems to attention.

OK. This is all fine, provided that there is a simple, uniform API that
hides it. If we use this we cannot use Msg as a handle for other operations
any more.

I think the only thing outside functions need is the target list. This
brings us to the next issue: How to handle Element arrays? Should we treat
Elements as ConnTainers, where each one may be an entire array? We would
need an ElementIter as an orthlog of Conn, providing the Element API including
its current index. We could provide sparse as well as full ArrayElement
variants. Bad thing with all this is the extra indirection. But could
we parallelize the Sends? OK, deal with this later. For now, provide target
list. Element::targets( int msgNum ) and Element::targets( const string name )
How about nodes/edges view. Msg was the original idea for an edge, but actually
it should be a ConnTainer. Or a Conn, that handles an entire 
vector< ConnTainer* > or multiple of them, as needed.

void Conn::increment() // goes one element and index at a time.
void Conn::nextElement() // goes one element at a time, skips indices.
const ConnTainer* Conn::connTainer(); // Gives the current ConnTainer of Conn.

Conn* Element::targets( int msgNum );
Conn* Element::targets( const string& finfoname );

// for later:
Conn* Element::targets( int msgNum, id elm ); // A true edge, between 2 elms.
Conn* Element::targets( id elm ); // A true edge, between 2 elms, any finfos.
Conn* Element::targets( int msgNum, int eIndex );

int Finfo::msg();
Finfo* Element::findFinfo( int msgNum );


==============================================================================
7 March
Implementation of revised messages and revised 'targets' nearly done.
Going through compilation.

Compiled. Back to grinding through unit tests.

More API cleanups needed:
bool Element::add( int msg1, Element* e2, int msg2 );
bool Element::add( const string& f1, Element* e2, const string& f2 );

bool Element::drop( int msg, unsigned int doomed );
bool Element::drop( int msg, const ConnTainer* doomed );
bool Element::dropAll( int msg );
bool Element::dropAll( const string& finfo );

==============================================================================
8 March
Most of these updated things implemented.
Checked in as revision 435 with unit test flags on, Smoldyn off, -g, GSL

Now stuck in a nasty memory bug which seems to be due to trying to access
an already deleted Finfo in the UnitTests. With valgrind I fixed one
of the problems, but the other is still confusing.
==============================================================================
9 March 2008
Many ugly bugs fixed in the process of getting past these early
Unit Tests. Valgrind helped a lot. The UnitTests.cpp is OK now.

Some more cleanup. Much to my astonishment, it suddenly progressed through
to the command line, clearing lots of parser tests. Hooray!
Even valgrind is pretty happy about it. Lots of leaks at the end, but
no bad stuff through the tests.

More unit tests to add:
* Direct test of handling 'next' msg
* Copy tests should use messages between objects and verify them
* Copy tests should check DynamicFinfo copies too
- Copy tests need to handle copies to globals.

Next (big) steps:
	+ Complete unit tests listed above.
	- Fix Element/Element Index confusion.
	- Include rest of code 
		- Unit tests
		- Regression tests
		- Benchmarks
	- Merge back with main distro
	- Incorporate arrays.
		- Lots of unit tests for arrays too.
	- Incorporate proper volume handling for kinetics

Copy tests reveal nasty bugs with freeing dynamic finfos. Perhaps I have
been using the same one twice. In cleaning up setupDynamicFinfo it now
breaks in LookupFinfo unit tests.

Anyway, network is now up so I'll check stuff in.
LookupFinfo stuff now works.
Copy stuff problem is because I have used the same DynamicFinfo twice in 
the same finfos_ vector

OK, sorted it out. The SimpleElement::innerCopy was both assigning the
Finfo and calling addFinfo. This bug took ages to fix.

Checked in as revision 437 with unit test flags on, Smoldyn off, -g, GSL

Bunch of crucial files were left out of the previous commit. Added.

Checked in as revision 438 with unit test flags on, Smoldyn off, -g, GSL

Looking at the rest of the code. There isn't much: just kinetics and
example, and to finish up biophysics.

Possibilities to resolve Element/Element Index stuff:
- A wrapper Element, as I used earlier for Arrays. 
	- Additional indirection.
	- Additional messy code.
- An Eref class like pair< Element*, unsigned int >
	Pass as reference in argument for all the functions,
	including sends, that used to use Elements, and now also bodge in the
	index somehow.
	- Actually references may have other overhead. Best to keep it simple.
	- Additional field data to pass around. Don't know if it matters.

Other features:
	- Define a special index (UINT_MAX?) to indicate entire array.


Much work done on converting to Eref for send, set and get. Conn also 
returns Eref rather than Element and Eindex.
Checked in as revision 439 with unit test flags on, Smoldyn off, -g, GSL

==============================================================================
10 March 2008

Continuing conversion to Eref. Completed basecode, shell, and element dirs.
Checked in as revision 440 with unit test flags on, Smoldyn off, -g, GSL

==============================================================================
11 March.
Continuing Eref conversion. Adding in kinetics stuff.
Compiled Kinetic Hub. More on the way.

==============================================================================
13 March.
Finally done Eref conversion, including kinetics stuff and the GSL solver. 
The biophysics solver stuff has been left out for now.
Clears unit tests right off.

==============================================================================
14 March.
Converted a few more of the non-solver objects in the biophysics directory.
Now working with the merge back into the main MOOSE tree.

Checked in as revision 444 with unit test flags on, Smoldyn off, -g, GSL

Working through other unit tests. Currently stuck right at the end of
scheduling.

==============================================================================
15 March
Tracked down a nasty bug in the send code: If Msg::next_ != 0 but ct_.size()==0
then the send does not happen.

Replaced with a check that the funcId is good. Not an ideal solution but 
it clears the sched tests now. More tests fail.
Checked in as revision 445 with unit test flags on, Smoldyn off, -g, GSL

==============================================================================
16 March.

Some cleanups to do:
	- More operations, especially many of the new Element:: operations,
	need to be handled by Eref instead. These include add, drop, target
	and so on.
	- All the fields need their own msg_ number. The DynamicFinfo should
	not invent any such numbers, Problem here with handling return value
	requests, since this needs a full Msg structure.

Working through KineticSolver unit tests. Issue now is that the solver
has substituted access functions for fields without providing matching
trig and other funcs. Should ideally automate all these variants.

Posit a Hub base class. It has to provide a common interface for one or
more of the following:
- handling regular messages
	- src
	- dest
	- shared.
- handling fields
	- set
	- get
- handling incoming messages to DynamicFinfos:
	- set
	- trigger/return.

Currently we replace the entire ThisFinfo of the zombie, and in that all
the Finfos can be updated. This is a loosely structured way of doing it
and needs a lot of additional work.

Ideally we should be able to use the templates to do all this without user
effort. The solver writer would still need to write to an interface, but
to a much tighter one.

Possible interfaces:
	- a set of Finfos for the Hub, much like the current ones, which
	  specify how to get at each individual value and function.
	- a mirror set of object definitions for each object taken over
	  by the solver. I do something like this for the SmoldynHub.
	- a set of virtual functions in the hub which somehow manage to
 	  account for all the functions and fields. 

For now slowly working on fix  for unit test issues with KineticHub.
The fix entails making a proper class for the arrival objects, since this will
also generate the proper Ids for trigger etc. Have to do it using static
initialization else it will mess up the FuncIds at run time. In fact need
a way to lock down funcIds after initialization.

==============================================================================
17 March 2008
Partial fix to issue of KineticHub set up for the replacement Molecule fields.
This does not involve a static Cinfo, but instead a static SolveFinfo where
the necessary initialization of FuncIds happens. Works, clears unit tests.

Checked in as revision 446 with unit test flags on, Smoldyn off, -g, GSL

Working now on regression tests. Fixed an infinite loop in the kholodenko test
for the kinetics solver. Many of the biophysics tests still fail in regression.

Checked in as revision 448 with unit test flags on, Smoldyn off, -g, GSL

Fixed a bug (SourceForge# 1916705) in showmsg.
Checked in as revision 451 with unit test flags on, Smoldyn off, -g, GSL

==============================================================================
28 Apr 2008
Trying to clear old regression tests with kinetic models. Stuck. Turns out
that there are problems with wildcarding so it is not saving the output.
Basic doublehash works but seems to foul up when doing the conditionals with
square braces. Lots of fixes to do here.
==============================================================================
29 Apr 2008

Re-implementing the wildcards with ids. Much cleaner.

Checked in as revision 462 with unit test flags on, Smoldyn off, -g, GSL

Fixed up and tested some additional stuff for doing wildcards against
field values.
Checked in as revision 463 with unit test flags on, Smoldyn off, -g, GSL

==============================================================================
30 Apr 2008
Setting up array messages.
*  bool SrcFinfo::add( Element* e, Element* destElm, const Finfo* destFinfo )
	should use Erefs instead of Element*, so that we get index info.
* Likewise, respondToAdd
- Should write a function to generate a ConnTainer based on src and dest
	erefs and the other args to each msg.
	- Select appropriate type of ConnTainer depending on indices.
	- In some cases want to look up an existing ConnTainer and add to it,
		rather than make a new one.
		- So the subsequent Msg::add may need to be conditional.
	- Or, a single function like 
		Msg::add( e, destElm, msg_, destMsg, srcIndex, destIndex,
			srcFuncId, destFuncId );
	

Changed arguments to add and respondToAdd to use Erefs rather than Element*.
Compiled and cleared unit tests.

Checked in as revision 464 with unit test flags on, Smoldyn off, -g, GSL

Several issues now with handling array messages:
	- The 'add' function is implemented directly in the 
		GenesisParserWrapper rather than the Shell where it should be.
	- The 'add' function has no way to specify what kind of connection
		to set up. Several of the options can be figured out from
		the element specifications, more if there were wildcards
		in the arguments.
	- The 'add' function is set up to use the Finfo::add. Fine, as long
		as the Finfo::add can pass in a desired Conn type.
	- We need subsequent access to the ConnTainer.	

==============================================================================
1 May 2008
Discussed the array messages. Plan is to have an optional extension to the
'add' function for specifying exactly which ConnTainer to use, otherwise use
some sensible defaults.

Will separate out the 'add' function from genesisParser and put in a 
shell command to issue it.

==============================================================================
2 May 2008
Implemented skeleton of the One2ManyConn stuff. Also implemented the
Fid class, to specify a field including the element Id it is on.
Passes unit tests, still to implement new set of tests for One2Many.

Checked in as revision 465 with unit test flags on, Smoldyn off, -g, GSL

Oops, forgot to add in the new files to svn. Check those in as well.

Checked in as revision 466 with unit test flags on, Smoldyn off, -g, GSL

==============================================================================
3 May 2008
Working on createmap. It comes to Shell::createArray which should use
a one-to-many message

Testing if the system really does use Element::add and family. Yes, in
multiple places. But this function call is flawed because it does not
have indexing info.

I should then check where the system uses other variants of add, and 
phase those out.

==============================================================================
4 May 2008

Some more thought on design needed here. I have a proliferation of handle
classes for index and field info, and several of the older functions should
really use those.

Fid: Id + field index (Needs more work so that all fields have indices)
Eref: Element* + Eindex. Currently a rather bare class
Id: Element lookup index + Eindex. Pretty well populated and well used.

One option is to remove all the message related utility ops from Element*
and put them into Eref, so that Eindex is always there. Additional
merit is that these are just utility functions, so do not percolate to
derived classes.

Done. Major cleanup involved, still at it.
One issue is that we now rely on a valid Finfo->msg(). This is OK for
src and dest Msgs, but Value msgs and dynamic msgs are not set up.

Even after fixing up the msg_ field for value msgs, I still have a problem in 
KineticHub.cpp when I try to use the msg_ field to set up a message. msg_
for the target is still INT_MAX.

For a temporary fix, I replaced the add msg call with the variant that uses
strings. Slower, but works and clears unit tests. Time to check in this mess.

Checked in as revision 467 with unit test flags on, Smoldyn off, -g, GSL

A preliminary test with a script in DEMOS/array gives the correct # of
array children from createmap, but their indices are all 0.

==============================================================================
6 May 2008
Put in first few unit tests for ArrayElements, fixed a few bugs. Now we
can create and list the ArrayElements. Showfield on them still causes
core dumps.
Checked in as revision 468 with unit test flags on, Smoldyn off, -g, GSL

Added test for field reads and assignment for the ArrayElement. Along the
way also fixed issue with deleting data contents of ArraysElements.
Checked in as revision 469 with unit test flags on, Smoldyn off, -g, GSL
Next thing is to test messages to and from ArrayElement entries.
Also valgrind is happy with it, at least during runtime. At clearup
it has a fair number of lost blocks.

==============================================================================
7 May 2008
Made a subdirectory 'connections' for the Conn classes. Various makefile
fixes to get it to compile.

ArrayElement messages are being set up, trying to do checks on their function.

Turns out that all the messages are being sent to all the targets. When I 
analyzed it, after much messing around it turns out that the problem is that
all of the messages on the ArrayElement are sent out even if only one of the
ArrayElement entries actually invokes it.
Checking each ConnTainer for ElementIndex match at the time that it creates 
its Conn. This is horribly wasteful. For example, here I have a dozen elements
in the array, of which only one will send a single message at a time.
Clearly I must not do a sequential scan for matching ConnTainers or Conns for
the long term.

Some incremental improvements to make in the Send command:
SimpleElements:
	- get func as at present
	- Consolidate all (SimpleConns) into one ConnTainer, 
	- Make an efficient iterator. Avoid virtual funcs. Possibly a single one

ArrayElements
	- get func as at present
	- Can we cascade downstream msgs from x2AllConn ? 
		No, that is the job of solvers
	- Look up Msgs or ConnTainers by index.

Checked in as revision 474 with unit test flags on, Smoldyn off, -g, GSL

==============================================================================
8 May 2008
What we would like:
- The iterator should line up all the individual msgs as Erefs. They all 
have the same src info, so that never changes. Additional dest info is just 
index. 
- The *2All msgs are also Erefs and index, use the wildcard info in the Eref.
- The *2Many msgs should have the target EIs already lined up.

class sendOne {
	class Node {
		Eref e;
		index i;
	};
	Node src;
	vector< Node > dest;
	Some iterator for the target() and data() args.
};

Not so simple for AllConns: Either need another sendList or another
phase of the send. Assume AllConns are rare so we can line up the allSends.
class sendAll{
	Node src;
	Element* dest;
	unsigned int numDest; // Will iterate through to numDest
	unsigned int index; // starting index.
}
class sendMany {
	Node src;
	Element* dest;
	vector< unsigned int > destIndex;
	unsigned int index; // starting index.
}


==============================================================================
9 May 2008

Muddling along, making a SparseMatrix template but it isn't so good with
the original Kinetic class implementation which was special purpose.
I've set up to use the SparseMatrix in a new Many2Many class.
Need to compile and run lots of unit tests before deploying.

==============================================================================
10 May 2008
Implemented SparseMatrix template, including unit tests.
Shifted old one to KinSparseMatrix. Later to merge.

Added getColumn to SparseMatrix. Did more extensive unit tests.
Checked in as revision 476 with unit test flags on, Smoldyn off, -g, GSL

Now trying to implement Many2Many. Lots of compiler fun. Compiled. Yet to test.
Checked in as revision 477 with unit test flags on, Smoldyn off, -g, GSL

- Unit tests with explicit assignment of Many2Many
- Getting at ConnTainer.
- Incremental assignment
- Getting at msg indices.

==============================================================================
11 May 2008
Did an analysis using pen and paper, of lookup patterns for the most common 
array message category: synaptic projections. In this case the dest index
is essential. 
Result is that the sparse matrix should indeed store the index in its contents.
I assume that the lookup process produces an array of non-zero entries and
their indices. The matrix column indices are simply the target element indices.
There is a bit of an issue in the current implementation where a zero is taken
as a null connection. Need to fix this.
Also the current implementation is expensive for inserts because it has a
single big vector. A set of individual vectors might be faster but a bit
more expensive.

Fixed the zero==null situation with setting up the matrix. Added to unit tests.

==============================================================================
12 May 2008
Cleaning up unit tests for ArrayElement. I've now put in a separate local
test class, will be useful soon for also doing message index tests.
Currently stuck with the Many2Many messaging. It clears the first set of 
tests with SimpleConns.

==============================================================================
13 May 2008
Got the Many2Many messaging to work, but so far it does one such ConnTainer
for each message in a set rather than putting them all in a single ConnTainer.
Now to try that.

==============================================================================
14 May 2008
Did some setup work for reusing Many2Many, but now long overdue to check in.

Checked in as revision 479 with unit test flags on, Smoldyn off, -g, GSL

==============================================================================
17 May 2008
Not sure how the previous build worked. Lots of bugs in adding messages
to existing ConnTainers.

Current program flow:
Eref::add( m1, e2, m2, connTainerOption)
	==> Logical place to put the 'add' API function.
	bool Finfo::add( e1, e2, destFinfo, connTainerOption )
		==> Several Finfo class-specific vfunc options here.
		ConnTainer* selectConnTainer( all args here )
			findExistingConnTainer(), or new ConnTainer.
				==> The findExisting needs to match up funcIds.
		Msg::add( ConnTainer, srcFuncId, destFuncId )
				==> This step not needed if we put info in
				existing ConnTainer.


OK, we can flatten this out by putting the selectConnTainer stuff within
Msg::add, after we expand its arguments.
	- Fixes issues with handling existing ConnTainers
	- Msg::add is a cleaner place to put the operations.

Msg.cpp:83.
==============================================================================
18 May 2008
Set up to do the 'flattening', yet to put the new Msg::add call in to the
Finfos. Still have a dangling issue of how to put in the connIndex needed
to look up synaptic weights etc.
Checked in as revision 480 with unit test flags on, Smoldyn off, -g, GSL

Now the new Msg::add call is implemented and seems to work. Also the
Many2Many message seems to be handling multiple entries OK.
Checked in as revision 481 with unit test flags on, Smoldyn off, -g, GSL

Raamesh needs a One2One map message for array copies. Let's set that up next.
Message set up, unit tests to do. Set up and cleared unit tests too. At this
point the One2One map will do the basic message passing correctly, but the
issue of destination indices is still dangling.

Checked in as revision 482 with unit test flags on, Smoldyn off, -g, GSL

Next step is to do unit tests for message indices. The nomenclature here
is ugly:

eIndex: Element index, identifies element in an array, usually part of an Eref.
msgIndex: Index to identify a message, now closely related to an identifier for
	Finfos. Sorted so that a limited set of hard-coded msgs are 
	preallocated, and the rest are set up as needed.
index: Message index, identifies specific connection to target.
	Usually not needed. Most remaining cases need it only for destination
	and we can do a slow lookup to get the source index in the rare 
	cases the reverse index is needed.

Our tests should make a connection matrix where each target has to handle
multiple incoming messages, of different kinds. Each input is associated with
a weight. I'll put the weights in as the same value as the expected
message argument, which is based on the Eindex of the src and dest element.

Much of the bread and butter of the new Atest class operations are done,
but we need to know how to couple the addition of messages to the 
expansion of the weights vector.

We have lots of issues now cropping up. One is the problem of managing
the synaptic wt_ vector. In the implementation of SynChan, this is done
by having all the access functions first resize the wt_ vector to 
accommodate all synapses. To do so we get the number of incoming synapses,
which was easy for simpleElements:
Element::numTargets( int msgNum )

but now we need to redo to handle ArrayElements. It would be nice to put
these wt on the ArrayElement, as it would also simplify the indexing.

==============================================================================
19 May 2008
Revisit question: Why not put weights on the connection?
- Need specific Conns. 
- Need Conns with index info for parallel messaging
- The RF does need this info in conjunction with the Conns.
- When do we ever need weight info on a per-element basis?
	- Planarweight
	- When rescaling
	Both of these are rare
	- Plasticity
	This is common. But one would have single synapse input here.

==============================================================================
20 May 2008

Currently we don't do the right thing for getting the connIndex in 
DestFinfo::respondToAdd. It just takes the total # of incoming msgs onto
the element, not those dedicated to the specified eIndex. The function
for calculating this # of msgs is already slow, will be slower still to
do so for arrays.

Treat different synapses as elements? 
	- Expand as new syns are formed.
	- Eliminates msgIndex field in Conns.
	- Messes up all2all and one2oneMap. But Many2Many is fine.
	- Not readily BC
	- Will need 2dArrayElement because we may have array of cells and syns.
	This gets too clever. Don't do it, at least till simple 
		implementation works.

We have three possible approaches here:
- Current: Maintain indexes for each connection. 
	- Gets messy and expensive to manage indices
	- General and uniform.
	- Costly. Most messages don't use it.
	- Element-centric syn info management.
- Eliminate indices, use eIndex as surrogate
	- Need to set up 2DArrayElements
	- Single index has to be quickly extracted into 2 levels of array index:
		one for the parent eref, and one for the synapse #
	- Element-centric syn info management.
- Put syn data into Conns.
	- Need way to access this generally (another void* ?)
	- Proliferation of ConnTainer classes (But OK if we regard as fat edges).
		- How do we specify which one we want? Magic templates?
	- Conn centric syn info management

Consider three specific use cases:
	- Local synapse. Here we need to manage wt and delay (doubles)
	- Off-node message call. Here we need to manage target and buffer 
		indexing data.
	- Plastic synapse. Here each synapse has to manage history for the input
		and work out plasticity rules. Perhaps each synapse needs to
		be an independent object: combining the worst of the 2dArray
		elements and the fat Conns with extra info. But we could just
		put the full plastic syn state info into the fat connTainer too.

Assume we are going with option 3: Syn data in Conns.
	- ConnTainer defined with a templated Ftype, including void which is 
		specialised so it takes no space.
	- Need derivative of DestFinfo to provide Conn spec at msg setup.
		- This means respondToAdd has to do more work.
	- Concurrently, convert Conn to a single simple class 
		(not virtual as now), optimized for iteration and having a 
		uniform interface. Passed around on heap, no separate
		destruction step needed.
		
==============================================================================
21 May 2008
Checkin to put in the new One2One conn files I had left out by mistake 
last time. Currently none of the above ideas is set up.

Checked in as revision 483 with unit test flags on, Smoldyn off, -g, GSL
Computation of Many2ManyConn.cpp::size needs to be done.
Issue of src vs dest in this call.

==============================================================================
22 May
Working through the process of getting the # of src and dests for each 
index of an element. Now it compiles and clears unit tests, though I haven't
started to explicitly test for the accuracy of these numbers.

Checked in as revision 484 with unit test flags on, Smoldyn off, -g, GSL

Added unit tests for message counting code.
Checked in as revision 485 with unit test flags on, Smoldyn off, -g, GSL

Got synapses to work with Simple and Many2Many connections, all in the
ArrayElement unit tests. This fails for now with One2One because we need 
to manage an 'indices' vector for each of the managed synapses. At this
point the implementation is option 1, where connections manage a target
'conn index' to identify synaptic weights and other entries on the 
destination.
I have continued with this for now because it was the existing idea and I don't
want to get into a major refactoring at this stage
Not able to check in, servers seem to be down.


==============================================================================
23 May

Checked in as revision 486 with unit test flags on, Smoldyn off, -g, GSL

Now to fix the One2One conns to manage indices correctly.

On the bigger scale, I think here we set the goals for the feature freeze:
- Functioning arrays and array messages
- Functioning createmap, planarconnect and planarweight/delay using arrays and
	simple elements both.
- Functioning solver, but not array version of solver. 
	Perhaps at this point we don't even ask the solver to handle 
	ArrayElements at all.
- Set of regression tests including big cell models and simple network
	models.
- Set of Python regression tests.

Longer-term project goals:
- Connection refactoring
- Better merging in Smoldyn and geometries for diffusion.
- Full integration of array messages including accessible fields
- Full integration of arrays and solvers
- Parallel implementation
- SBML/NeuroML/Neuroconstruct integration
- Shifting over to Python for production simulations.
Suggestions from the group:
- Documentation and tutorials
- Graphics

For now. Fixed the One2One conns. Done quite neatly in the constructor.
Passes unit tests first time round.
Checked in as revision 487 with unit test flags on, Smoldyn off, -g, GSL

==============================================================================
25 May 2008

Fixed an old bug (they all are old) in the SourceForge tracker. This was that
element wildcards don't work in showfield. Recorded test in 
TESTS/bugs/SourceForgeTracker/1863862_showfield_hash/example.g.

Tried to check in. There is a discrepancy on SourceForge and the unit
tests are not cleared. The biophysics directory Makefile claims that 
files script_out.cpp and script_out.h should exist. They do not. Don't
know if it is an error in the Makefile or that the files have not been 
uploaded.


==============================================================================
26 May 2008
Upload missing. Fixed. Now works. Time to check in the showfield wildcard fix.

Checked in as revision 490 with unit test flags on, Smoldyn off, -g, GSL

==============================================================================
29 May 2008
Worked on a fix for an old bug on SourceForge:
[ 1858980 ] Pool does not convert concentration SUMTOTAL inputs
This uncovered a bug in addmsg on the GenesisParserWrapper.
I put in tests and examples for SLAVE and SUMTOTAL messages. 
These two examples behave differently in GENESIS, but the same in MOOSE.
In GENESIS, the one with the SLAVE message scales up according to the volume,
but the one with the SUMTOTAL message does not.
In MOOSE, both scale up with the volume.

I am going to keep it this way, for two reasons:
- It is unlikely to break anything, and would be difficult to convert to the
        GENESIS form.
- The original verison is arguably less logical. With the current version I
        can scale SUMTOTAL inputs or not, as the case may be.

Checked in as revision 496 with unit test flags on, Smoldyn off, -g, GSL

Added in 'version' function to return 3.0 for MOOSE. This lets programs
run correctly in both MOOSE and GENESIS, if they want to use different
features. GENESIS versions are all below 2.5.

Checked in as revision 497 with unit test flags on, Smoldyn off, -g, GSL

Fixed another old bug: 
[ 1859530 ] Message to ValueFinfo causes field duplication
This involved some extra work in the SimpleElement::listFinfos code
and its counterpart in ArrayElement.

Checked in as revision 498 with unit test flags on, Smoldyn off, -g, GSL

==============================================================================
30 May 2008
[ 1861628 ] Unix shell commands not accessible within MOOSE interpreter
Implemented this. Borrowed some stuff from the old GENESIS code tree to do so.

Checked in as revision 501 with unit test flags on, Smoldyn off, -g, GSL

==============================================================================
31 May 2008
[ 1863902 ] '\' does not works in MOOSE interactive mode
Fixed.
Checked in as revision 503 with unit test flags on, Smoldyn off, -g, GSL

[ 1888537 ] -overwrite option for tab2file command actually appends
Fixed. Also made an 'append' DestFinfo for Interpol, which is inherited by
Table. Put in a test in 
TESTS/bugs/SourceForgeTracker/1888537_tab2file_overwrite

Checked in as revision 504 with unit test flags on, Smoldyn off, -g, GSL

.........................................................................
Some parallel messaging design:
Shifted over to DOCS/PARALLEL.

Mostly there with compile of PostMaster stuff..
==============================================================================
3 June 2008

Now MOOSE compiles with the PostMaster stuff, and clears unit tests on single
node. Haven't begun multi-node work yet.
Checked in as revision 505 with unit test flags on, Smoldyn off, -g, GSL, MPI on

Fixed issue with non-MPI compiled version: the pollPostmaster function was
called with a zero clock tick. Now bypasses the function.

Checked in as revision 506 with unit test flags on, Smoldyn off, -g, GSL, no MPI

Beginning to compile after folding in some of the async postmaster operations.
Still need to set up proxies.
==============================================================================
4 June 2008
Compiled in proxy element, doesn't do anything yet.

==============================================================================
5 June 2008
Compiling in AsyncDestFinfo.

Here we run into some issues with managing the FuncVecs for async, sync and
proxies. These FuncVecs can be tied to the Ftypes, but there are questions
about how to initialize them and how to guarantee their order. Once this is
done I think I can have a framework of getting them from their Ftypes.

A related possibility is to put an ordinal number on Ftypes, and use that
instead to access the associated FuncVecs.

I think I'll just put a sorting routine in the mooseInit function
called from main. Base it on the FuncVec names. Oh. I already do this in
sortFuncVec(), which is called in mooseInit.

==============================================================================
6 June 2008
Major changes to Ftypes to handle formation of FuncVecs for parallel messaging.
Those seem to be ready now, but some compilation stuff to do with the 
AsyncDestFinfo.

Along the way got rid of the last vestiges of the TypeFuncPair initialization
for shared ftypes.

Checked in as revision 509 with unit test flags on, Smoldyn off, -g, GSL, MPI on
Checked in as revision 510 with unit test flags on, Smoldyn off, -g, GSL, no MPI

==============================================================================
7 June 2008
Set up comprehensive unit tests in run up to doing internode messaging.
First set: Send async data into PostMaster.

==============================================================================
8 June 2008
Unit tests set up for postmaster data transfer. First set of tests on 
async data transfer into source PostMaster buffer OK.
Checked in as revision 511 with unit test flags on, Smoldyn off, -g, GSL, MPI on

==============================================================================
9 June 2008
Split parallel development into separate code branch. The current trunk will
be for release fixes.
Checked in as revision 514 with unit test flags on, Smoldyn off, -g, GSL, MPI on

==============================================================================
24 June 2008
Discussion with Stefan Wils about his 3-D stochastic simulator STEPS. STEPS
uses tetrahedral meshes and Gillespie-type calculations. It has a Python
front-end through SWIG, and is C++ for the number crunching. It would be 
a good complement to Smoldyn for 3-D stochastic reac-diff calculations.
He has sent a prelim doc file and will in due course send some example sims.
Some points:
Molecule definitions are global
	Molecules concs are initialized by explicit functions at reset.
Reaction definitions are attached to group-like entities
Diffusion properties are attached to compartments (idea being that different
	compts may have different viscosities)
Somewhere in there the reactions are attached to volume entitites/compartments.
Any number of groups can be attached to a geometry.
The spatial mesh is generated from geometries using a variety of tools
	One of the interesting ones uses a surface-distance function for
	any geometry to generate the mesh. This would be the one to use for
	building a mesh for a neuronal compartmental geometry.
There are two solution engines: 
	one uses a compartmental form, ignoring geometry except for volume
	one does full 3-d reac diff.
There is a runtime loop for extracting conc values. MOOSE could easily
	encapsulate it.
==============================================================================
1 July 2008
Some other discussions highlighted the fact that several people want to
do multiscale simulations and would like to try GENESIS, but the script
language is too horrible. Should provide a nice general interface for this.

Thoughts on a general interface. This relates to several existing ideas,
most notably the thoughts about a 'robot' for E. Coli.

Contexts:		To			Comm lines
1. E-Coli Robot		Signalling model of	Mol concs
Either solo, with GUI	chemotax		Prob of ccw turn of motor
Or multiple in crowd

2. Detailed neuron	ANN or			Spikes <---> rates
			Integ/Fire network	Spikes to syns on dends

3. Elect neuron model	Biochem model of syn	Calcium
						Channel phosph ---> chan numb

4. Detailed chem model	Savageau model or	Activities to multiple tgts.
			Simple chem model

5. Fly robot		Neuronal network	Visual stim
			model of vis-motor	Motor control

...........................................................................
Thought is to have an interface class that can handle many of these
'robot' and related tasks in a general way, acting as wrapper where needed.
Kinds of interfaces:
1. Message redirect
2. Message argument shuffle
3. Math/lookup message transform
4. Time filter transform
5. Timestep juggling / Quasi-steady-state assumptions
6. Chemical activity (see Bioinformatics 2002)
7. Array building (multicompt diffusion in another way)

Key test cases:
1. Electrical <---> biochem neuronal models
2. E Coli robots
3. Chemical module interface.

==============================================================================
15 August 2008
The new g++ (GCC) 4.2.3 (Ubuntu 4.2.3-2ubuntu7) is now getting picky about
const char* declarations. I have fixed about 25 of these, and there seem to
be several hundred left, almost all in the parser. May have to use an upgraded
flex/bison to rebuild the parser to fix this.

Checked in as revision 601: unit test flags on, Smoldyn off, -g, no GSL, MPI off

==============================================================================
29 August 2008
Added a fix to Msg::dropAll, so that it now clears the old FuncVec.
Checked in as revision 646: unit test flags on, Smoldyn off, -g, no GSL, MPI off

Fixed a problem with handling parsers. The Shell used a 'send' call 
to return a field value to the parser. Changed it to sendBack.
Checked in as revision 647: unit test flags on, Smoldyn off, -g, no GSL, MPI off

==============================================================================
2 Sep 2008
Begun work on robots/SigNeur.
==============================================================================
3 Sep 2008
Begun work on robots/Adaptor.

Checked in as revision 661: unit test flags on, Smoldyn off, -g, no GSL, MPI off
==============================================================================
4 Sep 2008

I now have it written up to the point where it should parse the cell.
But I need a converter from strings to Ids, to be able to do things from
the shell script.

Converter done, works.

Lots of headaches now with the cell copy. There is an infinite recursion,
from an object where isGlobal() == true.
Messing around with test scripts in 
/home/bhalla/genesis/SFmus/moose-g3/TESTS/robot

==============================================================================
5 Sep 2008

More work on SigNeur.
Working on a bug in copy, pertaining to globals. Here globals means objects
that are not supposed to be copied, instead they get messages sent to them
from the duplicates. Somewhat like pointers. Setting up to do unit tests for
this. Due to accumulation of changes, checked in the beastly revision:
Checked in as revision 666: unit test flags on, Smoldyn off, -g, no GSL, MPI off

Well, that is odd. After a lot of work setting up 1st and 2nd generation
global copy unit tests, and clearing all, the system still croaks with the
copies in the real model.

Checked in as revision 667: unit test flags on, Smoldyn off, -g, no GSL, MPI off

Things tried and eliminated:
- Unit tests cleared.
- Doesn't matter if first cell is in /library or elsewhere
- The system is OK with a couple of steps, dies as soon as reset is called
- Showmsg shows the right messages.
- gdb shows the right object names.

Oddly enough, it works for a 3-compartment version of the model. Don't know
what to make of it.

Fiddling around with the model. Looks like branching is implicated in the
crashes. A big unbranched model is fine, the tiny model with branching crashes.

Is this dependent on globals? Yes. The crash goes away as soon as the last 
	HH channel does. Even on the full 299 compartment model. The Ca pool
	and the ligand gated channels are still there.

OK, not necessarily globals. It may simply be mix-ups with the 'next'
in the msg when duplicating. Not sure where the branching comes in.

See runstiny.p. This has globals, this has branching. What it does not have
are multiple channel types (HH and synaptic) on any dend. Suggests that there
is an issue with the 'next' handling in Msg.

Redid SimpleElement::copyMessages to use safer code that takes care of next.
	No luck. Possibly CopyGobals needs a fix up too.
	That too did not work.

==============================================================================
6 Sep 2008
Further fixes. Now the unit tests fail. Worked slowly through them.
Currently I have had to comment out a test 'compareCopyMsgs' for the 
ArrayCopy, which I have not upgraded. Soon.

Anyway, the problem still persists. Whenever there are two kinds of
channels on a compartment, the model dies. To be a bit more precise: If
a HHchan follows a synchan, then the model dies. I can get the same model
to run if the channels are permuted. (origtiny.p and permute_runs_origtiny.p).
I thought I had fixed this kind of issue in the copy, but evidently not.

==============================================================================
7 Sep 2008
After fiddling around with SimpleElement::dumpMsgInfo, I finally was able
to confirm the hunch about a misplaced target during copy, even after
all the fixes to the copy function. In the tiny.p model,
spine_head_10_1 is mis-copied so that an HHChannel::channel ends up being
called as a SynChan::channel. Now I have the diagnostic I hope to be able
to home in on the copy problem.

OK, tracked it down. In Msg::copy I was obtaining funcId1 from the existing
funcId in the original msg. But this was obtained by using the c->msg2()
index, which always refers to the msg slot, and does not know about the 
next_ hack in msgs. Fixed by looking up the originating Finfo.

Confirmed with tiny.g, and then with full.g

This profoundly painful bug underlines the need to clean up and document
the messaging API.
Checked in as revision 673: unit test flags on, Smoldyn off, -g, no GSL, MPI off

==============================================================================
8 Sep 2008
Bug reported by Johannes Hjorth: showfield/setfield don't handle simple
element indices. Both were due to inability of wildcards to handle indices
on simple elements. Messy. Fixed and added unit tests.

Checked in as revision 674: unit test flags on, Smoldyn off, -g, no GSL, MPI off

Working again on SigNeur. Got it to traverse tree correctly after some
messaging confusion.

Next step is to subdivide compartments according to diffusion lambda,
and to assign index ranges in the tree. 

Checked in as revision 677: unit test flags on, Smoldyn off, -g, no GSL, MPI off

==============================================================================
9 Sep 2008

Signaling compartment subdividion and indices done.

Checked in as revision 678: unit test flags on, Smoldyn off, -g, no GSL, MPI off

For the diffusion, we create a reac for each diffusing molecule, on the
same index. It would be nice to have a nextIndex message, which
connects to the specified element with the next index from the source.
For now use SimpleConn for the nextIndex part, and One2One for the within-
index conns. The last compartment will have to have zero rates for its 
diffusion reaction.

In principle I should have the framework in place now, only the 
parameterization of volumes, diffusion constants and so on remains. Actually
there are a few issues:
- Making a new array in an existing one doesn't seem to go down well. This
	was attemped for the diffusion reaction.
	For now, best approach is to make a temporary copy of the proto
	and insert the diffusion reaction into it, including the original
	message. Then the whole lot comes over in the 'copy'.
- showmsg and le misbehave with the array. Possibly the same issue as above.

Implemented temporary copy. This seems good. Next to complete the 
diffusion messaging onto the next compt.

Checked in as revision 683: unit test flags on, Smoldyn off, -g, no GSL, MPI off

==============================================================================
9 Sep 2008
Generic progress on setting up diffusion messaging. Currently a bit stuck.
Minor fix to copyIntoArray.
Checked in as revision 684: unit test flags on, Smoldyn off, -g, no GSL, MPI off

Several issues now with completeDiffusion:
- Minor: junctions array needs to indicate which type of target is involved
	(soma, dend, spine)
- Major: Need a way to align molecules in different models. For now name
	identity will have to do, but in due course would like an identity
	map. In either event, need to set up such a map.

==============================================================================
11 Sep 2008
General cleanup of scattered CRL parallel code, prior to release. Also a bit
of cleanup to stuff in progress on SigNeur so that it all compiles and clears
unit tests.
Brought over latest version including the hsolver. But it fails to clear
unit tests: an issue with the 32 bit version.
Checked in as revision 686: unit test flags on, Smoldyn off, -g, no GSL, MPI off

Working on buildDiffusionJunction
==============================================================================
12 Sep 2008

Cleaned up buildDiffusionJunction. All signaling compts except for soma0 now
have someone to diffuse to. Still need to insert function to calculate which
of the parent compartments to attach to, based on coords.
Checked in as revision 698: unit test flags on, Smoldyn off, -g, no GSL, MPI off

Compiled code with complete[soma,dend,spine]Diffusion functions. Clears
unit test, also looks OK for sigNeur1.g

==============================================================================
13 Sep 2008

Checked in as revision 699: unit test flags on, Smoldyn off, -g, no GSL, MPI off

Major things remaining in SigNeur:
- Assign parameters
- Connect up adaptors
- Set up ksolver
- Fix up hsolver to work with the model
- Tests for diffusion, branching and coupling between two kinds of model
- Parallel decomposition.

Minor things:
- Do a better job of organizing junctions, based on element coordinates
- Handle compartment taper


A calculation of time-scales and parallelization options:
The signaling model ran about 40x faster than GENESIS. GENESIS runs about
1-10x faster than real time. The cell model runs at about real time.
So at this point, even with ~400 signaling compartments, the bottleneck is
the cell model.

Oops, previous revision had broken new code. Fixed.
Checked in as revision 700: unit test flags on, Smoldyn off, -g, no GSL, MPI off

==============================================================================
14 Sep 2008

Parameter assignment getting close. Compiled, yet to test.
Looks like parameters are OK. Loaded in acc79.g. The diffusion rates
are not working. In kkit, -ve diffusion rate means use the system default,
0 means none, and +ve rates means use specified value. acc79.g has lots of
-ve rates, but in MOOSE everything is being loaded as zero. 
Checked, the Molecule is setting -ve D to zero. Changed so it sets it to 1.0.
Now sigNeur2.g crashes. 

==============================================================================
15 Sep 2008
Looks like rates are getting to be more reasonable. Also not crashing, at
least at setup time.
However, seems like the kinetics object isn't able to load the model. Is it
an issue with handling array elements? 
- Need to assign the 'method' field to ee then back to rk5
- Element handling fails, see Stoich::findTargets:583
	Generally, there are plenty of functions in Stoich.cpp that need
	fixing to handle arrays.

==============================================================================
16 Sep 2008

Incrementally converting Stoich to use Erefs. Each time compile and test
with the moose_kholodenko.g regression test.
CountRates converted... OK
Vectors of mols converted... Needed also to fix up everything in Stoich.cpp and
KineticHub.cpp... OK.
KineticManager.cpp... OK.
But it still croaks in sigNeur2.g. Fixed, now it croaks because the 
SparseMatrix is too big!
Sundry further fixes later, we have a loaded model:

 showfield solve/stoich *
 [ /sig/kinetics/solve/stoich ]
 name                     = stoich
 index                    = 0
 parent                   = /sig/kinetics/solve
 class                    = Stoich
 cpu                      = 0
 dataMem                  = 232
 msgMem                   = 2
 nMols                    = 41349
 nVarMols                 = 28174
 nSumTot                  = 10490
 nBuffered                = 2685
 nReacs                   = 35979
 nEnz                     = 13962
 nMMenz                   = 0
 nExternalRates           = 0
 useOneWayReacs           = 0
 path                     = /sig/kinetics/##
 rateVectorSize           = 63903

Unfortunately all mol concs and nInits are stuck at zero. Anyway, this is
a big step forward.

Checked in as revision 708: unit test flags on, Smoldyn off, -g, MPI off

Trying to track down why values are zeros.

==============================================================================
17 Sep 2008
Set up a simple test model in robots to see what happens with solving arrays.
There are two complementary tests: ksolveArrayOn.g and ksolveArrayOff.g.
These helped identify issues with the zombify command. Having sorted that, 
it looks like the simulation runs OK but users can only access the zero index
element managed by the solver. This comes down to nasty stuff in the 
connections.
Checked in as revision 715: unit test flags on, Smoldyn off, -g, MPI off

Managed to track down the nasty stuff in connections. Now it works for the
little test case. Time to try on a serious model.
=> Loads up 140 ish meg, and returns reasonable values. But croaks as soon
as I try to run, with a nan. Suspect the dangling reactions/enzymes:

KinSparseMatrix.cpp:173: double KinSparseMatrix::computeRowRate(unsigned int, const std::vector<double, std::allocator<double> >&) const: Assertion `!( isnan( ret ) )' failed.

Put in assertions all over the place. Same bug persists.

==============================================================================
18 Sep 2008
Checked in as revision 720: unit test flags on, Smoldyn off, GSL on, -g, MPI off
Note that this revision (like 719) fails unless GSL is on.

Tracked down at least some of the problem: The zero substrate/product cases
do bad things. We can't simply eliminate them, because in an array situation
all objects are tied to the hub through a One2All message. One option is to
define a dummy rate term for these bad cases. Hopefully there won't be
too many of them, and we should encourage modelers to clean up their 
simulations. Another option is to be a bit more intelligent about how we
set up the zombie messages, so that even if index zero didn't come in, the
messages are set up.

Made a modified model without the dangling enzyme. The solver still runs 
into a nan.

Put in a dummy reac which does nothing, into the rates_ array instead of the
halfReac it was using and which should have been OK. Now it no longer
crashes, but the variables are all stuck at nInit.

Now the test model crashes. I think it is because it has a dangling reacn.
Fixed. 

Back to the sigNeur calculation. The system has set all the rates 
kf and kb to zero. Also all the rates for the enzymes.
This is a puzzle. The sigNeur stuff works OK for the Exp Euler method, but
not for rk5. Conversely, rk5 works OK for simple models including the 
Kholodenko model.
Checked in as revision 723: unit test flags on, Smoldyn off, GSL on, -g, MPI off

OK, I've replicated the problem with the much simpler TEST/robot/
ksolveArrayDanglingOn2.g, compared with ksolveArrayDanglingOn.g which works.
The former has reaction 0 dangling, and the latter has reaction 1 dangling.
Makes all the difference.

I think I have figured out and fixed the indexing issue, but now it looks
like the rates themselves are incorrectly set.
==============================================================================
19 Sep 2008
I think the problem may be that the addReac is done reaction by reaction,
but as soon as the first one is done then the entire lot are converted to
use the lookup functions from the solver.

That did it. I used the original Reaction class functions to look up the 
values, and then the ksolveArrayDanglingOn2.g simulation worked. Need to
carry this through to include the enzymes.
Done. Now I get reasonable looking changes in the big sigNeur3.g model.
Need to compile on a serious machine with optimization to run for long enough
to see if it is really working.
Checked in as revision 726: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Put in some missing regression tests.
Checked in as revision 727: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Compiled on pinni. Loaded the big sigNeur3 model, but crashed when I tried to
run it.

==============================================================================
21 Sep 2008
Implemented a new test case: cylinder.g. This makes a 240-compartment 
uniform cylinder model with only Ca in it, to test for diffusion.
Problem 1: Ksolver does not notice when I change n in the molecule. Confirmed
this with ksolveArrayDanglingOn2.g as well as ksolveArrayDanglingOff2.g.
Oddly, on reset n s visible as the new value, but as soon as the simulation
steps it goes back.
Also oddly, when I do an equivalent thing: setting n and nInit in the middle
of a simulation, for a much bigger model, it works. Difference there is that
the affected molecule was buffered.

Worked through it. The y_ array in GslIntegrator was not being updated when
Molecule::n was set. This overwrote the S_ array in Stoich. Some ugly
messaging later, the standalone.g is now working, but cylinder.g is not.

Now it transpires that there are problems in how many molecules are managed
by the solver in the cylinder case.

This turned out to be a really bizarre bug in the Molecule::getMode. The
solver uses getMode to decide whether to build the molecule as a varMol or
sumTot or buffered.
Fixed. Cylinder.g now looks promising. Need to dig up solution.

Now another random bug with 
getfield /sig/kinetics/solve/hub nMol

Oddly, showfield handles this with aplomb.
There is something bad happening in Neutral::getChildByName. The obvious
issue is that the Msg handling children has a nonzero next_, which a) should
not happen, and b) is not being followed. Somehow related to this is the
problem that there are only 2 children reported, neither of which is the 
hub.

Did a little test to at least ensure that mass conservation is obeyed in
the reaction system. It is OK.

On now to adaptors.
Implemented skeleton for this. It scans through and identifies src and dest
pairs and prints those out. The actual object creation and messaging to
come next.
Skeleton of those done too. Some issues with messaging from zombies to be
sorted.

==============================================================================
22 Sep 2008

Checked in as revision 735: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Looks like there is an issue with nInit rescaling.

Solution to 1-D diffusion is
n( x, t ) = (N/sqrt(4pi.Dt) ) * exp( -x^2/(4Dt ) )

Implemented in the cylinder.g. It works well, getting better as the spatial
discretization becomes finer.

Checked in as revision 741: unit test flags on, Smoldyn off, GSL on, -g, MPI off

In SynChan there is a modulator dest msg that scales conductance. However,
changing Gbar will not do so until it is reset, since Gbar is not used
directly during calculations.
In HHChan there is no modulator but Gbar is used directly.

Need to converge on a single common scaling, modulator seems most 
straightforward. Concern is about how the solver deals with it.

Looking at Hsolve code. See HsolveInterface.cpp line 124/125. The
check on channel does not correspond to the lookup on current_.
Also in many cases, the if statement is pointless if it is protected 
by an assert.

Another pending bug: SimpleElement.cpp:229 is commented out. Should not
be. Various issues come up when it is put back in. 
When it is removed though the function baseMsg doesn't work.

Another bug: Cannot showmsg if the target goes beyond the numSrc. See
Shell.cpp:listMessages around line 1935.


These bugs aside, it looks like the adaptors are connected up OK. It is
another question as to whether they are actually sending info as planned.

Next step is to sort out the scheduling. I think that we will need to put
t0 and t1 as before at the short dt around 50 usec, for the cell model,
and t2 and t3 for the medium dt around 0.1, for the signaling model.
Graphs etc will be on t4, but here again we may need two different plot dts.

First let's get the simulation clocks sorted.
Also need to ensure that the adaptors are connected up before the solvers are
built.

Did some cleanup first, separating the many parts of the SigNeur.cpp into
functional units. I now have five SigNeur source files, all much more 
manageable.

Begun implementation of scheduling.
Fails in sigNeurTiny.g, cannot find the adaptor for Ca_input.

==============================================================================
23 Sep 2008

Checked in as revision 742: unit test flags on, Smoldyn off, GSL on, -g, MPI off

After some messing around, fixed up the test for sumtotal input sources in
Stoich.cpp. In this case the input source was the adaptors. I believe that
external inputs will work OK, will have to test. This requires both the
solvers and also the scheduling to work.

Setting up scheduling. Currently fails, due to the pending issue of
path2eid listed yesterday.

Fixed an old irritant of 'call' not working. Should do now, but I need to 
check for multiple args... Checked by hand, looks good.

Checked in as revision 753: unit test flags on, Smoldyn off, GSL on, -g, MPI off

==============================================================================
24 Sep 2008
Trying to clean things up with the inoccuous looking fix to the
baseMsg function. This is an absolute can of worms.
1. Getting cinfo out of an element is bad, because it refers to the baseFinfo
	which doesn't exist in the base form.
2. The Msg::add( connTainer, funcId1, funcId2) is bad, because it should
	be a base-level function but uses the baseMsg function which has
	all these assumptions about the setup of Neutrals.
3. The handling of msg# in connTainers is bad because it brings up this
	separation between baseMsg# and actual msg#.
4. path2eid is bad because it gets stuck with the baseMsg function, leading
	to the above mess.

something else is also bad because when I bypass all the above it just croaks
a bit further down in UnitTests.cpp

Some progress with baseMsg. The unit test failed because my code failed to
handle DynamicFinfos, and was returning zero instead of the msg for that case.

With this cleared, back to the path2eid issue. Still stuck

==============================================================================
25 Sep 2008
Fixed both baseMsg and problem with inability to access fields in hub. 
Niraj had submitted a bug report #2116499 on this which helped because 
he gave a clear test case: TESTS/bugs/missing-hub.g

Checked in as revision 761: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Now that sigNeurTiny is loading, to fix up.
- The kinetic stuff is still stuck on tick0.
- The adaptors need to be put on tick 2 or 3.
- Clock dts are all wrong.

This part works, but the volume scaling of molecules seems to have hit a snag.
Will also need to go through rescaling kf and kb according to volume and
order of reactions.

Fixed up the adaptor scaling. They don't actually get the messages they need
from the solvers, though.
Also fixed an old irritation: the IkSrc message was missing from Mg_block.
Needed by the cell reader. Added it.

Checked in as revision 765: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Need something like a sendVectors function to deal with solvers sending
stuff from multiple zombines out to multiple targets. Comes up when
the kinetic solver has to send values out to the assorted adaptors.

==============================================================================
26 Sep 2008
Finally the whole thing begins to take shape. I have a small test model,
TESTS/robots/soma.g, which implements all the required bits. At present there
is still a glitch going from the signaling to the cell model, but the other
way the data looks like it is flowing properly.

Checked in as revision 767: unit test flags on, Smoldyn off, GSL on, -g, MPI off

==============================================================================
27 Sep 2008
Figured out issue with the soma model: Simply that the kinetics were wrong.
I have not yet put in the  scaling of kf and kb by volume and reaction order.
Also there is an issue with the diffusion rates at junctions.

==============================================================================
28 Sep 2008
Need to formalize volume and geometry before I go further. A lot of the stuff
I am doing in a difficult manner with the volumeScale should vanish, and
many issues of rates of reactions should be fixed.

Here is the relationship between the Smoldyn geometry concepts:
Geometry is a superstructure and manages a bunch of surfaces. No volume term
Surface manages a bunch of panels. Has a volume term
Panels are parts of a surface. One or more to completely define it.
	Multiple subclasses of panel: sphere, Hemisphere, cylinder, TriPanel, 
	RectPanel.

I had originally planned a flat tree for the object structure: See 18 Nov 2007.
Note that this does not have KinCompt in it at all.
	- /KineticManager|
			 L/solve----------------|
			 |			L/hub
			 |			L/stoich
			 |			L/solver
			 |
			 L/geometry-------------|
			 |			L/surface-------|
			 |			|		L/panels
			 |			|		L/panels
			 |			|
			 |			L/surface-------|
			 |			|		L/panels
			 |			|		L/panels
			 |			...
			 |
			 L/Other kinetic managers
			 |
			 L/model reacs.

Note that KinCompt has no place in this scheme. However, it fits better
with the SBML view of compts.

Another option is to put KinCompt as the 'group' object, and to require that
the volume of the group applies to all its children unless there is an
intervening group.
	- Straightforward, no additional messaging.
		- Awkward field access: vol is not part of parent-child message.
			- Access relatively rare (?).
	- Incompatible with old kinetics hierarchy and solvers: at this
		point solver wants to be /kinetics.
		- Could hack with a fallback search, or use separate messages.
	- Put geometry as optional child of KinCompt, and thus sibling of model
		reacs.

  /KineticManager|
		 L/solve--------|
		 |		L/hub
		 |		L/stoich
		 |		L/solver
		 |
		 L/KinCompt-----|
		 |		L/model mols and reacs
		 |		L/geometry------|
		 |		|		L/surface-------|
		 |		|		|		L/panels
		 |		|		|		L/panels
		 |		|		|
		 |		|		L/surface-------|
		 |		|		...
		 |		|
		 |		L/KinCompts----|
		 |			...
		 |
		 L/Other kinetic managers, nested

Couple of uncertain things here, though they don't have to be resolved till
I begin to use 3D methods: 
	- Do I use geometry at all or can it be folded into KinCompt?
	- Can one model have multiple geometries?
	- Can one geometry have multiple surfaces?

What do I do about all the legacy genesis script that uses volscale?
	* Clearly, I need to implement handler code in volscale, that refers
		to the authoritative volume and complains if it doesn't match.
	- Somewhat mitigated because almost all use of signaling objects in
		GENESIS is through kkit, which is highly stereotyped.
		- Will need to modify kkit reader to deal with this

What does it mean for current SigNeur implementation?
	* Replace neutrals for model holders with KinCompts
	* A fair amount of work to do on percolating volume changes into reacs.
	* A smaller bit of work for getting volume for molecules
	* Rescaling becomes a piece of cake.
	- Decide policy about moving molecules between compartments,
		which often have different volumes. This has implications 
		for modeling diffusion.
			- Use reacs as now. The rates are all first order,
				so no units issues. However, scaling issues.
			- Subclass from reacs to make it legal to go between
				compts, but otherwise reacs.
			

==============================================================================
29 Sep 2008.
Implemented the KinCompt and related stuff for scaling of molecules, reacs
and enzymes. So far unit tests only done for molecule vol scaling. 
Still to fully test the others out, but it clears the unit tests and
the moose_kholodenko.g regression test.

Bug at checkin in HsolveActive.cpp. Fixed.

Checked in as revision 774: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Now to return to the SigNeur stuff, which has been severely mauled.

==============================================================================
30 Sep 2008

Various cleanups, more unit tests for the kinetic scaling.
Worked on the test for SigNeur: soma.g: OK. 
cylinder.g is now broken: diffusion rates messed up.

Some fixes to diffusion. Now cylinder.g works, but these are patches, 
and there is scope for much cleaning. sigNeurTiny.g now fails... fixed.

Checked in as revision 778: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Tried to do a small run with sigNeur5.g, but no sign of movement. Need to
compile with optimization and run on a workstation, not an old laptop.

==============================================================================
2 Oct 2008.
There is a discrepancy in the output of soma.g for different levels of
optimization on different machines. I think it is the hsolver, next thing 
to do is check output on a pure cell model.

Did the check. I get 3 very distinct outputs for 32-bit debug version,
32-bit O3 version, and 64-bit O3 version. Used soma_cellonly.g.

Tried various things with scheduling: 2 resets, ensured method is hsolve,
put stages in the clocks. No change. Next to go through each channel
type in order and ensure all are identical at reset.

==============================================================================
3 Oct 2008.
Last night I had tracked down differences in the channel values at reset. Sent
this to Niraj, he says he has fixed it. Let's see...
No, not fixed. The O3 compiles for 32 and 64 bit now coincide, but differ
from the debug output. To check, I used GENESIS on the same model and confirmed
that the debug mode was the correct one. I have sent Niraj the output and
diagnostics: It looks like an initialization problem.

Having done this, back to the SigNeur implementation. If I assume that the
debug version does the right thing, I can proceed to design a production
simulation.

==============================================================================
5 Oct 2008
Doing a production model now with SigNeur. I clearly need a way to define
electrical compartments that should remain empty, otherwise it is absurdly
computationally wasteful. Implemented dendInclude and dendExclude fields in
sigNeur, still buggy. Problem is when spines are attached to an EMPTY
compartment: how to set up sigStart?

==============================================================================
6 Oct 2008
Tracked down issue, fixed problems with EMPTY, but there remain further
headaches. Currently the system for setting up junctions assumes that 
all compartments are filled with signaling stuff. Now the goal is to
allow only subsets of the model to do signaling.
Options:
	- Clean up management of numbering of junctions.
		Start numbering of each array appropriately.
	- EMPTY compartments have a dummy signaling model.
		Won't work: need to define an array size.

Fixed up first option. Seems OK so far, need to test thoroughly and with
multiple disconnected segments. Likewise with isolated spine models.

Put in Niraj's bugfix for the initialization of the channels in O3 mode. Now
the output is consistent across compiler optimization levels and also
against GENESIS in ee and chanmode 0.

==============================================================================
8 Oct 2008
Checked in as revision 811: unit test flags on, Smoldyn off, GSL on, -g, MPI off

=============================================================================
10 Oct 2008.
Peculiar bug in SigNeur/KinCompt: when I build a model, the volume of the
/library/dend and /library/soma KinCompts becomes a big negative number.

This bug remains, but doesn't seem to affect the copies made of the 
library models. 

I have changed the simUndump command so it now creates KinCompts for groups
when reading in a kkit model. After some work fixing how this percolates
down to the child groups, it looks OK.

Checked in as revision 834: unit test flags on, Smoldyn off, GSL on, -g, MPI off
Confirmed that this is handled properly by SigNeur too.
=============================================================================
13 Oct 2008
Serious bug involving array indexing has cropped up since version 834. 
In the meantime, implemented strSet for Ftype0.

Checked in as revision 841: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Fixed cosmetic bug for doing le on array elements.
Checked in as revision 842: unit test flags on, Smoldyn off, GSL on, -g, MPI off

=============================================================================
14 Oct 2008
Fixed serious bug in SigNeur where an uninitialized eref was being used
to set volumes
Also minor fixes to PulseGen for uninitialized variables.
Pending important fix to Eref, to give default initializer to Element::root().

Checked in as revision 847: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Continuing issues with the SigNeur, has been fixed on pinni, but
another surfaced. I will have to recompile in debug mode to catch many
of these issues, since the release mode has been happily skipping assertions
that otherwise would have cropped up.

Lots of fixes to Shell.cpp, needed because of unresolved parallel slots
all over the place, that caused havoc in serial mode.
Checked in as revision 850: unit test flags on, Smoldyn off, GSL on, -g, MPI off

=============================================================================
15 Oct 2008

Back to some of the old tests for SigNeur. This caught a bug at once:
compare the output of TESTS/robot/ksolveArrayOn.g and ksolveArrayOff.g
Turns out that the output of the array case is wrong.

Tracked down to the messaging, fixed. It now clears the following tests
in the robots directory:

ksolveArrayOn.g (vs ksolveArrayOff.g)
cylinder.g
ksolveArrayDanglingOn2.g (vs ksolveArrayDanglingOff2.g)

Checked in as revision 856: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Tracked down the issue with timing and dt of the SigNeur signalling 
calculations. The Shell::useClock was trying to find the specified clock tick
as a path, rather than as a name. Fixed. There is still an issue because t0
and t1 are trying to drive the sig model in the library.

Checked in as revision 857: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Another issue cropped up: The simundump was not able to read nComplexInit for
enzyme-substrate complexes. After some messing around with enzyme code it is
fixed. Also has a unit test.

Checked in as revision 858: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Need to set up a 5th clock, to handle graphics.

=============================================================================
21 Oct 2008
Created separate ksolve directory for kinetic solver, moved over files, tested.

Checked in as revision 867: unit test flags on, Smoldyn off, GSL on, -g, MPI off

=============================================================================
22 Oct 2008
Can I use stoich matrix to build up dependency tree?

Stoich matrix		Rates		Conc change
[ N11  N12  N13 ... ] 	[ v1 ]	= 	[ D1 ]
[ N21  N22  N23 ... ]	[ v2 ]	 	[ D2 ]
[ N31  N32  N33 ... ]	[ v3 ]	 	[ D3 ]
[ N41  N42  N43 ... ]	[ ...]	 	[ D4 ]
[ ...  ...  ...     ]		 	[ .. ]


- Si = Subset of molecules affected by vi are given by Stoich matrix.
- vi affected by Si are give by checking reactions depending on Si

Looked at algorithm and cost to get dependence vi->vj:
Stoich matrix approach: Total: O( N^2 )
foreach vi (size N)
	Si = Nji such that Nji != 0 // Make mol dep vector
foreach vi (size N)
	foreach Sj (all vectors of mol deps of vi: size N)
		if ( vi has reactant on Sj ) add vj to depvi.

Direct messaging approach:
foreach vi (size N) : Total O( N )
	Traverse to each product mol Pi (size O(1) )
		Traverse from Pi to each target reac vj (size O(1) )
			Add vj to vi dep list.

So the direct messaging approach, though painful, is more efficient.

				-----

Speeding up lookup of selected reactions:
Basic Gillespie: 
	- Pick reac with probability proportionate to its propensity.
	- Step for time drawn from lambda distribution for this propensity.

Basic approach is to fill a vector a1, a2... a_n with propensities for v_i
Find the total propensity. Scale the vector so total is 1.
Pick a random number R from 0 to 1.
March through propensity vector a_i till Sum( a_i ) > R
Use reaction i-1.

This is an O(N) search per time-step, can get nasty if we have 1e6 reacns,
e.g., in a diffn system.

Things to do to speed up:
Exact, serial: 
	- Approach of Mukund's visitor: Order propensities in diminishing order.
		The more likely reacns will be hit quickly.
	- Subdivide reacn set into groups with tot propensity maintained
		in each. Find target group, then nest down into reacns within
		group.
		- This can be done with many levels L of nesting.
		- Cost: # of updates to tot propensity per reacn step goes
			rapidly up with L, till all parent groups need 
			updating.

Approx, parallel:
	- Partition reacn subsets among nodes.
	- Advance each subset independently, then merge.
		- Probably similar approxes to tau-leap method. Check.
	- Grid update scheme for linear diffusion: 
		- Advance each grid point indept till checkpoint.
		- Transfer diffusing molecules. 
		- Select checkpoint so that
			# diffusing is a small fraction of total. Currently
			tau_diff ~25 sec, and dt is 5 msec, so this is a
			good assumption.
		- This works particularly well because we know ahead of time
			what the tau is.

In both cases, we need a 1-step backtrack capability so we can halt at
defined times.
=============================================================================
24 Oct 2008.
Had a closer look at ways to get dependency from stoichiometry matrix. This
is how to do it:

Dep matrix = abs(N(Transpose)).abs(N(neg))

where abs(N) is the absolute value of entries in N and 
N(neg) is the subset of negative entries in N. The logic is like this:

nonzero entries in each column (reaction) in N is the list of 
substrates (-ve) and products (+ve ) for that reaction. 
All of these will be affected when the reaction fires.

Negative entries in each column are the substrates for the reaction. If any
of these change, then the reaction rate is affected. Note that the positive
entries do NOT matter.

So, to get the intersection of dependencies, we multiply out the molecule
terms as above. This gives a matrix where the nonzero entries in each column
are the reactions depending on that column, i.e, the dependency graph.

This is nice and clean. Unfortunately the structure of our sparse
matrix makes it much easier to get rows than to get columns, but here
we need it the other way round. Implemented a transpose operation, and
then the getGillespieDependence operation in KinSparseMatrix to deal with
all this. Also did unit tests.

=============================================================================
26 Oct 2008.

Doing core numerics part of Gillespie SSA implementation. Note that
Slepoy et al have reported a linear time version in 2008, that would be
great to use.

Checked in as revision 881: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Fixed up what should be last part of core numerics, the update of the dependent
rates. This will need to be rethought if we do a tree search for propensity
to speed up the calculations, since the entries in the tree will then need
updating as well. No testing yet.
Checked in as revision 882: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Added code for solver setup. Yet to test.
Checked in as revision 883: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Implemented a unit test. Much to my astonishment, after it cleared assorted
assertion failures while setting things up, the actual run seemed to give the
right sort of answer the first time it ran. The unit test needs further
 cleaning (for example, to do stats on the output rather than print it out).

Checked in as revision 884: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Implemented a unit test for setting up of solver through KineticManager.
This was remarkably unpleasant, worked through numerous bugs. Remaining
fairly major issue is that the deletion of the children of KineticManager is 
unclean, and as far as I can tell it leaves dangling half-messages on the 
clock ticks. Hacked around it by first deleting the children of the 
KineticManager and then the manager itself, so as to clear unit tests.

Checked in as revision 885: unit test flags on, Smoldyn off, GSL on, -g, MPI off

=============================================================================
30 Oct 2008
Tried to get KineticManager to be subclassed of KinCompt. Seems to work
to compile, but it isn't doing what I expect.
=============================================================================
2 Nov 2008.
Identified issue with volume scaling and mol concs. The volume change in
molecules causes a scaling of the n, keeping conc the same. The solver does
not know what to do with the volume change. Since the Kinetic manager now
is derived from KinCompt, it can send a message out to the solver. The rule
is simply to scale all the volumes and rates as done with the
molecules and reacs. Possible alternative is to request an assignment to all
zombies and then use their conversion routine. Inefficient. Problem
is the kinetic manager knows the hub etc only as children. We could do this
implicitly to set a volumescale DestFinfo in Stoich, which manages all the
data for all except the Smoldyn solver.
Q: How often do we do a volume scale _after_ the solver creation?
For the purposes of SigNeur, seems like we do this after. Even so, a loose
end.
Actually went ahead and fixed it. Now things scale properly in various
solvers. I still have the problem with kb reported as 0 in GSSA solver, 
which is presumably due to the separate forward and back reacs.

=============================================================================
3 Nov 2008.
Checked in as revision 903: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Analyzing Gillespie solver for correctness. Has issue with numbers in small
vols, I think becauses for 2A---> B we might get a forward reaction even if
N[A] == 1.

=============================================================================
4 Nov 2008
Fixed Gillespie solver. Two problems: the above small volume issue, and 
an error in the initialization that rounded things the wrong way for 
non-integral initial values of n.
Checked in as revision 907: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Various stumbling blocks:
- Doesn't even complete the run on the acc4_1e-18 model.
	For some reason this has concs 1000x too high. Perhaps the
	reading is faulty.
- Runs with a rescaled acc4_1e-21, but the output shows no time-changes
	The sumtot isn't working. Works with rk5 though.
	Need to set up a dependency arrangement.
	Also need to add dependencies for changing any mol conc.
* Crashes on looking up a zero pointer when run with the dend.g model. This
	is in the NOrder reaction, perhaps it has never been exercised before.
	Fixed. I was using sizeof( vec ) rather than vec.size().

=============================================================================
6 Nov
First pass at implementing sumtot dependencies. Sort of works but in one
test the sumtots fail to initialize. Fixed that too.

Checked in as revision 917: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Put the tests from TESTS/GSSA into the subversion repository.
Checked in as revision 918: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Still stuck with the acc4 run. PKC_active still not right.

There may be an issue with the volume rescaling. The rk5 runs also differ
between vols. Is it that the nuclear compt isn't getting set to the
correct vol?

Got the PKC model from the database: acc48.g. The volume scaling is quite
messed up for the MOOSE reads. If I rescale it to 1.666e-21 
(where conc == # of molecules) using GENESIS, and then run the PKC model using
MOOSE/Gillespie, it matches the rk5 and GENESIS output.
If all this is true, why does the acc4 model not give matching results?

Did a specific extension of the enztot to see what happens downstream of the
tot. This is incorrect.

Tracked it down. The sparse matrix N_ does not keep track of sumtotals,
even though it is sized to do so. Should be OK without overhead, as the
function that updates values only does so for varMols.

Now it handles the enztot runs correctly. Time to try the bigger models.
The acc4 model now shows fluctuations in PKC-active, but the value is
still wrong. An inspection of values shows that the supposedly buffered
Ca is not. It has a 'mode' of 6. Perhaps it isn't doing the AND with the 
slave_enable bit at 0x04.

The original Stoich version handles it correctly. So it is something to do
with the Gillespie solver. Got it. Now that we have all mols in the
matrix, the KinSparseMatrix::fireReac() also updates the buffered mols.

Setting up a further vector within the KinSparseMatrix, this one to keep
track of the truncated row endings suitable for the variable molecules.
This seems to have dealt with it. Now MOOSE seems to handle acc4 properly at a
range of volumes.

Checked in as revision 919: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Next step is to fix up the volume scaling problems during file loading.

=============================================================================
7 Nov 2008
Dealt with volume scaling. Seems to work.
Checked in as revision 921: unit test flags on, Smoldyn off, GSL on, -g, MPI off

=============================================================================
10 Nov 2008
Some analysis on simulations indicated that there is something funny
happening with relative ordering of compartments, spines, and signaling
compartments. From notes from BISTAB_CASCADE simulations on 9 Nov:
"Plotted out the original output file directly in xplot. Turns
out that spinehead3 and dend16 and dend17 are the problems. So there is
something backward in the dendrite numbering."

Looking at SigNeur to understand why. Turns out that the
order of the spines on the compartment tree (a vector) is backwards. 
Since this vector is used for ordering the construction of signaling
compartments, it explains why things go backwards.
It does not explain why spinehead3 and dend 16/17 have low Ca levels, though.

The adaptors from spineheads cell to sig seem not be be created. The others,
from the dend, do work.

Next to check: run it, see if the printed value of conc in Ca_input tallies.
Yes, it does. dend[16] and dend[17], and spine[3] are much below their peers. 
How about the conc in the cell compts?
spine_head values are all OK, but /sig/cell/lat_14_9/Ca_conc is 77644x 
lower than its peers. Nothing obvious in the .p file.

=============================================================================
11 Nov 2008
Fixed a divide-by-zero bug in Mg_block, of the form (x / (x+y) ). Both x and y
were zero.

Checked in as revision 928: unit test flags on, Smoldyn off, GSL on, -g, MPI off

More fixes to Mg_block. The badly named KMg_A_ and B_ were misunderstood as
state variables and were being reinited to zero. They are actually parameters.
This seems to have helped a bug in the SigNeur tests.

Checked in as revision 930: unit test flags on, Smoldyn off, GSL on, -g, MPI off

=============================================================================
13 Nov 2008
Fixed a bug in assignment of nInit and coInit of a buffered molecule, when
the kinetic solver is operational. Now assignment happens.
Checked in as revision 935: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Implemented a rather nasty hack in the solver to handle midstream turnon/off
of buffering of molecules. Only works for molecules that start out unbuffered.
Checked in as revision 937: unit test flags on, Smoldyn off, GSL on, -g, MPI off

=============================================================================
14 Nov 2008
Fixed a problem with volScale assignments to molecules. These were not 
percolating back to the parent KinCompt. 
Checked in as revision 938: unit test flags on, Smoldyn off, GSL on, -g, MPI off
=============================================================================
15 Nov 2008
Cleaned up volume mismatch reporting for kkit model loads.
Checked in as revision 939: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Trying to figure out why the gsolve has a problem with big models. Checked
that it correctly handles enzymes whose parents are sumtotalled. See
totenz.g and manyvolstotenz.g in the TESTS/GSSA dir. It works fine.

Another possible problem: does the GSSA handle MMenz properly? See
MMenz.g and manyvolsMMenz.g in the TESTS/GSSA dir. Dies.
MMenz on its own seems OK. 
I can reproduce the error if I first set the volume to 1e-15 or bigger. 
1e-16 or smaller doesn't crash. How odd. Tracked it down to a problem
with EPSILON comparing against k1 for MM enzymes. k1 depends on volume,
so big volumes caused it to fail to make the rate term. Fixed by making the
EPSILON a million times smaller, but still not an ideal situation.

Checked in as revision 940: unit test flags on, Smoldyn off, GSL on, -g, MPI off

This is fine, but I still don't see how it would affect the running of the
big models, as they are all small volume.

Designing flux for volume transfer between different solvers.
- Simple method: have halfreacs with appropriate flux rates, pipe the
	molecules into the flux vector which can be a contiguous set of
	entries in S_.
	- Known drawback: Guaranteed to always lower the conc of molecules
	below correct value. This fraction will be reduced for smaller dt.

=============================================================================
16 Nov 2008
Still working on problem with cAMP. New test shows that problem is with 
enzyme E not being in the dependency tree for MMenz. 
See rMMenz.g and manyvolsrMMenz.g.
Also checked if intermediate assignments of values cause suitable updates
in the dependency tree. They do not. See assignReac.g and manyvolsAssignReac.g.
So there are two reasons that the Gsolver method might fail.
Checked in as revision 941: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Worked on the two problems. The rMMenz still does not work at all. There
is some progress on the assignReac, but it is still not right.
AssignReac issue: the 'step' call in gsolve mode starts the simulation off
again from t = 0 but displays only the latest stuff. Fixed.

Also got rMMenz.g to work: I had been using the wrong molecule from the
substrate list as the 'enzyme'. Both assignReac.g and rMMenz.g now work.

Checked in as revision 942: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Tried putting in a safety factor to prevent flatlines. Didn't work.

Various cleanups in GssaStoich::innerProcessFunc. Checked, looks OK.
Next protect mtrand against 0.0 for getting tau. Seems unlikely, but it
could give a bizarre logarithm. Maybe just print out and see if it correlates
with flatline.

=============================================================================
18 Nov 2008
Confirmed that mtrand was giving 0.0. Confirmed that fixing this fixed
flatline. Checked mtrand code: it actually uses 32 bits, so 0.0 is not
so unlikely after all. Very probable, in fact.
Checked in as revision 945: unit test flags on, Smoldyn off, GSL on, -g, MPI off

=============================================================================
21 Nov 2008
Updated some field information for Molecule.
Checked in as revision 958: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Fixed missing capability in GssaStoich: It was unable to handle dynamic
buffering, that is molecules that start out unbuffered but then get switched
to buffered and assigned to assorted new values. Test is in 
TESTS/GSSA/testDynamicBuffering.g
Checked in as revision 961: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Fixed missing capability in GssaStoich: It was unable to handle dynamic
buffering, that is molecules that start out unbuffered but then get switched
to buffered and assigned to assorted new values. Test is in 
TESTS/GSSA/testDynamicBuffering.g

=============================================================================
25 Nov 2008.
Designing flux for volume transfer between different solvers.
- Alternate 0: have halfreacs with appropriate flux rates, pipe the
	molecules into the flux vector which can be a contiguous set of
	entries in S_.
	- Known drawback: Guaranteed to always lower the conc of molecules
	below correct value. This fraction will be reduced for smaller dt.
- Alternate 1: Assume that the flux terms are a small fraction of total #.
	Then one can accumulate flux terms throughout the run without actually
	effecting any change in mol #. At the time of exchange of flux data,
	the mol#s are updated. This needs a variant on the FirstOrder RateTerm.
- Alternate 2: Same assumption, don't do anything until update time. Then
	do an estimate of # of molecules transferred for the whole period,
	in either direction. Amounts to a simple Euler timestep. Could also
	do as Exp Euler. This is a slightly coarser approximation than alt1,
	assumes that average conc == latest conc. Could do a trapezoidal too.

A look at NumWreck indicates all sorts of pitfalls. Key thing seems to be
to have access to concs at either end of the dendrite: a little more 
sophistication in the messaging. Ideally want an implicit solution, but
here we definitely have to keep it multi-node.
For starters, let's try their FTCS scheme, which is 2nd order in space:
u is conc, j is the spatial index, n is the time step.

(u_j_n+1 - u_j_n) / dt = D[ (u_j+1_n - 2 u_j_n + u_j-1_n)/(dx^2) ]

Actually this is identical to what we would get with the simple one-sided
explicit Euler flux calculation.

- Alternate 3: Dummy neighbour compartments with the latest conc in each,
	bidirectional reacs, updating the conc in the dummy compts each dt.

Perhaps do a small standalone calculation.

Alternate 0 and 3 use the intrinsic solver mechanisms. 
Alternate 1  needs a different kind of calculation, a flux term that doesn't
	remove any molecules.
Alternate 2 needs a completely separate calculation.

Consider using Smoldyn: Alternates 1 and 2 won't work with it.
Alternate 0 is ugly and needs something clever still to bring in molecules
in Smoldyn-like cases.
Alternate 3 is clean with all molecules including Smoldyn, but may 
entail computational cost.

=============================================================================
26 Nov 2008
A more immediate local problem: Volume scaling still causing problems.
Turned out to be an issue with the local kkit.g file, which was explicitly
assigning volumes. Must weed this out. Also cleaned up the KinCompt code
and field documentation.

Checked in as revision 970: unit test flags on, Smoldyn off, GSL on, -g, MPI off

Working again on inter-solver data transfer.
- Need the following for each flux message:
	- vector of current concentrations (pointers to S_ of diffusing mols)
	- Leave it to the setup object to guarantee that the vectors are of
	corresponding molecules. The only requirement here is that the # of
	molecules matches.
	- Setup object also sets fluxRates. These include transport as well as
	diffusion. Cannot be negative. Can be asymmetric for active transport.
	- Locally deal with trapezoidal calculations.
	- Locally inject appropriate # of molecules in. The derived Stoich class
	( GssaStoich ) may need to do some special update stuff here.

- Alternatively, set up a separate object for handling inter-solver flux.
	- Maps of mol names for L and R pools, looking up vec indices.
	- Rates for each mol, each way (L and R).
	- But the stoich still has to maintain a vec of transferred mols for
		each flux channel.
- Could set up like the HHGate, which has its own data visible as child
	interpols.

- Based on the construction of diffusion, just replace the 'Reaction' with a
	derived class for inter-solver data transfer. This makes the setup
	much easier. Issue is that the other end of the diff reaction is
	currently just a message, but we'll need something more concrete for
	the inter-solver data flow.
	Actually, cannot do this so easily. The array is for the entire 
	system: each of the kinetic compartments in the model. If I want
	to subdivide into different solvers I will have to do different
	things for regular array entries, which are all reactions.
	Or do a different operation to set up the inter-solver flux at the 
	point in the setup code where we complete the diffusion.
	Note that if we set up stuff here, it has to be the solver that
	figures out what to do with it. What we can do is to record the
	Eref or Id of the putative target. Preferably also a solver identifier.

	One horrible thing of the current design is that the sections are all
	set up on arrays. Makes it hard to subdivide between nodes. This
	is a pretty fundamental SigNeur issue.
	For now: Deal with subdividing among different solvers.

=============================================================================
28 Nov 2008
Minor cleanup to SigNeur code so it doesn't emit so many diagnostics.
Minor further cleanup to SigNeur code so it does not set up diffusion if
	one of the rates is zero.
Medium cleanup to ksolve code, specially Stoich.cpp, so it handles dangling
	reactions better. It puts in a zero-order reaction. This is good for
	the Gillespie method as there are no dependencies... but at some point
	I need to figure out what to do if I really want a zero order step.

Checked in as revision 975: unit test flags on, Smoldyn off, GSL on, -g, MPI off

=============================================================================
30 Nov 2008
Working on InterSolveFlux
=============================================================================
1 Dec 2008
After some strange results for the spine PKC buildup, had a look at volumes.
These were completely off. Need to print out as they are assigned.
OK, turned out that the issue was that the volume and xByL vectors have the
soma, then dend, then spine compts in order. The volumes etc are actually
OK. The problem was that I was indexing these two vectors by the Eref indices
for src and dest molecules, which are not continuous but local to the
arrays for soma, dend and spine respectively. Fixed. Looks OK now.
Checked in as revision 977: unit test flags on, Smoldyn off, GSL on, -g, MPI off

=============================================================================
2 Dec
Working on the InterSolverFlux stuff. Remaining:
- Need to schedule the flux updates. Has to be set up by SigNeur, because of
	the complex staging involved.
- SigNeur needs to call the setup function for making the flux terms on 
	Stoich, and then set up the messages on the flux stubs.

Simplest approach for now is to keep the diff reacs on the spines,
and use them as handles to set up the flux info.
Checked in as revision 980: unit test flags on, Smoldyn off, GSL on, -g, MPI off

=============================================================================
3 Dec 2008
Working on SigNeur setup to begin InterSolver work.
Desirable setup is to have a separate KineticManager for each compartment that
	is to be solved independently.

Analyzing setup procedures for SigNeur. It comes close to the above:
	- Sets up a KinCompt for each compartment. Could easily be a 
		KineticManager
	- Issue is that parent KineticManager wants to take over the whole lot
		during its path assignment.
	- Futher issue: If we want to lump multiple dend compartments together
		for calculations, we will need another layer of managers for
		this new division of compartments.
		- For now, OK to do fine subdivision.
	- Continuing issue: The underlying dend and spine models are arrays.
		OK for separate solvers, but messy between nodes.

Options:
	1 KineticManager path assignment has to be smarter and not attempt to
	take over the turf of child KineticManagers.
	2 KineticManager path defaults to its descendants, with above proviso.
		- KineticManager has 'neutral' option that tells parent to 
		treat it like a KinCompt and take over its kids.
	3 KineticManager is really smart and figures out inter-solver data
	transfer itself.
		- This will need handling of multiple reaction types, using the 
		internal methods of the junction reactions.
		- Numerical issues begin to get nasty.
		- What to do if enzyme, substrate, and product are on 
		different compts?
		- Should we only permit diffusive exchange between compartments?
			- What if we really do want a huge model to be 
			subdivided?  


Going for now with option 2.
Checked in as revision 982: unit test flags on, Smoldyn off, GSL on, -g, MPI off
Let's see now if we do get an array of KineticManagers each doing its
own thing... Sets up OK then dies.

=============================================================================
5 Dec 2008.
Checking multiple solver setup for spines. Croaks both for Gillespie and rk5
methods with an assertion failure in KineticHub.cpp:742.

Looks like the hub erefs are simple elements. odd.
=============================================================================
6 Dec 2008.
I think I can see it now. The hubs are created individually on the duplicated
KineticManagers. So the kms are arrayed, but hubs are simple. What a mess.
But then the solver set up should be straightforward.
I think I see a problem now in zombify. The system currently just returns
if the object is already zombified. As it should if there is a single master
solver, otherwise we will zombify array elements multiple times. Here however
we have multiple little solvers, and need to zombify each index individually.
Ugh. As a short-term hack, set up each spine as an individual copy, rather
than an array copy.
Clearly we need to move on a systematic array element management system.

First pass at setting up spines as individual copies. 

This happens, but the buildMoleculeNameMap is unhappy because we now have
a tree with lots of duplicate names. Need a variant that does array indexing.

Looking through existing code.
=============================================================================
9 Dec 2008

A general solution is needed to deal with distinct solvers,
distinct models in dendrites and spines, and distinct diffusing molecules.

Currently we optimize a lot on space by using arrays for each model. 
- Problems with handling these using distinct solvers. The current
	eref message deletion calls don't play well with individual indices
	in an array. Even if they did, this would be a real mess of 
	asymmetric messaging in a context designed for symmetry. Slower updates.
	Deeper problem: How to delete a single message at a time from an array
	message, which is what got set up.
- Problems with separating into individual models. Now we need to build the
	molEref-name map for each model. Element overheads. It would be nice
	to have completely virtual objects/Elements here. Paths change.
- In the longer term, every Element will have array capabilities including
	partial arrays across nodes. So would like to sort out messaging
	issues anyway.
	

Working on zombifySeparate. This still doesn't quite do what I need, which is
to identify when it is handling a separate hub for each index, so that it
can either do the one-time-only zombie operations, or do the one-per-index.

=============================================================================
10 Dec
Implemented a preliminary fix, compiles, but need to initialize the 
separateZombie_ flag. Testing too remains.

=============================================================================
11 Dec
Fixed up initialization, did backward compat tests with the Kholodenko model.
Checked in as revision 985: unit test flags on, Smoldyn off, GSL on, -g, MPI off
Next:
	* Make zombifySeparate_ flag a field
	- Have SigNeur use it
	- Back off the earlier changes for separating spines out of arrays
	- Test mess with uniform rk5 setup
	- Make test model with a series of spines at different vols, test
		if they are dealt with correctly by SigNeur
	- Fix molecule name lookup stuff to be more general.


The implementation is too snarled up at this point. I will need to rebuild
from scratch in view of what this implementation has taught, and avoid the
current issues which are particularly severe with the arrays and various
hacks that have gone with them.

- Compartmentalization using the cell model compartments.
- Build an initial load map based on model size and estimated dt. 
	Separately estimate electrical model load.
- Split up stoch compartments wherever possible into separate solvers. 
	Even if not parallel, these will be faster than a big solver.
- Provide defaults for splitting up or lumping models when doing ODE solutions.
- Arrays should only be used when they will be within a given solver.
- Provide asymmetric flux capabilities:
	- Transport
	- CoInit gradients
- Eliminate TreeNode stuff. Just build sig models on top of elec compts,
	similar to channels. Each sig model is rooted on a KineticManager.
	KineticManager has a child that does name[index] to Eref mapping.
- SigNeur should have a map of compartments to load vector(s), and use it to 
	set up the load balancing. Estimates for G1 are tricky... Should be
	the job of the KineticManager. I think an estimate of total propensity

- Are we separating this into a a super readcell and a super solver setup?
=============================================================================
12 Dec 2008

Super readcell:
- Read in sig prototypes. Simple, add a new 'chan' type in ReadCell::addChannel.
	* This needs to bypass the initial copy, and instead install a
	placeholder SigNeurKineticManager object to subsequently configure the
	signaling model in the compartment.
	* During its construction the SigNeurKineticManager figures out 
	dimensions, subdivisions, load etc. Don't execute yet.
	* What to use for the arg of the SNKM? 
		- Not scaling of CoInit, that should be done in the sig models
			at the level of individual molecules
		- Possibly the recommended integ method. A bit silly.
		- Possibly lambda for compt subdivisions. A bit crude.
	* In addition to SNKM, could add a series of adaptors. This keeps
		the adaptor definitions in a declarative place rather than
		in the script that sets up the model.
		- In theory these could also be set up in the sig model
			definition, but if that is SBML it gets messy.
		- Need to have multiple args here, will need work on ReadCell.
			- Scale factor, 2 offsets
			- mol
			- chan.
			- Last 2 could also be inferred from name format. Hack.
- Work out orientation of compartments wrt soma. At this stage the SNKMs 
	have their neighbours assigned. Sig stuff not yet instantiated.

Super solver, AKA what remains of SigNeur
	- Parse model tree, build load map.
	- Assign nodes, if needed. Also possible multithread options later.
	- The SigNeurKineticManager will be
	parent to off-node models, each on a KinCompt, and the associated
	solve neutral that holds the solver stuff.
	- Instantiate the models. May be arrayed. May be off-node. Would be 
		easier if we could move/copy the SNKM off-node.
	- Set up the Adapter messages between SNKM models and 
		parent compts and chans. Adaptors already made, see readcell.
		May be internode.
	- Set up the solvers. A local op for each SNKM, on whichever node it is
	- Set up the diffusion/flux between models. May be internode.
	- Set up scheduling.


=============================================================================
16 Dec 2008
Set up skeleton for ReadCell modifications. These should be fairly easy
to fill in. Should make sure that we can prototype the compartment with the
SNKM and adaptors.
Real work is to come yet, with the SNKM implementation.

=============================================================================
18 Dec 2008.
Trying to recompile. Some of the earlier hacks get in the way.
Reverted them. 
Checked that the whole thing is able to handle a current SigNeur model. OK. 
Checked that cell reader still works. Runs moose_readcell.g: OK

Checked in as revision 986: GSL on, -g, MPI off
=============================================================================
19 Dec 2008
Setting up tests for the enhanced cell reader.
* Get the simple single-line read to pass in args properly.
- Check that cell protos work: Nope, need to implement, or decide to bypass.
+ Build kin model
	Need to build only KinMgr to encapsulate load info.
+ Build adaptors
- Post-build diffusion

=============================================================================
20 Dec 2008
Working on setup of KinPlaceHolder within the cell reader.
Compiles, doesn't run.
Fixed.
Also set up adaptors.
Now all placeholders are set up from the cell reader, but the real work of
building the model is yet to come.
=============================================================================
21 Dec 2008.
Working on load estimations. Reasonable framework now in place, will need to
calibrate on actual models. One issue is that load changes during run.

Since we now use the cell reader to build the cell, we either have to adapt
it to generate the SigNeur, or make a derived class of the Cell object that
has the remaining SigNeur operations.
To back up: Do we want to put the entire spec of SigNeur within the cell 
	reader? Main remaining specifications are load balancing preferences,
	which also may apply to regular HH models. Also may want a global
	manager. Lots of setup work remaining though.
- Separate SigNeur: Keep it simple for now. Cell can just be loaded onto
	a SigNeur.
- Derived from Cell: Makes a messy overloaded object.

Do we keep the kinetics stuff now within the cell? Looks like it, since the
	structure is designed for node decomposition.

Stages:
+ Get rid of old SigNeur stuff.
+ Implement a skeleton replacement SigNeur that does the calls to the 
	placeholders to build things up.
- Start to fill out model building
- Set up inter-solver flux
- Set up parallel sims.
=============================================================================

25 Dec 2008
Working on KinPlaceHolder.cpp to assignDiffusion.
Checked in as revision 987: GSL on, -g, MPI off

=============================================================================
28 Dec 2008
Seems to be setting up the models and diffusion.
- Diffusion rates (kf, kb) are 2.56e12. Various scalings needed.
- Won't let me look at all fields in cAMP. Crashes, seems whenever I ask for
	a field that refers back to the solver. Odd. I thought solver array
	handling issues had been sorted out, but perhaps my hack to fix things
	for array messages fails for individual ones.

=============================================================================
24 June 2009
Working on SteadyState.cpp. Stuck with a Nan in the molecule matrix S_.
Looked at generated matrices. One issue is that the rank is wrong. It seems
that the LU decomposition isn't doing what I thought it did, by way of
keeping all the nonzero entries above.
=============================================================================
27 June 2009
Fixed the LU decomposition stuff by adding my own code to shuffle rows.
After some significant debugging, first pass version works. Have yet to
test with 'serious' models.
The SteadyState solver is built in to the kinetics framework, and is
set up automatically when the GslSolver is built.
TODO: Check so that it isn't called if GSL is disabled.
To run it on a typical kkig file:
include fb_bis.g

setfield /kinetics/A/M CoInit 1.5
reset
showfield /kinetics/##[ISA=Molecule] n
call /kinetics/solve/ss settle
showfield /kinetics/solve/ss status nIter
showfield /kinetics/##[ISA=Molecule] n

Checked in as revision 1176

Working in mishti:~/homework/TRAFFILATOR/JUN27_SS3
Implemented a dose-response script, doser.g. It fails to converge just past
the upper transition point for M.
Implemented another dose-response script, doser2.g, which operates on M*. It
converges all the way but with many negative values.
Implemented another dose-response script, doser3.g, which operates on M and
goes with declining Mtot. It fails to converge all the way.
Implemented another dose-response script, doser4.g, which operates on M and
uses resets each time and goes with increasing Mtot.
It converges below the transition point, fails
from there up to about 26 uM, and then begins to converge again.

For the negative solutions: Need to use the same trick as I did in another
context in this same project: Take the x values generated by the gsl system,
and square them to use for the kinetic calculations to guarantee positives.

For the non-convergence: First, go back and test with the standalone
ss_neworder.c code. See if this issue is real. I seem to remember being able
to get convergence with all starting conditions.

Tested with standalone code. This program is in 
mishti:~/homework/TRAFFILATOR/JUN27_SS3/ss_test_doser.c

It behaves just like the MOOSE version.

Implemented ss_squares_doser.c:
As the name suggests, this eliminates the negative solutions problem by using
squares of the x values suggested by the minimizer. Problems still persist.
The iterations simply do not progress away from the starting point.

I wonder if the issue is that the squares transforms makes the derivates
almost symmetric around zero.

=============================================================================
28 June 2009
Did a fair amount of further messing around, still in the directory
mishti:~/homework/TRAFFILATOR/JUN27_SS3

Further looking at ss_squares_doser.c. After a lot of checking, I conclude 
that the hybrids algorithm simply does not converge with squares.

Now working in 
mishti:~/homework/TRAFFILATOR/JUN28_SS
Implemented ss_op_doser.c so I can easily flip between various options:
int MAX_ITER = 200;
double EPSILON = 1e-8;
double CRITERION = 1e-8;
int VERBOSE = 0;
int DO_SERIES = 1;

Implemented a fallback algorithm that uses the 
gsl_multiroot_fsolver_hybrids first, as it converges fast when it works. Then
it falls back to gsl_multiroot_fsolver_dnewton.

With this arrangement, tried out three different variants of the operations
transform to see how it handles the simple bistable system across a
range of input values. All this done using the flags and changes to the ops
in ss_op_doser.c

Output file		Notes
op_square.plot		Works best. Finds values safely from 0 to nearly 27.
			Finds an unstable fixed point along the way, giving
			an apparent glitch. Still doesn't converge if I give
			it 1000 iterations. See op_square1000.plot
op_fabs.plot		Next best, but not too good. Works from 0 to 2.7, then
			a jump, and a few OK readings around 4. Always
			finds the stable fixed points.
op_nop.plot		Terrible. Finds points only up to 1.7, but also finds
			a lot of cases with negative concs.
op_log_plus1.plot	Terrible again for large values. Gives incorrect
			results without any error messages. 

Next: See if it helps to give greater weight to the conservation laws.
Basec closely on ss_op_doser.c with the square transform.
See ss_weight_consv.c, ss_weight_consv.plot
Absolutely no difference when compared to op_square.plot. I infer that the
system does some internal scaling.

Let's work with the square transform for now.
Got it compiled back in MOOSE, still barfs.

Minor bug, fixed.
Success! In fact, the ~/homework/TRAFFILATOR/JUN28_SS/doser.g script cleanly
finds all the solutions up to 100 uM, without a single problem with 
convergence. The secret is that for each new conc value I begin the 
calculation using the previous solution as a starting point.

Tried then to get the downward going trajectory. Didn't go well at first.
Then I tried doing an initial settle phase with the ODEs. This probably
introduces a small amount of numerical error. However, it brings the
system close enough to a steady state that the rest of the calculation goes
smoothly.

Also, the script does stuff with low precision numerics. I need to do this
with doubles.

Worked next on setting the SteadyState class up to handle requests
for specific conservation totals. After some messing around, this works. 
Assignment of totals works somewhat better for clean generation of 
dose-response curves against total #. But it still runs into trouble
(failure to converge) at the transition points.

A composite function for generating the entire curve: upper, lower and
saddle, is in doser_tot.g. It runs into convergence problems at the
transition points but doesn't crash, and the curve is a very clean one.

Checked in the MOOSE code as revision 1177.

Now tried to run a slightly more complicated model, a diff_eq_bis case.
This is happening, or not as the case may be, in 
mishti:/home/bhalla/homework/TRAFFILATOR/JUN28_FIG2
This has problems.
Need to inspect the matrices. Implemented SteadyState::showMatrices
function to do so.
This reveals that we still have a problem with the row echelon calculation.
Also, why is Nr 6x8 while gamma is 1x7?
7 mols is OK.
8 reacs is OK.
Nr should really be 5x8 (5 independent mols) 
gamma should be 2x7 (2 dept mols)

Knowing rank might help. But it should be possible to derive from LU
decomp.
=============================================================================
29 June 2009
I'm beginning to think that the GSL LU is more trouble than it is worth.
I can simply fix up my own Gaussian elimination in order to get row-echelon
form, and since this is a nice clean stochiometry matrix with integer entries,
the issues of stability should not come up.

Implemented
mishti:~/homework/TRAFFILATOR/JUN29_SS/myGaussian.c
which does what it says. Now try to run it through MOOSE.

First check in earlier debug changes in moose. This is revision 1178

Then fix up the new code. This works. Tests in 
mishti:/home/bhalla/homework/TRAFFILATOR/JUN29_SS.

Then try to get it to do the planned saddle plot figure:
mishti:/home/bhalla/homework/TRAFFILATOR/JUN29_FIG2/saddle_start.g
Possibly because of round-off error, the system does not stay at the saddle
point for very long. But it does work.
Let's see if we can salvage the original idea of the figure by using a
MOOSE operation to reassign the initial conditions.

Implemented.

No. It improves the time that the ODE calculation hovers around the saddle
point, but that is still much smaller than required for the figure.

Anyway, checked in to SourceForge as revision 1179.

For the purposes of figures for the paper, split up the saddle_start.g
file into two:
saddle_start_bis.g
saddle_start_neg.g

and the output of these files is in fig2_fb_bis.plot and fig2_fb_neg.plot
respectively.

=============================================================================
16 July 2009
Implemented classifier for steady states. I generate the Jacobian
and then use the GSL to compute eigenvalues. Tested, seems to work, but
there are further tests to come.
checked in as revision 1282.

=============================================================================
19 July 2009
In heavy use over the last few days, the eigenvalue state classifier seems
OK.

Did some updates to the SteadyState object to better handle error
status and to do slightly better on state classification.

=============================================================================
20 July 2009
Minor fix to writefile command to clean up error message and options.
checked in as version 1288

=============================================================================
23 Aug 2009
Major fix to SteadyState object.
Fixed difficult bug in eigenvalue classification for kinetic SteadyState
calculations. I was using the conservation law totals to compute total
molecular levels in order to set the increment for estimating the
Jacobian. This was sometimes an issue because the conservation law
calculations don't necessarily give positive values. So it was possible
to have negative concs when trying to estimate Jacobian. Converted to using
initial concs, seems resolved.
Also minor utility enhancements to SteadyState object: can look up 
eigenvalues and nVarMols.
Checked in as revision 1314.

=============================================================================
1 Sep 2009
Time to code in some of the script-based classification algorithms I have
used for the TRAFFILLATOR project. The approach was to systematically scan
different starting points for the state classification, consistent with the
boundary conditions of total molecules. This was pretty effective at finding
most fixed points. 

Approach for finding states:
- Scan through all pairwise combinations of molecules, log increment of 0.1
	Initialize conc to x, 1-x, rest to zero.
- Check mass consv OK (No negative concs)
- Set initial concs
- Step for 1 sec
- call settle function.
- Check if solutionStatus == 0
	- Check if solution is novel. This is if RMS diff from prev solution,
		 EPSILON > 1e-4. This should really be scale factor from total.
		If so, add solution as set of mol concs.
- Should also add check in case there are not enough successful solutions.
	Classification is stronger if there are many.
	
Heiruistic for state classification:
Count each of:
NUM_SOLUTIONS
NUM_STABLE
NUM_SADDLE
NUM_OSC
NUM_OTHER
int classification = NUM_STABLE
    if ( NUM_SOLUTIONS == NUM_OTHER )
        classification = 1 
    end 
    if ( NUM_SOLUTIONS == 1 && ( NUM_SADDLE == 1 || NUM_OSC == 1 ) ) 
        classification = 0 
    else
        if ( NUM_STABLE == 0 && ( NUM_SOLUTIONS != NUM_OTHER ) && NUM_SOLUTIONS >= 1 )
            classification = 8 // ill-defined.
        end
    end 
    if ( NUM_SOLUTIONS == 3 && NUM_OSC == 1 && NUM_STABLE == 1 ) 
        classification = 9 // Stable + osc.
    end 

=============================================================================
10 Sep 2009
Implementing State Scanner. It needs to manage arrays of conc values for
different molecules, for example, for the states it finds, or for the 
dose-response curves. This necessitated some updates to the Interpol object
to support stack operations. Checked in as version 1323.

Further implementation of StateScanner. I have implemented the management of
conc values as Tables. Actually the stack ops were not needed, but they may
be handy for some other cases.
Yet to implement actual algorithms.

=============================================================================
12 Sep 2009
Got part of the dose-response code working. Checked in as version 1326

=============================================================================
13 Sep 2009.
Implemented a couple of helper operations in StateScanner, to dump 
dose-response and other data as xplot files and as csv files.
Confirmed issue with SS finder doing dose-response curves: 
It does not like getting input as an
increment to one of the concs. Looks like the input does alter something,
but mass conservation is messed up. I'm not quite sure what happens here -
perhaps it reinits all but the incremented molecule?
Checked in as revision 1327.

Move on now to finding fixed all points.
Approach:
	Find conserved set with largest conc.
	Go through algorithm on 19/7/09 (page 19 and 20) for this set,
		making sure that all molecules in set are visited.

=============================================================================
14 Sep 2009

In order to control the scanning through initial conditions, we
need to know all about the gamma (conservation) matrix and the 
vector of totals (which is not necessarily the simple sum of mol
concs). 
-> Rather than do that here, we need to talk to the SteadyState
object and ask it to do the scanning, as it knows all.
-> Rather than ask the user to identify a reference molecule for the
scanning, we'll ask the SteadyState to find the biggest Totals
group and use it first, with an approximate predefined # of samples.
As an option, we can ask SteadyState to extend the algorithm through
all Totals groups.
A Monte Carlo sampling approach would need to first select a molecule,
then decide what fraction to assign to it, then if needed decide which
next molecule to assign. Sometimes there is only one other molecule
that could be assigned.

For reference:

Gamma.S = T
For example:

Gamma					S	T
[1	1	0	0	0]	[1] = 	[3	5]
[-1	0	1	1	2]	[2]
					[1]
					[1]
					[2]
Steps
- Ensure that we have a correct ordering for Totals.
- Find a way to enumerate all mol sequences for a given proportion
  in the first.

Looked at the math a bit. Although one could with some effort figure out
which conservation set had the largest total # of molecules, it still isn't
a good general way to establish the set that we want to play with for finding
steady states. For example, we could have a large conc of a slow enzyme that
does only one reaction, but the interesting states could be in the other
molecules.

So I will simply be agnostic about the order in which to scan through the
molecules S. Totals and Gamma server only to decide how to assign the next
molecule.

Estimating # in a scan:
1. Pick i, mol #: Start with 1.
2. Let x_i = T_j/gamma_ji. Find a value of j for which this is nonzero
3. For this value of j, find # of molecules (k > i) for which 
	(x_k == T_j/gamma_jk) > 0
Will need to take into account initial concs in order to work out which 
combinations can work with the other rows of gamma.

This is getting ugly. Could simply look at the gamma matrix and do a quick
estimate based on how many columns are occupied in each row, eliminating 
overlapping columns from lower rows. For the above gamma it should be 2+3.
But in each row, the # of permutable molecules is one less, so it becomes 1 + 2.
This fits with the rank of the system here which is 3: only 3 molecules are
truly independent. So we need the rank of the system to estimate # of possible 
permutations.

Suppose we have 10 values per permutable molecule.
Take molecule 1 here. Assign it.
	Molecule 2 is fixed because of conservation laws in row 1 of gamma
	Molecule 3 can take any of 10 values (but note consv laws may limit)
	Molecule 4 can take any of 10 values (but note consv laws may limit)
	Molecule 5 is now fixed due to conservations laws in row 2 of gamma

This is good, but how do we find what those 10 values are?

Example 1:
Molecule 1 takes max value of 3.
Molecule 2 becomes 0. No choice.
Molecule 3 can now take any value between 3 and 8. Say it takes 8.
Molecule 4 must become 0.
Molecule 5 must become 0.

So we don't really have 3 dimensions here. Only 2.

Example 2:
Molecule 1 takes min value of 0.
Molecule 2 becomes 3. No choice.
Molecule 3 can now take any value between 0 and 5. Say it takes 2.
Molecule 4 can take any value between 0 and 3. Say it takes 2.
Molecule 5 must become 1.

	Looks like Molecule 3 always has access to the full range of concs,
	though the start and end may differ.
	Clearly Molecule 4 does not have access to the full range of concs.
		On average, half.
	If we had further molecules in this series, the next one will have 
		access to 1/4 the range of concs on average.

So it looks like an exponentially declining series. For n molecules in
a conservation set, and a granularity of g samples across the range, we have

#samples = g * g/2 * g/4 *...

The series for fractions of 2 goes like:
	1 * .5 * .25 * ...
	= 2^0 * 2^-1 * 2^-2 *....
	= 2^(0 - 1 - 2...)
	
	1 + 2 + 3 + 4 ... = n(n+1)/2
	0 + 1 + 2 + 3 ... = n(n+1)/2 - n = n( (n+1)/2 - 1 ) = n( ((n+1)-2) / 2 )
		  	  = n(n-1)/2
	
So
#samples = (g^n)/( 2^(n(n-1)/2) )

ln(#samples) = n*ln(g) - (n*(1-n)/2)*ln(2)
Some numbers: Note g = #levels - 1, since zero levels are allowed.

granularity g	num mol n	#samples			using combin
10		2		10				11
10		3		50				66
10		4		(1000/8) = 125			286
	(we're now unable to get round#s of samples)
10		5		10000/64 ~ 156 			715

1		2		2				2
1		3		3				3
1		4		4 (estimate would have been 1)	4
1		5		5 (estimate < 1)		5

2		2		3				3
2		3		3+2+1 = 6			6
2		4		6+3+1 = 10			10

This doesn't work too well. Try again:
m1 + m2 + m3 ... = tot
How many ways to choose m1, m2, m3 with a given granularity g.
If we simply say tot = g (# of levels) and use integer, it turns into simple
combinations with repetition: how to partition g levels among m molecules.

(g + m - 1)C(m - 1) = (g + m - 1)Cg
Plug this into the table above and see how it works.

Check it for 2 mols: 10 levels. # in first can be 0 to 10 inclusive, others
are fixed from this. So it is 11 levels.
Check it for 3 mols: 10 levels. # in first can be 0 to 10 inclusive. Sum
of remainder is fixed from this, and it goes into 2 mols. Remainder could be 
0: 1 way
1: 2 ways
2: 3 ways
3: 4 ways
4: 5 ways
...
10: 11 ways.
so total ways is n(n+1)/2 = 66.
Seems OK.
Also checked for the case of granularity = 1 and 2.

This is a good quick way to estimate # of samples for a given granularity,
and work backwards iteratively to find granularity. Next step is to implement
the scanning.

1. Order gamma so first row is all positive. I think the
	current algorithm always does this for the first row.
2. Define granularity, send #samples info back to StateScanner
3. Simplest approach is to build up an internal table of mol levels that
	the iterator looks up. It is unlikely anyone will use masses of
	memory on this. For big numbers we'll recommend Monte Carlo.
4. Run through table.

For the Monte Carlo case it is still simpler. On each sample, generate
random #s for mol concs scaled to fit within range.

After all this, I have gone ahead with an implemetantion for the Monte Carlo
generator instead. It just generates a single Monte Carlo point.
Checked in (after some problems) as revision 1328. Yet to test.

=============================================================================
15 Sep 2009
Implemented, the algorithm itself is flawed. First, it is way to complicated:
I came up with a much simpler way to assign the mol concs.
Second, the constraints of the consv laws don't come through cleanly in
	either approach, and will need careful work.
=============================================================================
16 Sep 2009
Implemented new algorithm for generating initial conditions using 
Monte Carlo methods. Seems OK for a simple test case.

checked in as revision 1330.
=============================================================================
17 Sep 2009
Finally the general algorithm for finding all steady states seems to be
working. Turns out that the Monte Carlo approach is surprisingly bad at
finding some corner cases, that turn up right away with the systematic
scan. Some minor cleanup needed, and then I have to decide if I want to
proceed with the systematic scan algorithm too.
checked in as revision  1332

Tried with slightly bigger model  SNARE_dup_bis_m2star_TRI.g
This fails to expand the state table, and loses track if there are 
some non-convergent solutions. See StateScanner.cpp:832 and 898
Another symptom is that every time the Steady state iteration fails, the
size of the state vector is depleted by one.

Let's see how it handles one of the traffillator models.
After much messing around, it works.  Tracked down the bug with depleted 
state vector. There is still a bug with it maintaining one
more solution in the mol tables than it should.
Also it contines to need huge numbers of trials: 2000 in this case, to get
all states of a tristable. 
Otherwise nice.
checked in as revision 1333.

=============================================================================
18 Sep 2009
General cleanup. Problem with extra solutions fixed. 
Csv and xplot outputs fixed.
checked in as revision 1335.

=============================================================================
13 Aug 2010.
Coming back to the trunk in order to fix up SigNeur clock handling. The
current version does not deal properly with NeuroML compilations.
Set SigNeur to assign clocks 0, 1, 2 to hsolve, and 3, 4 to signaling.
Checkin as 2118.
=============================================================================
19 Aug 2010
Issue with ordering of molecule identities for readout by zombies
as compared to setup.
When using SigNeur, setup is through KineticManager.
The function that sets up the elist is 
findDescendants( Eref manager, vector< Id >& ret )
	which recursively gets the childList of each Element.
This is extremely messy for arrays, but looks like it starts on
index 0, traverses through tree, then does index 1 through tree,
and so on.

Put a 'sort' function in Stoich::rebuildMatrix to ensure that the
incoming vector< Id > is independent of the algorithm used to build the
tree. This seems to help.
Checkin 2129.
=============================================================================
22 Aug 2010
Implemented handling of SynChans in SigNeurAdaptor.cpp.
Checkin 2131.
=============================================================================
27 Aug 2010
untar the pymoose_binaries.tar
and execute pymoose.sh
=============================================================================
8 Nov 2010
Put in a check for kinetic models where the rank = nVarMols. This is an 
extremely improbable situation and might reflect a bug in the model itself,
but should not cause the simulator to crash. Checkin 2336.
